"""
	Characterization(model)

Compute quantities useful for characterizing the model

ARGUMENT
-a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

OPTIONAL ARGUMENT
-`nsamples`: number of samples to include within the composite

RETURN
-a composite containg quantities useful for understanding the model. See `types.jl` for details on each field of the composite.
"""
Characterization(model::Model; nsamples=100) = Characterization(model, model;nsamples=nsamples)

"""
	Characterization(testmodel, trainingmodel)
"""
function Characterization(testmodel::Model, trainingmodel::Model; nsamples::Integer=100)
	Characterization(paccumulator = accumulator_distribution(testmodel),
					paccumulator_choice = posterior_accumulator_distribution(testmodel; conditionedon="choices"),
					paccumulator_choicespikes = posterior_accumulator_distribution(testmodel; conditionedon="choices_spikes"),
					paccumulator_spikes = posterior_accumulator_distribution(testmodel; conditionedon="spikes"),
					LLchoice = loglikelihood_choice(testmodel),
					LLchoice_bernoulli = map((testset, trainingset)->loglikelihood_choice_bernoulli(testset, trainingset), testmodel.trialsets, trainingmodel.trialsets),
					LLchoice_spikes = loglikelihood_choice_given_spikes(testmodel),
					LLspikes = loglikelihood_spiketrains(testmodel),
					LLspikes_poisson = map((testset, trainingset)->loglikelihood_spiketrains_poisson(testset, trainingset), testmodel.trialsets, trainingmodel.trialsets),
					expectedemissions = ExpectedEmissions(testmodel, nsamples))
end

"""
	accumulator_distribution(model)

Moment-to-moment probability distribution of the accumulated evidence

ARGUMENT
-a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`pğš`: a nested array whose element `pğš[i][m][t][j]` corresponds to the probability of the accumulator in the j-th state during the t-th time step of the m-th trial in the i-th trialset
"""
function accumulator_distribution(model::Model)
	memory = Memoryforgradient(model)
	P = update_for_latent_dynamics!(memory, model.options, model.Î¸native)
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			pğš = collect(zeros(0) for t=1:trial.ntimesteps)
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			pğš[1] = copy(memory.pğšâ‚)
			@inbounds for t=2:trial.ntimesteps
				Aáµƒ = transitionmatrix(trial.clicks, memory.Aáµƒinput, memory.Aáµƒsilent, t)
				pğš[t] = Aáµƒ * pğš[t-1]
			end
			return pğš
		end
	end
end

"""
	posterior_accumulator_distribution

Moment-to-moment distribution of the accumulated evidence given the choices, spike trains, or both

ARGUMENT
-`model`:a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

OPTIONAL ARGUMENT
-`conditionedon`: a string that needs to contain "choice" or "spike"

RETURN
-`ğ©`: a nested array whose element `ğ©[i][m][t][j]` corresponds to the probability of the accumulator in the j-th state during the t-th time step of the m-th trial in the i-th trialset

"""
function posterior_accumulator_distribution(model::Model; conditionedon::String="choices_spikes")
	memory = Memoryforgradient(model)
	if occursin("choice", conditionedon) && occursin("spike", conditionedon)
		posteriors!(memory, model)
	elseif occursin("choice", conditionedon)
		choiceposteriors!(memory, model)
	elseif occursin("spike", conditionedon)
		posterior_on_spikes!(memory, model)
	else
		error("unrecognized data type")
	end
	fb = sortbytrial(memory.Î³, model)
	map(fb) do fb
		map(fb) do fb
			map(fb) do fb
				dropdims(sum(fb, dims=2), dims=2)
			end
		end
	end
end

"""
	loglikelihood_choice(model)

Log(base 2)-likelihood of the choice on each trial

ARGUMENT
-a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`â„“â‚‚ğ‘‘`: a nested array whose element `â„“â‚‚ğ‘‘[i][m]` is the log-likelihood of the choice in the m-th trial in the i-th trialset.
"""
function loglikelihood_choice(model::Model)
	memory = Memoryforgradient(model)
	P = update_for_âˆ‡latent_dynamics!(memory, model.options, model.Î¸native)
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			pğš = memory.pğšâ‚
			for t = 2:trial.ntimesteps
				Aáµƒ = transitionmatrix(trial.clicks, memory.Aáµƒinput, memory.Aáµƒsilent, t)
				pğš = Aáµƒ*pğš
			end
			pğ‘‘_ğš = memory.pğ‘‘_a[trial.trialsetindex][trial.index_in_trialset]
			conditionallikelihood!(pğ‘‘_ğš, trial.choice, model.Î¸native.Ïˆ[1])
			log2(dot(pğš, pğ‘‘_ğš))
		end
	end
end

"""
	loglikelihood_choice_given_spikes(model)

Log(base 2)-likelihood of the choice on each trial, conditioned on the spike trains

ARGUMENT
-`model`:a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`â„“â‚‚ğ‘‘_ğ˜`: a nested array whose element â„“â‚‚ğ‘‘_ğ˜[i][m]` is the log(base 2)-likelihood of the choice in the m-th trial in the i-th trialset.
"""
function loglikelihood_choice_given_spikes(model::Model)
	memory = Memoryforgradient(model)
	P = update!(memory, model)
	memory_ğ˜ = Memoryforgradient(model)
	for i in eachindex(memory_ğ˜.pğ˜ğ‘‘)
		scaledlikelihood!(memory_ğ˜.pğ˜ğ‘‘[i], model.options.sf_y, model.trialsets[i])
	end
	P_ğ˜ = update_for_latent_dynamics!(memory_ğ˜, model.options, model.Î¸native)
	log2e = log2(exp(1))
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			memory.â„“[1] = 0.0
			memory_ğ˜.â„“[1] = 0.0
			forward!(memory, P, model.Î¸native, trial)
			forward!(memory_ğ˜, P_ğ˜, model.Î¸native, trial)
			return log2e*(memory.â„“[1] - memory_ğ˜.â„“[1])
		end
	end
end

"""
	loglikelihood_choice_bernoulli(test_trialset, training_trialset)

Log-likelihood of the choices under a Bernoulli model

ARGUMENT
-`test_trialset`: held-out trials
-`training_trialset`: trials used to estimate the parameter of the Bernoulli distribution

RETURN
-`â„“â‚‚ğ‘‘_bernoulli`: nested array whose element `â„“â‚‚ğ‘‘_bernoulli[i][m]` is the log-likelihood of the choice in the m-th trial in the i-th trialset.
"""
function loglikelihood_choice_bernoulli(test_trialset::Trialset, training_trialset::Trialset)
	p = 0.0
	for trainingtrial in training_trialset.trials
		p+= trainingtrial.choice
	end
	p/=length(training_trialset.trials)
	logâ‚‚p = log2(p)
	logâ‚‚q = log2(1-p)
	map(test_trialset.trials) do testtrial
		testtrial.choice ? logâ‚‚p : logâ‚‚q
	end
end

"""
	loglikelihood_spiketrains_poisson(test_trialset, training_trialset)

Log-likelihood of the spike trains under a Bernoulli model

ARGUMENT
-`test_trialset`: held-out trials
-`training_trialset`: trials used to estimate the parameter of the Bernoulli distribution

RETURN
-`â„“â‚‚ğ²_poisson`: a nested array whose element `â„“â‚‚ğ²_poisson[m][n][t]` is the log-likelihood of observed spike count at the t-time step of the m-th trial for the n-th neuron.
"""
function loglikelihood_spiketrains_poisson(test_trialset::Trialset, training_trialset::Trialset)
	concatenatedâ„“s = map(test_trialset.mpGLMs, training_trialset.mpGLMs) do test_mpGLM, training_mpGLM
						Î»Î”t = mean(training_mpGLM.ğ²)
						map(y->log2(poissonlikelihood(Î»Î”t, y)), test_mpGLM.ğ²)
					end
	map(test_trialset.trials) do trial
		timesteps = trial.Ï„â‚€ .+ (1:trial.ntimesteps)
		map(concatenatedâ„“s) do concatenatedâ„“
			concatenatedâ„“[timesteps]
		end
	end
end

"""
	loglikelihood_spiketrains(model)

Log(base 2)-likelihood of the spike count of each neuron at each time step

ARGUMENT
-`model`:a composite containing the data, parameters, and hyperparameter of a factoral hidden Markov drift-diffusion model

RETURN
-`â„“â‚‚ğ²`: a nested array whose element `â„“â‚‚ğ²[i][m][n][t]` is the log-likelihood of the spike count of n-th neuron of the i-th trialset on the t-th time step of the m-th trial within the i-th trialset.
"""
function loglikelihood_spiketrains(model::Model)
	memory = Memoryforgradient(model)
	P = update_for_âˆ‡latent_dynamics!(memory, model.options, model.Î¸native)
	pğ‘¦_ğšğœ = zeros(model.options.Î, model.options.K)
	map(model.trialsets) do trialset
		map(trialset.trials) do trial
			â„“â‚‚ğ² = collect(zeros(trial.ntimesteps) for mpGLM in trialset.mpGLMs)
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			pğš = memory.pğšâ‚
			pğœ = memory.Ï€á¶œ
			for t=1:trial.ntimesteps
				if t > 1
					Aáµƒ = transitionmatrix(trial.clicks, memory.Aáµƒinput, memory.Aáµƒsilent, t)
					pğš = Aáµƒ*pğš
					pğœ = memory.Aá¶œ*pğœ
				end
				Ï„ = trial.Ï„â‚€ + t
				for (mpGLM, â„“â‚‚ğ²) in zip(trialset.mpGLMs, â„“â‚‚ğ²)
					conditionallikelihood!(pğ‘¦_ğšğœ, mpGLM, Ï„)
					â„“â‚‚ğ²[t] = log2(pğš'*pğ‘¦_ğšğœ*pğœ)
				end
			end
			return â„“â‚‚ğ²
		end
	end
end

"""
	ExpectedEmissions(model, nsamples)

Compute the expectation of the choice and spike train on each trial by averaging across simulations

While the expectation of the choice can be computed without simulation, the expectation of a spike train requires simulation due to the spike history input.

Note the similarity between this function and `drawsamples`

ARGUMENT
-`model`: a composite containing the data, parameters, and hyperparameters of the factorial hidden-Markov drift-diffusion model
-`nsamples`: number of samples to draw

RETURN
-`expectedemissions`: a nested array whose element `expectedemissions[i][m]` contains the expected choice and the choice-conditioned spike trains of each neuron on the m-th trial of the i-th trialset.
"""
function ExpectedEmissions(model::Model, nsamples)
	memory = Memoryforgradient(model)
	P = update_for_latent_dynamics!(memory, model.options, model.Î¸native)
	a = zeros(Int, memory.maxtimesteps)
	c = zeros(Int, memory.maxtimesteps)
	map(model.trialsets) do trialset
		ğ„ğ = map(mpGLM->externalinput(mpGLM), trialset.mpGLMs)
		ğ¡ = map(mpGLM->postspikefilter(mpGLM), trialset.mpGLMs)
		ğ›š = map(mpGLM->transformaccumulator(mpGLM), trialset.mpGLMs)
		map(trialset.trials) do trial
			accumulator_prior_transitions!(memory.Aáµƒinput, P, memory.pğšâ‚, trial)
			Eğ˜left = collect(zeros(trial.ntimesteps) for mpGLM in trialset.mpGLMs)
			Eğ˜right = deepcopy(Eğ˜left)
			nright = 0
			for s = 1:nsamples
				trialsample = sampletrial!(a, c, ğ„ğ, ğ¡, memory, ğ›š, model.Î¸native.Ïˆ[1], trial, trialset)
				nright += trialsample.choice
				Eğ˜ = trialsample.choice ? Eğ˜right : Eğ˜left
				for (Eğ², ğ²) in zip(Eğ˜, trialsample.spiketrains)
					for t in eachindex(Eğ²)
						Eğ²[t] += ğ²[t]
					end
				end
			end
			nleft = nsamples-nright
			if nleft > 0
				for Eğ²left in Eğ˜left
					for t in eachindex(Eğ²left)
						Eğ²left[t] /= nleft
					end
				end
			end
			if nright > 0
				for Eğ²right in Eğ˜right
					for t in eachindex(Eğ²right)
						Eğ²right[t] /= nright
					end
				end
			end
			ExpectedEmissions(rightchoice=nright/nsamples,
							spiketrain_leftchoice=Eğ˜left,
							spiketrain_rightchoice=Eğ˜right)
		end
	end
end

"""
	Characterization(cvindices, testmodels, trainingmodels)

Out-of-sample computation of quantities for characterizing the model

ARGUMENT
-`cvindices`: a vector of composites, each of which containing the indices of trials used for testing and training for a particular cross-validation fold
-`testmodels`: a vector of composites, each of which containing the held-out data for a cross-validation fold
-`trainingmodels`: a vector of composites, each of which containing the training data for a cross-validation fold
"""
function Characterization(cvindices::Vector{<:CVIndices}, testmodels::Vector{<:Model}, trainingmodels::Vector{<:Model}; nsamples::Integer=100)
	characterization_each_fold = map((testmodel, trainingmodel)->Characterization(testmodel, trainingmodel; nsamples=nsamples), testmodels, trainingmodels)
	ntrialsets = length(cvindices[1].testingtrials)
	trialindices = collect(vcat((cvindex.testingtrials[i] for cvindex in cvindices)...) for i=1:ntrialsets)
	values =
		map(fieldnames(Characterization)) do fieldname
			map(1:ntrialsets) do i
				field = vcat((getfield(characterization, fieldname)[i] for characterization in characterization_each_fold)...)
				field[trialindices[i]]
			end
		end
	Characterization(values...)
end

"""
	save(characterization, folderpath)

Save the characterizations of the model.

Each field of the composite `characterization` is saved within a separate file, with the same name as that of the field, within a folder whose absolute path is specified by `folderpath`.
"""
function save(characterization::Characterization, folderpath::String)
	if !isdir(folderpath)
		mkdir(folderpath)
		@assert isdir(folderpath)
	end
	for fieldname in fieldnames(Characterization)
		filepath = joinpath(folderpath, String(fieldname)*".mat")
		if fieldname==:expectedemissions
			entry =
				map(characterization.expectedemissions) do expectedemissions
					map(expectedemissions) do expectedemissions
						dictionary(expectedemissions)
					end
				end
		else
			entry = getfield(characterization, fieldname)
		end
		dict = Dict(String(fieldname)=>entry)
	    matwrite(filepath, dict)
	end
end

"""
"""
function peristimulus_time_histogram(ğ„::Vector{<:ExpectedEmissions}, options::Options)
	maxtimesteps = maximum((length(E.spiketrain_leftchoice[1]) for E in ğ„))
	Ïƒ_timestep = ceil(options.dt*Ïƒ_s)
	h = causal_gaussian_impulse_response(Ïƒ_timestep, maxtimesteps)
	w = conv(ones(maxtimesteps),h)[1:maxtimesteps]
	nneurons = length(ğ„[1].spiketrain_leftchoice)
	map(1:nneurons) do n
		map(ğ„) do E
			conv_causal_gaussian(h, w, E.spiketrain_leftchoice[n])
		end
	end

	psth = (zeros(maxtimesteps) for n = 1:nneurons)
	psth_leftchoice = (zeros(maxtimesteps) for n = 1:nneurons)
	psth_rightchoice = (zeros(maxtimesteps) for n = 1:nneurons)
	weights_leftchoice = zeros(maxtimesteps)
	weights_rightchoice = zeros(maxtimesteps)
	for E in ğ„
		for t in eachindex(E.spiketrain_leftchoice[1])
			weights_leftchoice += 1-E.rightchoice
			for n = 1:nneurons
				psth_leftchoice[n][t] += E.spiketrain_leftchoice[n][t]
				psth_rightchoice[n][t] += E.spiketrain_rightchoice[n][t]
				psth[n][t] += E.spiketrain_leftchoice[n][t]*(1-E.rightchoice) + E.spiketrain_rightchoice[n][t]*E.rightchoice
			end
		end
	end
f = Normal()
v = collect(pdf(f, x) for x in 0:0.1:1)
conv(u,v)./conv(ones(length(u)), v)
end

"""

Weight convolution of a spike train with a causal gaussian

Spike train responses near the beginning are adjusted for the lack of responses available before the beginning

ARGUMENT
-`ğ²`: spike trains of a neuron in each trial
-`Ïƒ`: standard deviation of the causal gaussian filter, in time steps

RETURN
-`psth`: a nested array whose element `psth[m][t]` correspons to the smoothed
"""
function convolve_causal_gaussian(ğ²::Vector{<:Vector{<:Real}}, Ïƒ::Real)
	maxtimesteps = maximum(length(ğ²â‚˜) for ğ²â‚˜ in ğ²)
	normal = Normal(0,Ïƒ)
	ğ¯ = collect(pdf(normal,t) for t=1:maxtimesteps)
	ğ° = conv(ones(maxtimesteps),ğ¯)[1:maxtimesteps]
	map(ğ²) do ğ²â‚˜
		ğ± = conv(ğ²â‚˜, ğ¯)
		collect(ğ±[i]/ğ°[i] for i in eachindex(ğ²â‚˜))
	end
end
