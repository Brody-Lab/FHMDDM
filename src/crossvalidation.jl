"""
    crosssvalidate(model, kfold, ğ›Œ)

Assess how well the factorial hidden Markov drift-diffusion model generalizes to independent datasets

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model
-`kfold`: number of cross-validation folds
-`ğ¬`: a vector of floating point numbers representing the L2 regularization weight on each parameter

OUTPUT
-an instance of `CVResults`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
julia> ğ¬ = 0.1.*ones(length(concatenatedÎ¸))
julia> cvresults = crossvalidate(model, 5, ğ¬)
"""
function crossvalidate(model::Model,
                       kfold::Integer,
                       ğ¬::Vector{<:AbstractFloat};
					   iterations= 1000)
    cvindices = CVIndices(model, kfold)
    Î¸â‚€native = map(k->LatentÎ¸(), 1:kfold)
    Î¸native = map(k->LatentÎ¸(), 1:kfold)
	losses = map(k->fill(NaN, iterations), 1:kfold)
	gradientnorms = map(k->fill(NaN, iterations), 1:kfold)
    glmÎ¸ = map(1:kfold) do k
				map(model.trialsets) do trialset
					map(trialset.mpGLMs) do mpGLM
						GLMÎ¸(ğ®=copy(mpGLM.Î¸.ğ®),
							 ğ¯=copy(mpGLM.Î¸.ğ¯),
							 a=copy(mpGLM.Î¸.a),
							 b=copy(mpGLM.Î¸.b))
					end
				end
			end
    for k=1:kfold
        Î¸â‚€native[k] = initializeparameters(model.options)
        trainingmodel = Model(trialsets = trainingset(cvindices[k], model.trialsets),
                              options = model.options,
                              Î¸â‚€native = Î¸â‚€native[k],
                              Î¸native = LatentÎ¸(([getfield(Î¸â‚€native[k], f)...] for f in fieldnames(LatentÎ¸))...),
                              Î¸real = native2real(model.options, Î¸â‚€native[k]))
        maximizechoiceLL!(trainingmodel)
        initializeparameters!(trainingmodel)
        losses[k], gradientnorms[k] = maximizeposterior!(trainingmodel, ğ¬, Optim.LBFGS(linesearch = LineSearches.BackTracking()); iterations=iterations)
        Î¸native[k] = trainingmodel.Î¸native
        for i in eachindex(model.trialsets)
            for n in eachindex(model.trialsets[i].mpGLMs)
                glmÎ¸[k][i][n] = model.trialsets[i].mpGLMs[n].Î¸
            end
        end
    end
    rll_choice, rll_spikes = relative_loglikelihood(cvindices, glmÎ¸, model.options, Î¸native, model.trialsets)
    CVResults(cvindices = cvindices,
              Î¸â‚€native = Î¸â‚€native,
              Î¸native = Î¸native,
              glmÎ¸ = glmÎ¸,
              losses = losses,
              gradientnorms = gradientnorms,
              rll_choice = rll_choice,
              rll_spikes = rll_spikes)
end

"""
	relative_loglikelihood(cvindices, glmÎ¸, options, Î¸native, trialsets)

Relative log-likelihood of the choices and of the spike train responses

ARGUMENT
-`cvindices`: indices of the trials and timesteps used for training and testing in each fold
-`glmÎ¸`: optimized parameters of the Poisson mixture GLM of each neuron in each fold
-`options`: model settings
-`Î¸native`: optimized parameters specifying the latent variables in each fold
-`trialsets`: the data

OUTPUT
-`rll_choice`: A vector of floating point numbers whose element `rll_choice[i]` represents the trial-averaged log-likelihood of the choices in the i-th trialset. Subtracted from this value is the baseline trial-averaged log-likelihood of the choices, computed under a Bernoulli distribution parametrized by the fraction of right responses.
-`rll_spikes`: A nested vector of floating point numbers element `rll_spikes[i][n]` represents the time-average log-likelihood of the n-th neuron's spike train in the i-th trialset. Subtracted from this value this is baseline time-average log-likelihood computed under a Poisson distribution parametrized by the average spike train response across time steps. The difference is further divided by the number of spikes observed for each neuron.
"""
function relative_loglikelihood(cvindices::Vector{<:CVIndices},
								glmÎ¸::Vector{<:Vector{<:Vector{<:GLMÎ¸}}},
                                options::Options,
                                Î¸native::Vector{<:LatentÎ¸},
                                trialsets::Vector{<:Trialset})
    rll_choice = zeros(length(trialsets))
    rll_spikes = map(trialset->zeros(length(trialset.mpGLMs)), trialsets)
    kfold = length(cvindices)
    for k=1:kfold
        testingmodel = Model(trialsets = testingset(cvindices[k], trialsets),
                             options = options,
                             Î¸â‚€native = Î¸native[k],
                             Î¸native = Î¸native[k],
                             Î¸real = native2real(options, Î¸native[k]))
        for i in eachindex(testingmodel.trialsets)
            for n in eachindex(testingmodel.trialsets[i].mpGLMs)
                testingmodel.trialsets[i].mpGLMs[n].Î¸.ğ® .= glmÎ¸[k][i][n].ğ®
                testingmodel.trialsets[i].mpGLMs[n].Î¸.ğ¯ .= glmÎ¸[k][i][n].ğ¯
                testingmodel.trialsets[i].mpGLMs[n].Î¸.a .= glmÎ¸[k][i][n].a
                testingmodel.trialsets[i].mpGLMs[n].Î¸.b .= glmÎ¸[k][i][n].b
            end
        end
		ğ›Œâ‚€Î”t = map(trialsets, cvindices[k].trainingtimesteps) do trialset, trainingtimesteps
					map(trialset.mpGLMs) do mpGLM
						mean(mpGLM.ğ²[trainingtimesteps])
					end
				end
		fractionright = map(trialsets, cvindices[k].trainingtrials) do trialset, trainingtrials
							mean(map(trialset.trials[trainingtrials]) do trial
									trial.choice
								 end)
						end
		â„“ğ‘‘, â„“ğ‘¦ = relative_loglikelihood(testingmodel, ğ›Œâ‚€Î”t, fractionright)
		for i in eachindex(testingmodel.trialsets)
			rll_choice[i] += â„“ğ‘‘[i]/kfold
            for n in eachindex(testingmodel.trialsets[i].mpGLMs)
				rll_spikes[i][n] += â„“ğ‘¦[i][n]/kfold
        	end
		end
    end
	return rll_choice, rll_spikes
end

"""
	relative_loglikelihood(model, ğ›Œâ‚€, fractionright)

Compute the relative log-likelihood of the choices and spike train responses

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model
-`ğ›Œâ‚€Î”t`: the mean number of spikes per timestep of each neuron
-`fractionright`: the fraction of responding right

OUTPUT
-`â„“ğ‘‘`: â„“ğ‘‘[i] corresponds to the log-likelihood of the choices per trial in the i-th trialset, relative to the log-likelihood under a Bernoulli parametrized by `fractioncorrect`
-`â„“ğ‘¦`: â„“ğ‘¦[i][n] corresponds to the log-likelihood per spike of the n-th spike train in the i-th trialset, relative to the log-likelihood under a Poisson parametrized by `ğ›Œâ‚€`
"""
function relative_loglikelihood(model::Model,
								ğ›Œâ‚€Î”t::Vector{<:Vector{<:AbstractFloat}},
								fractionright::Vector{<:AbstractFloat})
	@unpack options, Î¸native, trialsets = model
	@unpack Aá¶œâ‚â‚, Aá¶œâ‚‚â‚‚, Ï€á¶œâ‚ = Î¸native
	@unpack Î”t, K, Î = options
	Aá¶œáµ€ = [Aá¶œâ‚â‚[1] 1-Aá¶œâ‚â‚[1]; 1-Aá¶œâ‚‚â‚‚[1] Aá¶œâ‚‚â‚‚[1]]
	Ï€á¶œáµ€ = [Ï€á¶œâ‚[1] 1-Ï€á¶œâ‚[1]]
	ğ› = Î¸native.B[1]*(2collect(1:Î) .- Î .- 1)/(Î-2)
	ğ› = conditionedmean(0.0, Î”t, Î¸native.Î»[1], ğ›)
	Aáµƒ, Aáµƒsilent = zeros(Î,Î), zeros(Î,Î)
	stochasticmatrix!(Aáµƒsilent, ğ›, âˆš(Î¸native.ÏƒÂ²â‚[1]*Î”t), ğ›)
	Ïƒáµ¢ = âˆšÎ¸native.ÏƒÂ²áµ¢[1]
	â„“ğ‘‘ = zeros(length(model.trialsets))
	â„“ğ‘¦ = map(trialset->zeros(length(trialset.mpGLMs)), model.trialsets)
	pğ‘¦ = zeros(Î,K)
	homogeneousPoissons = map(Î»Î”t->map(Î»Î”t->Poisson(Î»Î”t),Î»Î”t),ğ›Œâ‚€Î”t)
	for i in eachindex(model.trialsets)
		Ï„ = 0
		for m in eachindex(model.trialsets[i].trials)
			@unpack choice, clicks, ntimesteps, previousanswer = trialsets[i].trials[m]
			C = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
			Î¼ = Î¸native.Î¼â‚€[1] + previousanswer*Î¸native.wâ‚•[1]
			pğš = probabilityvector(Î¼, Ïƒáµ¢, ğ›)
			pğœáµ€ = copy(Ï€á¶œáµ€)
			for t=1:ntimesteps
				Ï„+=1
				if t > 1
					if isempty(clicks.inputindex[t])
						pğš = Aáµƒsilent*pğš
					else
						cL = sum(C[clicks.left[t]])
						cR = sum(C[clicks.right[t]])
						ğ› = conditionedmean(cR-cL, Î”t, Î¸native.Î»[1], ğ›)
						Ïƒ = âˆš( (cL+cR)*Î¸native.ÏƒÂ²â‚›[1] + Î¸native.ÏƒÂ²â‚[1]*Î”t )
						stochasticmatrix!(Aáµƒ, ğ›, Ïƒ, ğ›)
						pğš = Aáµƒ*pğš
					end
					pğœáµ€ = pğœáµ€*Aá¶œáµ€
				end
				for n in eachindex(trialsets[i].mpGLMs)
					likelihood!(pğ‘¦, trialsets[i].mpGLMs[n], Ï„)
					â„“ğ‘¦[i][n] += log(sum(pğ‘¦.*(pğš*pğœáµ€))) - Distributions.logpdf(homogeneousPoissons[i][n], trialsets[i].mpGLMs[n].ğ²[Ï„])
				end
			end
			pğ‘‘ = conditionallikelihood(choice, Î¸native.Ïˆ[1], Î)
			â„“ğ‘‘[i] += log(sum(pğ‘‘.*pğš)) - log(choice ? fractionright[i] : 1-fractionright[i])
		end
  		â„“ğ‘‘[i] /= length(model.trialsets[i].trials)
		for n in eachindex(trialsets[i].mpGLMs)
			â„“ğ‘¦[i][n] /= sum(trialsets[i].mpGLMs[n].ğ²)
		end
	end
	return â„“ğ‘‘, â„“ğ‘¦
end

"""
    likelihood(choice, Ïˆ, Î)

Conditional probability of a right choice given the state of the accumulator

MODIFIED ARGUMENT
-`pğ˜â‚œğ‘‘`: A matrix whose element pğ˜â‚œğ‘‘[j,k] â‰¡ p(ğ˜â‚œ, ğ‘‘ âˆ£ aâ‚œ = Î¾â±¼, zâ‚œ = k) for time bin t that is the at the end of the trial

UNMODIFIED ARGUMENT
-`choice`: the observed choice, either right (`choice`=true) or left.
-`Ïˆ`: the prior probability of a lapse state

OPTIONAL ARGUMENT
- `zeroindex`: the index of the bin for which the accumulator variable equals zero
"""
function conditionallikelihood(choice::Bool,
					             Ïˆ::type,
								 Î::Integer) where {type<:Real}
	p = ones(type, Î)
	zeroindex = cld(Î,2)
    p[zeroindex] = 0.5
    if choice
        p[1:zeroindex-1] .= Ïˆ/2
        p[zeroindex+1:end] .= 1-Ïˆ/2
    else
        p[1:zeroindex-1]   .= 1-Ïˆ/2
        p[zeroindex+1:end] .= Ïˆ/2
    end
    return p
end

"""
	likelihood!(p, mpGLM, t)

Conditional likelihood the spike train response at a single timestep

MODIFIED ARGUMENT
-`p`: a matrix whose element `p[i,j]` represents the likelihood conditioned on the accumulator in the i-th state and the coupling in the j-th state

UNMODIFIED ARGUMENT
-`mpGLM`:a structure with information on the mixture of Poisson GLM of a neuron
-`t`: timestep
"""
function likelihood!(p::Matrix{<:Real}, mpGLM::MixturePoissonGLM, t::Integer)
	@unpack Î”t, ğ”, ğš½, ğ›, Î¸, ğ², ğ²! = mpGLM
	ğ”â‚œğ® = ğ”[t,:] â‹… Î¸.ğ®
	ğš½â‚œğ¯ = ğš½[t,:] â‹… Î¸.ğ¯
	Î = size(p,1)
	K = size(p,2)
	if K > 1
		Î»Î”t = softplus(ğ”â‚œğ®)*Î”t
		p[:,2] .= likelihood(Î»Î”t, ğ²[t],  ğ²![t])
	end
	fa = rectifya(Î¸.a[1])
	for i = 1:Î
		fÎ¾ = transformaccumulator(Î¸.b[1], ğ›[i])
		Î»Î”t = softplus(ğ”â‚œğ® + fa*fÎ¾*ğš½â‚œğ¯)*Î”t
		p[i,1] = likelihood(Î»Î”t, ğ²[t],  ğ²![t])
	end
	return nothing
end

"""
    CVIndices(model, kfold)

Create indices for cross-validation

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model
-`kfold`: number of cross-validation folds

OUTPUT
-a vector of instances of `CVIndices`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
```
"""
function CVIndices(model::Model,
                   kfold::integertype) where {integertype<:Integer}
    testingtrials = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    trainingtrials = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    testingtimesteps = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    trainingtimesteps = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    for i in eachindex(model.trialsets)
        ntrials = length(model.trialsets[i].trials)
        ntestingtrials = cld(ntrials, kfold)
        partitionedtrials = collect(Base.Iterators.partition(shuffle(1:ntrials), ntestingtrials))
        timesteps = map(trial->collect(1:trial.ntimesteps), model.trialsets[i].trials)
        count = 0
        for m in eachindex( model.trialsets[i].trials)
            timesteps[m] .+= count
            count +=  model.trialsets[i].trials[m].ntimesteps
        end
        for k=1:kfold
            testingtrials[k][i] = sort(partitionedtrials[k])
            trainingtrials[k][i] = sort(vcat(partitionedtrials[vcat(1:k-1, k+1:kfold)]...))
            testingtimesteps[k][i] =  vcat(timesteps[testingtrials[k][i]]...)
            trainingtimesteps[k][i] =  vcat(timesteps[trainingtrials[k][i]]...)
        end
    end
    map(1:kfold,
        trainingtrials,
        testingtrials,
        trainingtimesteps,
        testingtimesteps) do    k,
                                trainingtrials,
                                testingtrials,
                                trainingtimesteps,
                                testingtimesteps
        CVIndices(trainingtrials = trainingtrials,
                  testingtrials = testingtrials,
                  trainingtimesteps = trainingtimesteps,
                  testingtimesteps = testingtimesteps)
    end
end

"""
    trainingset(cvindices, trialsets)

Subsample the data for training

ARGUMENT
-`cvindices`: an instance of `CVIndices`
-`trialsets`: a vector of instances of `Trialset`

OUTPUT
- a vector of instances of `Trialset`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
julia> first_training_set = trainingset(cvindices[1], model.trialsets)
```
"""
function trainingset(cvindices::CVIndices, trialsets::Vector{<:Trialset})
    map(trialsets, cvindices.trainingtrials, cvindices.trainingtimesteps) do trialset, trainingtrials, trainingtimesteps
        subsample(trialset, trainingtrials, trainingtimesteps)
    end
end

"""
    testingset(cvindices, trialsets)

Subsample the data for testing

ARGUMENT
-`cvindices`: an instance of `CVIndices`
-`trialsets`: a vector of instances of `Trialset`

OUTPUT
- a vector of instances of `Trialset`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
julia> first_testing_set = testingset(cvindices[1], model.trialsets)
```
"""
function testingset(cvindices::CVIndices, trialsets::Vector{<:Trialset})
    map(trialsets, cvindices.testingtrials, cvindices.testingtimesteps) do trialset, testingtrials, testingtimesteps
        subsample(trialset, testingtrials, testingtimesteps)
    end
end

"""
    subsample(trialset, trialindices, timesteps)

Create an instance of `Trialset` by subsampling

ARGUMENT
-`trialset`: a structure corresponding to a collection of trials in which the same neurons werre recorded
-`trialindices`: a vector of integers indexing the trials to include
-`timesteps`: a vector of integers indexing the timesteps of spiketrains to include

OUTPUT
- an instance of `Trialset`
"""
function subsample(trialset::Trialset,
                   trialindices::Vector{<:Integer},
                   timesteps::Vector{<:Integer})
    Trialset(trials = trialset.trials[trialindices],
             mpGLMs = map(mpGLM->subsample(mpGLM, timesteps), trialset.mpGLMs))
end

"""
    subsample(mpGLM, timesteps)

Create a mixture of Poisson GLM by subsampling the spike train of a neuron

ARGUMENT
-`mpGLM`: a structure with information on the mixture of Poisson GLM of a neuron
-`timesteps`: a vector of integers indexing the timesteps to include

OUTPUT
-an instance of `MixturePoissonGLM`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> ntimesteps = length(model.trialsets[1].mpGLMs[1].ğ²)
julia> firsthalf = collect(1:cld(ntimesteps,2))
julia> mpGLM = subsample(model.trialsets[1].mpGLMs[1], firsthalf)
```
"""
function subsample(mpGLM::MixturePoissonGLM, timesteps::Vector{<:Integer})
	Î¸ = GLMÎ¸(ğ®=copy(mpGLM.Î¸.ğ®),
			ğ¯=copy(mpGLM.Î¸.ğ¯),
			a=copy(mpGLM.Î¸.a),
			b=copy(mpGLM.Î¸.b))
    MixturePoissonGLM(Î”t = mpGLM.Î”t,
                        K = mpGLM.K,
                        ğ” = mpGLM.ğ”[timesteps, :],
                        ğš½ = mpGLM.ğš½[timesteps, :],
                        Î¦ = mpGLM.Î¦,
                        Î¸ = Î¸,
                        ğ— = mpGLM.ğ—[timesteps, :],
                        ğ› = mpGLM.ğ›,
                        ğ² =mpGLM.ğ²[timesteps])
end
