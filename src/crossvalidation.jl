"""
    crosssvalidate(model)

Assess how well the factorial hidden Markov drift-diffusion model generalizes to independent datasets

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model

OPTIONAL ARGUMENT
-`kfold`: number of cross-validation folds
-`iterations`: maximum number of iterations the solver goes through before stopping

OUTPUT
-an instance of `CVResults`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_16_test/T176_2018_05_03_static/data.mat")
julia> cvresults = crossvalidate(model;kfold=5, iterations=10)
julia> save(cvresults, model.options)
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_16_test/T176_2018_05_03_stochastic/data.mat")
julia> cvresults = crossvalidate(model;kfold=5, iterations=10)
julia> save(cvresults, model.options)
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_16_test/T176_2018_05_03_deterministic/data.mat")
julia> cvresults = crossvalidate(model;kfold=5, iterations=10)
julia> save(cvresults, model.options)
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_16_test/T176_2018_05_03_both/data.mat")
julia> cvresults = crossvalidate(model;kfold=5, iterations=10)
julia> save(cvresults, model.options)
```
"""
function crossvalidate(model::Model;
                       kfold::Integer=5,
					   iterations=1000)
    cvindices = CVIndices(model, kfold)
	results = pmap(cvindices->maxmizeposterior(cvindices, model; iterations=iterations), cvindices)
	trainingmodels = collect(result[1] for result in results)
	losses = collect(result[2] for result in results)
	gradientnorms = collect(result[3] for result in results)
	glmÎ¸s = collect(collect(collect(mpGLM.Î¸ for mpGLM in trialset.mpGLMs) for trialset in trainingmodel.trialsets) for trainingmodel in trainingmodels)
	Î¸â‚€native = collect(trainingmodel.Î¸â‚€native for trainingmodel in trainingmodels)
	Î¸native = collect(trainingmodel.Î¸native for trainingmodel in trainingmodels)
    rll_choice, rll_spikes = relative_loglikelihood(cvindices, glmÎ¸s, model.options, Î¸native, model.trialsets)
    CVResults(cvindices = cvindices,
              Î¸â‚€native = Î¸â‚€native,
              Î¸native = Î¸native,
              glmÎ¸ = glmÎ¸s,
              losses = losses,
              gradientnorms = gradientnorms,
              rll_choice = rll_choice,
              rll_spikes = rll_spikes)
end

"""
	maxmizeposterior(cvindices, model)

Maximize the posterior log-likelihood of subsample of the data

ARGUMENT
-`cvindices`: indices of the trials and timesteps used for training and testing in each fold
-`model`: structure containing the full dataset, parameters, and hyperparameters

RETURN
-`trainingmodel`: structure containing the data in the training trials, parameters optimized for the data in the trainings, and hyperparameters
-`losses`: the value of the cost function in each iteration
-`gradientnorms`: the 2-norm of the gradient the cost function in each iteration
"""
function maxmizeposterior(cvindices::CVIndices, model::Model; iterations::Integer)
	Î¸â‚€native = initializeparameters(model.options)
	trainingmodel = Model(trialsets = trainingset(cvindices, model.trialsets),
						  options = model.options,
						  Î¸â‚€native = Î¸â‚€native,
						  Î¸native = LatentÎ¸(([getfield(Î¸â‚€native, f)...] for f in fieldnames(LatentÎ¸))...),
						  Î¸real = native2real(model.options, Î¸â‚€native))
	if (trainingmodel.options.K > 1) && (trainingmodel.options.basistype == "none")
		initialize_for_stochastic_transition!(trainingmodel)
	else
		initializeparameters!(trainingmodel)
	end
	losses, gradientnorms = maximizeposterior!(trainingmodel; iterations=iterations)
	return trainingmodel, losses, gradientnorms
end

"""
	relative_loglikelihood(cvindices, glmÎ¸, options, Î¸native, trialsets)

Relative log-likelihood of the choices and of the spike train responses

ARGUMENT
-`cvindices`: indices of the trials and timesteps used for training and testing in each fold
-`glmÎ¸`: optimized parameters of the Poisson mixture GLM of each neuron in each fold
-`options`: model settings
-`Î¸native`: optimized parameters specifying the latent variables in each fold
-`trialsets`: the data

OUTPUT
-`rll_choice`: A vector of floating point numbers whose element `rll_choice[i]` represents the trial-averaged log-likelihood of the choices in the i-th trialset. Subtracted from this value is the baseline trial-averaged log-likelihood of the choices, computed under a Bernoulli distribution parametrized by the fraction of right responses.
-`rll_spikes`: A nested vector of floating point numbers element `rll_spikes[i][n]` represents the time-average log-likelihood of the n-th neuron's spike train in the i-th trialset. Subtracted from this value this is baseline time-average log-likelihood computed under a Poisson distribution parametrized by the average spike train response across time steps. The difference is further divided by the number of spikes observed for each neuron.
"""
function relative_loglikelihood(cvindices::Vector{<:CVIndices},
								glmÎ¸::Vector{<:Vector{<:Vector{<:GLMÎ¸}}},
                                options::Options,
                                Î¸native::Vector{<:LatentÎ¸},
                                trialsets::Vector{<:Trialset})
    rll_choice = zeros(length(trialsets))
    rll_spikes = map(trialset->zeros(length(trialset.mpGLMs)), trialsets)
    kfold = length(cvindices)
    for k=1:kfold
        testingmodel = Model(trialsets = testingset(cvindices[k], trialsets),
                             options = options,
                             Î¸â‚€native = Î¸native[k],
                             Î¸native = Î¸native[k],
                             Î¸real = native2real(options, Î¸native[k]))
        for i in eachindex(testingmodel.trialsets)
            for n in eachindex(testingmodel.trialsets[i].mpGLMs)
                testingmodel.trialsets[i].mpGLMs[n].Î¸.ğ® .= glmÎ¸[k][i][n].ğ®
				for k = 1:length(glmÎ¸[k][i][n].ğ¯)
	                testingmodel.trialsets[i].mpGLMs[n].Î¸.ğ¯[k] .= glmÎ¸[k][i][n].ğ¯[k]
				end
            end
        end
		ğ›Œâ‚€Î”t = map(trialsets, cvindices[k].trainingtimesteps) do trialset, trainingtimesteps
					map(trialset.mpGLMs) do mpGLM
						mean(mpGLM.ğ²[trainingtimesteps])
					end
				end
		fractionright = map(trialsets, cvindices[k].trainingtrials) do trialset, trainingtrials
							mean(map(trialset.trials[trainingtrials]) do trial
									trial.choice
								 end)
						end
		â„“ğ‘‘, â„“ğ‘¦ = relative_loglikelihood(testingmodel, ğ›Œâ‚€Î”t, fractionright)
		for i in eachindex(testingmodel.trialsets)
			rll_choice[i] += â„“ğ‘‘[i]/kfold
            for n in eachindex(testingmodel.trialsets[i].mpGLMs)
				rll_spikes[i][n] += â„“ğ‘¦[i][n]/kfold
        	end
		end
    end
	return rll_choice, rll_spikes
end

"""
	relative_loglikelihood(model, ğ›Œâ‚€, fractionright)

Compute the relative log-likelihood of the choices and spike train responses

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model
-`ğ›Œâ‚€Î”t`: the mean number of spikes per timestep of each neuron
-`fractionright`: the fraction of responding right

OUTPUT
-`â„“ğ‘‘`: â„“ğ‘‘[i] corresponds to the log-likelihood of the choices per trial in the i-th trialset, relative to the log-likelihood under a Bernoulli parametrized by `fractioncorrect`
-`â„“ğ‘¦`: â„“ğ‘¦[i][n] corresponds to the log-likelihood per spike of the n-th spike train in the i-th trialset, relative to the log-likelihood under a Poisson parametrized by `ğ›Œâ‚€`
"""
function relative_loglikelihood(model::Model,
								ğ›Œâ‚€Î”t::Vector{<:Vector{<:AbstractFloat}},
								fractionright::Vector{<:AbstractFloat})
	@unpack options, Î¸native, trialsets = model
	@unpack Aá¶œâ‚â‚, Aá¶œâ‚‚â‚‚, Ï€á¶œâ‚ = Î¸native
	@unpack Î”t, K, minpa, Î = options
	Aá¶œáµ€ = [Aá¶œâ‚â‚[1] 1-Aá¶œâ‚â‚[1]; 1-Aá¶œâ‚‚â‚‚[1] Aá¶œâ‚‚â‚‚[1]]
	Ï€á¶œáµ€ = [Ï€á¶œâ‚[1] 1-Ï€á¶œâ‚[1]]
	Aáµƒinput, Aáµƒsilent = zeros(Î,Î), zeros(Î,Î)
	expÎ»Î”t = exp(Î¸native.Î»[1]*Î”t)
	dÎ¼_dÎ”c = differentiate_Î¼_wrt_Î”c(Î”t, Î¸native.Î»[1])
	dğ›_dB = (2 .*collect(1:Î) .- Î .- 1)./(Î-2)
	ğ› = Î¸native.B[1].*dğ›_dB
	transitionmatrix!(Aáµƒsilent, minpa, expÎ»Î”t.*ğ›, âˆš(Î”t*Î¸native.ÏƒÂ²â‚[1]), ğ›)
	Ïƒáµ¢ = âˆšÎ¸native.ÏƒÂ²áµ¢[1]
	â„“ğ‘‘ = zeros(length(model.trialsets))
	â„“ğ‘¦ = map(trialset->zeros(length(trialset.mpGLMs)), model.trialsets)
	pğ‘¦ = zeros(Î,K)
	homogeneousPoissons = map(Î»Î”t->map(Î»Î”t->Poisson(Î»Î”t),Î»Î”t),ğ›Œâ‚€Î”t)
	log2e = log2(exp(1))
	for i in eachindex(model.trialsets)
		Ï„ = 0
		ntrials = length(model.trialsets[i].trials)
		for m in eachindex(model.trialsets[i].trials)
			@unpack choice, clicks, ntimesteps, previousanswer = trialsets[i].trials[m]
			Î¼ = Î¸native.Î¼â‚€[1] + previousanswer*Î¸native.wâ‚•[1]
			pğš = probabilityvector(minpa, Î¼, Ïƒáµ¢, ğ›)
			pğœáµ€ = Ï€á¶œáµ€
			if length(clicks.time) > 0
				adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
			end
			for t=1:ntimesteps
				Ï„+=1
				if t > 1
					if t âˆˆ clicks.inputtimesteps
						cL = sum(adaptedclicks.C[clicks.left[t]])
						cR = sum(adaptedclicks.C[clicks.right[t]])
						ğ› = expÎ»Î”t.*ğ› .+ (cR-cL).*dÎ¼_dÎ”c
						Ïƒ = âˆš((cR+cL)*Î¸native.ÏƒÂ²â‚›[1] + Î”t*Î¸native.ÏƒÂ²â‚[1])
						transitionmatrix!(Aáµƒinput, minpa, ğ›, Ïƒ, ğ›)
						Aáµƒ = Aáµƒinput
					else
						Aáµƒ = Aáµƒsilent
					end
					pğš = Aáµƒ*pğš
					pğœáµ€ = pğœáµ€*Aá¶œáµ€
				end
				for n in eachindex(trialsets[i].mpGLMs)
					conditionallikelihood!(pğ‘¦, trialsets[i].mpGLMs[n], Ï„)
					â„“ğ‘¦[i][n] += log2(sum(pğ‘¦.*pğš.*pğœáµ€)) - log2e*Distributions.logpdf(homogeneousPoissons[i][n], trialsets[i].mpGLMs[n].ğ²[Ï„])
				end
			end
			pğ‘‘ = conditionallikelihood(choice, Î¸native.Ïˆ[1], Î)
			â„“ğ‘‘[i] += log2(sum(pğ‘‘.*pğš)) - log2(choice ? fractionright[i] : 1-fractionright[i])
		end
  		â„“ğ‘‘[i] /= ntrials
		for n in eachindex(trialsets[i].mpGLMs)
			nspikes = sum(trialsets[i].mpGLMs[n].ğ²)
			â„“ğ‘¦[i][n] /= nspikes
		end
	end
	return â„“ğ‘‘, â„“ğ‘¦
end

"""
    conditionallikelihood(choice, Ïˆ, Î)

Conditional probability of a right choice given the state of the accumulator

MODIFIED ARGUMENT
-`pğ˜â‚œğ‘‘`: A matrix whose element pğ˜â‚œğ‘‘[j,k] â‰¡ p(ğ˜â‚œ, ğ‘‘ âˆ£ aâ‚œ = Î¾â±¼, zâ‚œ = k) for time bin t that is the at the end of the trial

UNMODIFIED ARGUMENT
-`choice`: the observed choice, either right (`choice`=true) or left.
-`Ïˆ`: the prior probability of a lapse state

OPTIONAL ARGUMENT
- `zeroindex`: the index of the bin for which the accumulator variable equals zero
"""
function conditionallikelihood(choice::Bool,
					             Ïˆ::type,
								 Î::Integer) where {type<:Real}
	p = ones(type, Î)
	zeroindex = cld(Î,2)
    p[zeroindex] = 0.5
    if choice
        p[1:zeroindex-1] .= Ïˆ/2
        p[zeroindex+1:end] .= 1-Ïˆ/2
    else
        p[1:zeroindex-1]   .= 1-Ïˆ/2
        p[zeroindex+1:end] .= Ïˆ/2
    end
    return p
end

"""
	conditionallikelihood!(p, mpGLM, t)

Conditional likelihood the spike train response at a single timestep

MODIFIED ARGUMENT
-`p`: a matrix whose element `p[i,j]` represents the likelihood conditioned on the accumulator in the i-th state and the coupling in the j-th state

UNMODIFIED ARGUMENT
-`mpGLM`:a structure with information on the mixture of Poisson GLM of a neuron
-`t`: timestep
"""
function conditionallikelihood!(p::Matrix{<:Real}, mpGLM::MixturePoissonGLM, t::Integer)
	@unpack Î”t, dğ›_dB, Î¸, ğ•, ğ—, ğ² = mpGLM
	@unpack ğ®, ğ¯ = Î¸
	ğ”â‚œğ® = 0
	for i in eachindex(ğ®)
		ğ”â‚œğ® += ğ—[t,i]*ğ®[i]
	end
	Î, K = size(p)
	for k=1:K
		ğ•â‚œğ¯ = 0
		for i in eachindex(ğ¯[k])
			ğ•â‚œğ¯ += ğ•[t,i]*ğ¯[k][i]
		end
		for j=1:Î
			L = ğ”â‚œğ® + dğ›_dB[j]*ğ•â‚œğ¯
			p[j,k] = poissonlikelihood(Î”t, L, ğ²[t])
		end
	end
	return nothing
end

"""
    CVIndices(model, kfold)

Create indices for cross-validation

ARGUMENT
-`model`: a structure containing the settings, data, and parameters of a factorial hidden-Markov drift-diffusion model
-`kfold`: number of cross-validation folds

OUTPUT
-a vector of instances of `CVIndices`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
```
"""
function CVIndices(model::Model,
                   kfold::integertype) where {integertype<:Integer}
    testingtrials = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    trainingtrials = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    testingtimesteps = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    trainingtimesteps = map(k->map(trialset->integertype[], model.trialsets), 1:kfold)
    for i in eachindex(model.trialsets)
        ntrials = length(model.trialsets[i].trials)
        ntestingtrials = cld(ntrials, kfold)
        partitionedtrials = collect(Base.Iterators.partition(shuffle(1:ntrials), ntestingtrials))
        timesteps = map(trial->collect(1:trial.ntimesteps), model.trialsets[i].trials)
        count = 0
        for m in eachindex( model.trialsets[i].trials)
            timesteps[m] .+= count
            count +=  model.trialsets[i].trials[m].ntimesteps
        end
        for k=1:kfold
            testingtrials[k][i] = sort(partitionedtrials[k])
            trainingtrials[k][i] = sort(vcat(partitionedtrials[vcat(1:k-1, k+1:kfold)]...))
            testingtimesteps[k][i] =  vcat(timesteps[testingtrials[k][i]]...)
            trainingtimesteps[k][i] =  vcat(timesteps[trainingtrials[k][i]]...)
        end
    end
    map(1:kfold,
        trainingtrials,
        testingtrials,
        trainingtimesteps,
        testingtimesteps) do    k,
                                trainingtrials,
                                testingtrials,
                                trainingtimesteps,
                                testingtimesteps
        CVIndices(trainingtrials = trainingtrials,
                  testingtrials = testingtrials,
                  trainingtimesteps = trainingtimesteps,
                  testingtimesteps = testingtimesteps)
    end
end

"""
    trainingset(cvindices, trialsets)

Subsample the data for training

ARGUMENT
-`cvindices`: an instance of `CVIndices`
-`trialsets`: a vector of instances of `Trialset`

OUTPUT
- a vector of instances of `Trialset`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
julia> first_training_set = trainingset(cvindices[1], model.trialsets)
```
"""
function trainingset(cvindices::CVIndices, trialsets::Vector{<:Trialset})
    map(trialsets, cvindices.trainingtrials, cvindices.trainingtimesteps) do trialset, trainingtrials, trainingtimesteps
        subsample(trialset, trainingtrials, trainingtimesteps)
    end
end

"""
    testingset(cvindices, trialsets)

Subsample the data for testing

ARGUMENT
-`cvindices`: an instance of `CVIndices`
-`trialsets`: a vector of instances of `Trialset`

OUTPUT
- a vector of instances of `Trialset`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_02_18_test/data.mat")
julia> cvindices = CVIndices(model, 5)
julia> first_testing_set = testingset(cvindices[1], model.trialsets)
```
"""
function testingset(cvindices::CVIndices, trialsets::Vector{<:Trialset})
    map(trialsets, cvindices.testingtrials, cvindices.testingtimesteps) do trialset, testingtrials, testingtimesteps
        subsample(trialset, testingtrials, testingtimesteps)
    end
end

"""
    subsample(trialset, trialindices, timesteps)

Create an instance of `Trialset` by subsampling

ARGUMENT
-`trialset`: a structure corresponding to a collection of trials in which the same neurons werre recorded
-`trialindices`: a vector of integers indexing the trials to include
-`timesteps`: a vector of integers indexing the timesteps of spiketrains to include

OUTPUT
- an instance of `Trialset`
"""
function subsample(trialset::Trialset,
                   trialindices::Vector{<:Integer},
                   timesteps::Vector{<:Integer})
    Trialset(trials = trialset.trials[trialindices],
             mpGLMs = map(mpGLM->subsample(mpGLM, timesteps), trialset.mpGLMs))
end

"""
    subsample(mpGLM, timesteps)

Create a mixture of Poisson GLM by subsampling the spike train of a neuron

ARGUMENT
-`mpGLM`: a structure with information on the mixture of Poisson GLM of a neuron
-`timesteps`: a vector of integers indexing the timesteps to include

OUTPUT
-an instance of `MixturePoissonGLM`
"""
function subsample(mpGLM::MixturePoissonGLM, timesteps::Vector{<:Integer})
    MixturePoissonGLM(Î”t = mpGLM.Î”t,
                        dğ›_dB = mpGLM.dğ›_dB,
						max_spikehistory_lag = mpGLM.max_spikehistory_lag,
						Î¦ = mpGLM.Î¦,
						Î¸ = GLMÎ¸(mpGLM.Î¸, eltype(mpGLM.Î¸.ğ®)),
                        ğ• = mpGLM.ğ•[timesteps, :],
                        ğ— = mpGLM.ğ—[timesteps, :],
                        ğ² =mpGLM.ğ²[timesteps])
end
