"""
	MixturePoissonGLM(concatenatedÎ¸, mpGLM)

Create a structure for a mixture of Poisson GLM with updated parameters

ARGUMENT
-`concatenatedÎ¸`: a vector of new parameter values
-`mpGLM`: a structure containing information on the mixture of Poisson GLM for one neuron

OUTPUT
-a new structure for the mixture of Poisson GLM of a neuron with new parameter values
"""
function MixturePoissonGLM(concatenatedÎ¸::Vector{<:Real}, mpGLM::MixturePoissonGLM; offset::Integer=0, initialization::Bool=false)
	values = map(fieldnames(MixturePoissonGLM)) do fieldname
				if fieldname == :Î¸
					GLMÎ¸(mpGLM.Î¸, concatenatedÎ¸; offset=offset, initialization=initialization)
				else
					getfield(mpGLM, fieldname)
				end
			end
	return MixturePoissonGLM(values...)
end

"""
    linearpredictor(mpGLM, j, k)

Linear combination of the weights in the j-th accumulator state and k-th coupling state

ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model of one neuron
-`j`: state of the accumulator variable
-`k`: state of the coupling variable

RETURN
-`ð‹`: a vector whose element ð‹[t] corresponds to the t-th time bin in the trialset
"""
function linearpredictor(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î¸, ð— = mpGLM
    @unpack ð , ð® = Î¸
	gâ‚– = ð [min(length(ð ), k)]
	ð° = evidenceweight(j, k, mpGLM)
	ð—*vcat(gâ‚–, ð®, ð°)
end

"""
	evidenceweight(j,k,mpGLM)

Encoding weight of the accumulated evidence conditioned on the states of the latent variables

ARGUMENT
-`j`: state of the accumulator variable
-`k`: state of the coupling variable
-`mpGLM`: the mixture of Poisson generalized linear model of one neuron

RETURN
-`ð°`: vector representing the encoding weight of accumulated evidence
"""
function evidenceweight(j::Integer, k::Integer, mpGLM::MixturePoissonGLM)
	@unpack dð›_dB, Îž = mpGLM
    @unpack b, b_scalefactor, ð¯, Î”ð¯, fit_Î”ð¯ = mpGLM.Î¸
	káµ¥ = min(length(ð¯), k)
	if (j == 1 || j == Îž) && fit_Î”ð¯
		ð¯â‚– = ð¯[káµ¥] .+ Î”ð¯[káµ¥]
	else
		ð¯â‚– = ð¯[káµ¥]
	end
	if b != 0.0
		ð¯â‚–.*transformaccumulator(b[1]*b_scalefactor, dð›_dB[j])
	else
		ð¯â‚–.*dð›_dB[j]
	end
end

"""
	conditionallikelihood!(p, mpGLM, Ï„)

Conditional likelihood the spike train response at a single timestep

MODIFIED ARGUMENT
-`p`: a matrix whose element `p[i,j]` represents the likelihood conditioned on the accumulator in the i-th state and the coupling in the j-th state

UNMODIFIED ARGUMENT
-`mpGLM`:a structure with information on the mixture of Poisson GLM of a neuron
-`Ï„`: timestep among time steps concatenated across all trials in a trialset
"""
function conditionallikelihood!(p::Matrix{<:Real}, mpGLM::MixturePoissonGLM, Ï„::Integer)
	@unpack Î”t, Î¸, ð•, ð—, ð—columns_gain, ð² = mpGLM
	@unpack ð , ð® = Î¸
	Gâ‚œ = ð—[Ï„,ð—columns_gain]
	ð”â‚œð® = 0
	offsetð” = maximum(ð—columns_gain)
	for i in eachindex(ð®)
		q = offsetð” + i
		ð”â‚œð® += ð—[Ï„,q]*ð®[i]
	end
	Îž, K = size(p)
	Kð  = length(ð )
	for k=1:K
		gâ‚– = ð [min(k,Kð )]
		Gâ‚œgâ‚– = Gâ‚œâ‹…gâ‚–
		for j=1:Îž
			ð° = evidenceweight(j,k,mpGLM)
			L = Gâ‚œgâ‚– + ð”â‚œð® + ð•[Ï„,:]â‹…ð°
			p[j,k] = poissonlikelihood(Î”t, L, ð²[Ï„])
		end
	end
	return nothing
end

"""
    scaledlikelihood(mpGLM, j, k, s)

Conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`ð©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against
"""
function scaledlikelihood(mpGLM::MixturePoissonGLM, j::Integer, k::Integer, s::Real)
    @unpack Î”t, ð² = mpGLM
    ð‹ = linearpredictor(mpGLM, j, k)
    ð© = ð‹
    @inbounds for i=1:length(ð©)
        ð©[i] = scaledpoissonlikelihood(Î”t, ð‹[i], s, ð²[i])
    end
    return ð©
end

"""
    scaledlikelihood!(ð©, mpGLM, j, k, s)

In-place multiplication of `ð©` by the conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

MODIFIED ARGUMENT
-`ð©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`nothing`
"""
function scaledlikelihood!(ð©::Vector{<:Real}, mpGLM::MixturePoissonGLM, j::Integer, k::Integer, s::Real)
    @unpack Î”t, ð² = mpGLM
    ð‹ = linearpredictor(mpGLM, j, k)
    @inbounds for i=1:length(ð©)
		ð©[i] *= scaledpoissonlikelihood(Î”t, ð‹[i], s, ð²[i])
    end
    return nothing
end

"""
	expectation_âˆ‡loglikelihood!(âˆ‡Q, Î³, mpGLM)

Expectation under the posterior probability of the gradient of the log-likelihood.

This function is used for computing the gradient of the log-likelihood of the entire model

MODIFIED ARGUMENT
-`âˆ‡`: The gradient

UNMODIFIED ARGUMENT
-`Î³`: Joint posterior probability of the accumulator and coupling variable. Î³[i,k][t] corresponds to the i-th accumulator state and the k-th coupling state in the t-th time bin in the trialset.
-`mpGLM`: structure containing information for the mixture of Poisson GLM for one neuron
"""
function expectation_âˆ‡loglikelihood!(âˆ‡Q::GLMÎ¸, Î³::Matrix{<:Vector{<:Real}}, mpGLM::MixturePoissonGLM)
	@unpack Î”t, ð•, ð—, Îž, ð² = mpGLM
	@unpack ð¯ = mpGLM.Î¸
	ð›š = transformaccumulator(mpGLM)
	dð›š_db = dtransformaccumulator(mpGLM)
	Îž, K = size(Î³)
	T = length(ð²)
	âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚– = collect(zeros(T) for k=1:K)
	âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢ = collect(zeros(T) for k=1:K)
	if âˆ‡Q.fit_b
		âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÏ‰áµ¢_db = collect(zeros(T) for k=1:K)
	end
	if âˆ‡Q.fit_Î”ð¯
		âˆ‘_bounds_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢ = collect(zeros(T) for k=1:K)
	end
	@inbounds for k = 1:K
		for i = 1:Îž
			ð‹ = linearpredictor(mpGLM,i,k)
			for t=1:T
				dQáµ¢â‚–_dLáµ¢â‚– = Î³[i,k][t] * differentiate_loglikelihood_wrt_linearpredictor(Î”t, ð‹[t], ð²[t])
				âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–[k][t] += dQáµ¢â‚–_dLáµ¢â‚–
				âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢[k][t] += dQáµ¢â‚–_dLáµ¢â‚–*ð›š[i]
				if âˆ‡Q.fit_Î”ð¯ && (i==1 || i==Îž)
					âˆ‘_bounds_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢[k][t] += dQáµ¢â‚–_dLáµ¢â‚–*ð›š[i]
				end
				if âˆ‡Q.fit_b
					âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÏ‰áµ¢_db[k][t] += dQáµ¢â‚–_dLáµ¢â‚–*dð›š_db[i]
				end
			end
		end
	end
	ð” = @view ð—[:, 2:1+length(âˆ‡Q.ð®)]
	âˆ‘áµ¢â‚–_dQáµ¢â‚–_dLáµ¢â‚– = sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–)
    âˆ‡Q.ð® .= ð”' * âˆ‘áµ¢â‚–_dQáµ¢â‚–_dLáµ¢â‚–
	@inbounds for k = 2:length(âˆ‡Q.ð )
		âˆ‡Q.ð [k] = sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–[k])
	end
	if length(âˆ‡Q.ð¯) == K
		@inbounds for k = 1:K
			mul!(âˆ‡Q.ð¯[k], ð•', âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢[k])
		end
	else
		mul!(âˆ‡Q.ð¯[1], ð•', sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢))
	end
	if âˆ‡Q.fit_b
		if length(âˆ‡Q.ð¯) == K
			âˆ‡Q.b[1] = 0.0
			@inbounds for k = 1:K
				âˆ‡Q.b[1] += dot(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÏ‰áµ¢_db[k], ð•, ð¯[k])
			end
		else
			âˆ‡Q.b[1] = dot(sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÏ‰áµ¢_db), ð•, ð¯[k])
		end
	end
	if âˆ‡Q.fit_Î”ð¯
		if length(âˆ‡Q.Î”ð¯) == K
			@inbounds for k = 1:K
				mul!(âˆ‡Q.Î”ð¯[k], ð•', âˆ‘_bounds_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢[k])
			end
		else
			mul!(âˆ‡Q.Î”ð¯[1], ð•', sum(âˆ‘_bounds_dQáµ¢â‚–_dLáµ¢â‚–â¨€Ï‰áµ¢))
		end
	end
	return nothing
end

"""
    expectation_of_loglikelihood(Î³, mpGLM, x)

ForwardDiff-compatible computation of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

Ignores the log(y!) term, which does not depend on the parameters

ARGUMENT
-`Î³`: posterior probability of the latent variable
-`mpGLM`: the GLM of one neuron
-`x`: weights of the linear filters of the GLM concatenated as a vector of floating-point numbers

RETURN
-expectation of the log-likelihood of the spike train of one neuron
"""
function expectation_of_loglikelihood(Î³::Matrix{<:Vector{<:AbstractFloat}}, mpGLM::MixturePoissonGLM, x::Vector{<:Real}; initialization::Bool=false)
	mpGLM = FHMDDM.MixturePoissonGLM(x, mpGLM; initialization=initialization)
    @unpack Î”t, ð² = mpGLM
    T = length(ð²)
    Îž,K = size(Î³)
    Q = 0.0
    @inbounds for i = 1:Îž
	    for k = 1:K
			ð‹ = linearpredictor(mpGLM,i,k)
            for t = 1:T
				Q += Î³[i,k][t]*poissonloglikelihood(Î”t, ð‹[t], ð²[t])
            end
        end
    end
    return Q
end

"""
	âˆ‡negativeloglikelihood!(âˆ‡nâ„“, âˆ‡â„“glms, offset)

Concatenate the first-order partial derivatives of the model's log-likelihood w.r.t. to the parameters in each neuron's GLM

MODIFIED ARGUMENT
-`âˆ‡nâ„“`: a vector representing the gradient of the model's log-likelihood

UNMODIFIED ARGUMENT
-`âˆ‡â„“glm`: a nested vector of the partial derivatives of the model's log-likelihood w.r.t. to the  parameter of each neuron's mixture of Poisson GLM. Element `âˆ‡â„“glms[i][n]` corresponds to the n-th neuron in the i-th trialset
-`offset`: the number of elements at beginning of `âˆ‡nâ„“` that are unrelated to the GLM's
"""
function âˆ‡negativeloglikelihood!(âˆ‡nâ„“::Vector{<:Real}, âˆ‡â„“glm::Vector{<:Vector{<:GLMÎ¸}}, offset::Integer)
	counter = offset
	for âˆ‡â„“glm in âˆ‡â„“glm
		for âˆ‡â„“glm in âˆ‡â„“glm
			if âˆ‡â„“glm.fit_b
				counter+=1
				âˆ‡nâ„“[counter] = -âˆ‡â„“glm.b[1]
			end
			for k = 2:length(âˆ‡â„“glm.ð )
				counter+=1
				âˆ‡nâ„“[counter] = -âˆ‡â„“glm.ð [k]
			end
			for u in âˆ‡â„“glm.ð®
				counter+=1
				âˆ‡nâ„“[counter] = -u
			end
			for ð¯â‚– in âˆ‡â„“glm.ð¯
				for v in ð¯â‚–
					counter+=1
					âˆ‡nâ„“[counter] = -v
				end
			end
			if âˆ‡â„“glm.fit_Î”ð¯
				for Î”ð¯â‚– in âˆ‡â„“glm.Î”ð¯
					for Î”v in Î”ð¯â‚–
						counter+=1
						âˆ‡nâ„“[counter] = -Î”v
					end
				end
			end
		end
	end
	return nothing
end

"""
	postspikefilter(mpGLM)

Return a vector representing the post-spike filter of a Poisson mixture GLM.

The first element of the vector corresponds to the first time step after the spike.
"""
function postspikefilter(mpGLM::MixturePoissonGLM)
	@unpack Î¦â‚•, Î¸ = mpGLM
	@unpack ð®, ð®indices_hist = Î¸
	return Î¦â‚•*ð®[ð®indices_hist]
end

"""
	externalinput(mpGLM)

Sum the input from extern events for each time step in a trialset.

The external events typically consist of the stereoclick, departure from the center port, and the photostimulus.

RETURN
-a vector whose Ï„-th element corresponds to the Ï„-th time step in the trialset
"""
function externalinput(mpGLM::MixturePoissonGLM)
	@unpack ð—, ð—columns_time, ð—columns_move, ð—columns_phot, Î¸ = mpGLM
	@unpack ð®, ð®indices_time, ð®indices_move, ð®indices_phot = Î¸
	ð„ = @view ð—[:,vcat(ð—columns_time, ð—columns_move, ð—columns_phot)]
	ðž = ð®[vcat(ð®indices_time, ð®indices_move, ð®indices_phot)]
	return ð„*ðž
end

"""
    subsample(mpGLM, timesteps)

Create a mixture of Poisson GLM by subsampling the spike train of a neuron

ARGUMENT
-`mpGLM`: a structure with information on the mixture of Poisson GLM of a neuron
-`timesteps`: a vector of integers indexing the timesteps to include

OUTPUT
-an instance of `MixturePoissonGLM`
"""
function subsample(mpGLM::MixturePoissonGLM, timesteps::Vector{<:Integer})
    MixturePoissonGLM(Î”t = mpGLM.Î”t,
                        dð›_dB = mpGLM.dð›_dB,
						Î¦â‚ = mpGLM.Î¦â‚,
						Î¦â‚• = mpGLM.Î¦â‚•,
						Î¦â‚˜ = mpGLM.Î¦â‚˜,
						Î¦â‚š = mpGLM.Î¦â‚š,
						Î¦â‚štimesteps = mpGLM.Î¦â‚štimesteps,
						Î¦â‚œ = mpGLM.Î¦â‚œ,
						Î¸ = FHMDDM.copy(mpGLM.Î¸),
                        ð• = mpGLM.ð•[timesteps, :],
                        ð— = mpGLM.ð—[timesteps, :],
                        ð² =mpGLM.ð²[timesteps])
end
