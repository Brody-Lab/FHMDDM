"""
	fit_basic_glms!(model)

Fit a generalized linear model without association to any latent variable to each neuron's spike train

The accumulator-related modulation is set to be 0, and the coupling probability is set to be 1

MODIFIED ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a drift-diffusion coupled generalized linear model
"""
function fit_basic_glms!(model::Model)
	for trialset in model.trialsets
		for mpGLM in trialset.mpGLMs
			@assert mpGLM.Î¸.c_u == 1.0
			mpGLM.Î¸.c[1] = Inf
			mpGLM.Î¸.v[1] = 0
			mpGLM.Î¸.Î²[1] = 0
			maximizelikelihood!(mpGLM)
			basicglm = PoissonGLM(Î”t=mpGLM.Î”t, ğ—=mpGLM.ğ—[:,1:end-1], ğ²=mpGLM.ğ²)
			maximizelikelihood!(basicglm)
			mpGLM.Î¸.ğ® .= basicglm.ğ°
		end
	end
end

"""
    maximizelikelihood!(glm::PoissonGLM)

Learn the maximum likelihood parameters of a Poisson generalized linear model
"""
function maximizelikelihood!(glm::PoissonGLM; iterations::Integer=20)
    f(ğ°) = negativeloglikelihood!(glm, ğ°)
    âˆ‡f!(âˆ‡, ğ°) = âˆ‡negativeloglikelihood!(âˆ‡, glm, ğ°)
    âˆ‡âˆ‡f!(âˆ‡âˆ‡, ğ°) = âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡, glm, ğ°)
    results = Optim.optimize(f, âˆ‡f!, âˆ‡âˆ‡f!, rand(size(glm.ğ—,2)), NewtonTrustRegion(), Optim.Options(iterations=20))
	glm.ğ° .= Optim.minimizer(results)
	return nothing
end

"""
	negativeloglikelihood!(glm,ğ°)

Negative log-likelihood of the model given projection weights `ğ°`

The object `glm` is modified if `ğ°` differs from `glm.ğ°`
"""
function negativeloglikelihood!(glm::PoissonGLM, ğ°::Vector{<:Real})
    update!(glm, ğ°)
    -glm.â„“[1]
end

"""
	âˆ‡negativeloglikelihood!(âˆ‡, glm, ğ°)

Compute in `âˆ‡` the gradient of the negative of the log-likelihood with respect to `ğ°`
"""
function âˆ‡negativeloglikelihood!(âˆ‡::Vector{<:AbstractFloat}, glm::PoissonGLM, ğ°::Vector{<:Real})
    update!(glm, ğ°)
    for i in eachindex(âˆ‡)
        âˆ‡[i] = -glm.âˆ‡â„“[i]
    end
	return nothing
end

"""
	âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡, glm, ğ°)

Compute in `âˆ‡âˆ‡` the hessian of the negative of the log-likelihood with respect to `ğ°`
"""
function âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡::Matrix{<:AbstractFloat}, glm::PoissonGLM, ğ°::Vector{<:Real})
    update!(glm, ğ°)
    for i in eachindex(âˆ‡âˆ‡)
        âˆ‡âˆ‡[i] = -glm.âˆ‡âˆ‡â„“[i]
    end
	return nothing
end

"""
	update!(glm::PoissonGLM, ğ°)
"""
function update!(glm::PoissonGLM, ğ°::Vector{<:Real})
	if (ğ° != glm.ğ°) || isnan(glm.â„“[1])
		glm.ğ° .= ğ°
		âˆ‡âˆ‡loglikelihood!(glm)
	end
end

"""
	âˆ‡âˆ‡loglikelihood!(glm)

Compute the log-likelihood of a Poisson GLM, its gradient, and its hessian

EXAMPLE
```julia-repl
julia> using FHMDDM, ForwardDiff, Random
julia> Random.seed!(1234)
julia> ğ°â‚€ = rand(10);
julia> glm = FHMDDM.PoissonGLM(Î”t=0.01, ğ—=rand(100,10), ğ² = floor.(Int, rand(100).*3), ğ° = ğ°â‚€)
julia> FHMDDM.âˆ‡âˆ‡loglikelihood!(glm)
julia> f(x) = FHMDDM.loglikelihood(glm, x)
julia> fauto = f(ğ°â‚€)
julia> gauto = ForwardDiff.gradient(f, ğ°â‚€)
julia> hauto = ForwardDiff.hessian(f, ğ°â‚€)
julia> println("   |Î”â„“|: ", abs(fauto-glm.â„“[1]))
julia> println("   max(|Î”gradient|): ", maximum(abs.(gauto.-glm.âˆ‡â„“)))
julia> println("   max(|Î”hessian|): ", maximum(abs.(hauto.-glm.âˆ‡âˆ‡â„“)))
```
"""
function âˆ‡âˆ‡loglikelihood!(glm::PoissonGLM)
	@unpack Î”t, â„“, âˆ‡â„“, âˆ‡âˆ‡â„“, ğ°, ğ—, ğ² = glm
    ğ‹ = ğ—*ğ°
    dÂ²ğ¥_dğ‹Â², dğ¥_dğ‹, ğ¥ = similar(ğ‹), similar(ğ‹), similar(ğ‹)
    for t in eachindex(ğ‹)
        dÂ²ğ¥_dğ‹Â²[t], dğ¥_dğ‹[t], ğ¥[t] = differentiate_twice_loglikelihood_wrt_linearpredictor(Î”t, ğ‹[t], ğ²[t])
    end
    â„“ .= sum(ğ¥)
    âˆ‡â„“ .= ğ—'*dğ¥_dğ‹
    âˆ‡âˆ‡â„“ .= ğ—'*(dÂ²ğ¥_dğ‹Â².*ğ—)
	return nothing
end

"""
	loglikelihood(glm::PoissonGLM)
"""
loglikelihood(glm::PoissonGLM) = loglikelihood(glm, glm.ğ°)

"""
	loglikelihood(glm, ğ°)

ForwardDiff-compatible computation of Poisson log-likelihood
"""
function loglikelihood(glm::PoissonGLM, ğ°::Vector{<:Real})
	ğ‹ = glm.ğ—*ğ°
	â„“ = 0
	for (L,y) in zip(ğ‹,glm.ğ²)
		â„“ += log(poissonlikelihood(glm.Î”t, L, y))
	end
	return â„“
end

"""
	loglikelihood(Î”t, kfold, ğ—, ğ²)

Out-of-sample log-likelihood of a basic Poisson GLM

ARGUMENT
-`glm`: an object containing the quantities of a basic GLM
-`kfold`: number of cross-validation folds
"""
function loglikelihood(glm::PoissonGLM, kfold::Integer)
	@unpack Î”t, ğ—, ğ² = glm
    testindices, trainindices = cvpartition(kfold, size(ğ—,1))
	â„“ = 0
	for k = 1:kfold
		trainglm = PoissonGLM(Î”t=Î”t, ğ—=ğ—[trainindices[k],:], ğ²=ğ²[trainindices[k]])
		maximizelikelihood!(trainglm)
		testglm = PoissonGLM(Î”t=Î”t, ğ°=trainglm.ğ°, ğ—=ğ—[testindices[k],:], ğ²=ğ²[testindices[k]])
		â„“ += loglikelihood(testglm)
	end
	return â„“
end
