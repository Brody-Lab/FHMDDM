"""
	fit_basic_glms!(model)

Fit a generalized linear model without association to any latent variable to each neuron's spike train

The accumulator-related modulation is set to be 0, and the coupling probability is set to be 1

MODIFIED ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a drift-diffusion coupled generalized linear model
"""
function fit_basic_glms!(model::Model)
	for trialset in model.trialsets
		for mpGLM in trialset.mpGLMs
			@assert mpGLM.Î¸.c_u == 1.0
			mpGLM.Î¸.c[1] = Inf
			mpGLM.Î¸.v[1] = 0
			mpGLM.Î¸.Î²[1] = 0
			maximizeloglikelihood!(mpGLM)
		end
	end
end

"""
	maximizeloglikelihood!(mpGLM)

Learn the weights of the latent variable-independent inputs
"""
function maximizeloglikelihood!(mpGLM::MixturePoissonGLM)
	mpGLM.Î¸.ğ® .= maximizeloglikelihood(mpGLM.Î”t, mpGLM.ğ—[:,1:end-1], mpGLM.ğ²)
end

"""
    maximizeloglikelihood(Î”t, ğ—, ğ²)

Learn the projection weights that maximize the log-likelihood of poisson observations

ARGUMENT
-`Î”t`: time step duration, in seconds
-`ğ—`: design matrix. Rows correspond to samples, and columns to regressors

RETURN
-optimal weights
"""
function maximizeloglikelihood(Î”t::AbstractFloat, ğ—::Matrix{<:AbstractFloat}, ğ²::Vector{<:Integer})
    derivatives = PoissonGLMDerivatives(Î”t=Î”t, ğ—=ğ—, ğ²=ğ²)
    f(ğ°) = negativeloglikelihood!(derivatives, ğ°)
    âˆ‡f!(âˆ‡, ğ°) = âˆ‡negativeloglikelihood!(âˆ‡, derivatives, ğ°)
    âˆ‡âˆ‡f!(âˆ‡âˆ‡, ğ°) = âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡, derivatives, ğ°)
    results = Optim.optimize(f, âˆ‡f!, âˆ‡âˆ‡f!, rand(size(ğ—,2)), NewtonTrustRegion())
	Optim.minimizer(results)
end

"""
	negativeloglikelihood!(derivatives,ğ°)

Negative log-likelihood of the model given projection weights `ğ°`

The object `derivatives` is modified if `ğ°` differs from `derivatives.ğ°`
"""
function negativeloglikelihood!(derivatives::PoissonGLMDerivatives, ğ°::Vector{<:Real})
    if (ğ° != derivatives.ğ°) || isnan(derivatives.â„“[1])
        derivatives.ğ° .= ğ°
        âˆ‡âˆ‡loglikelihood!(derivatives)
    end
    -derivatives.â„“[1]
end

"""
	âˆ‡negativeloglikelihood!(âˆ‡, derivatives, ğ°)

Compute in `âˆ‡` the gradient of the negative of the log-likelihood with respect to `ğ°`
"""
function âˆ‡negativeloglikelihood!(âˆ‡::Vector{<:AbstractFloat}, derivatives::PoissonGLMDerivatives, ğ°::Vector{<:Real})
    if (ğ° != derivatives.ğ°) || isnan(derivatives.â„“[1])
        derivatives.ğ° .= ğ°
        âˆ‡âˆ‡loglikelihood!(derivatives)
    end
    for i in eachindex(âˆ‡)
        âˆ‡[i] = -derivatives.âˆ‡â„“[i]
    end
end

"""
	âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡, derivatives, ğ°)

Compute in `âˆ‡âˆ‡` the hessian of the negative of the log-likelihood with respect to `ğ°`
"""
function âˆ‡âˆ‡negativeloglikelihood!(âˆ‡âˆ‡::Matrix{<:AbstractFloat}, derivatives::PoissonGLMDerivatives, ğ°::Vector{<:Real})
    if (ğ° != derivatives.ğ°) || isnan(derivatives.â„“[1])
        derivatives.ğ° .= ğ°
        âˆ‡âˆ‡loglikelihood!(derivatives)
    end
    for i in eachindex(âˆ‡âˆ‡)
        âˆ‡âˆ‡[i] = -derivatives.âˆ‡âˆ‡â„“[i]
    end
end

"""
	âˆ‡âˆ‡loglikelihood!(derivatives)

Compute the log-likelihood of a Poisson GLM, its gradient, and its hessian

EXAMPLE
```julia-repl
julia> using FHMDDM, ForwardDiff, Random
julia> Random.seed!(1234)
julia> ğ°â‚€ = rand(10);
julia> derivatives = FHMDDM.PoissonGLMDerivatives(Î”t=0.01, ğ—=rand(100,10), ğ² = floor.(Int, rand(100).*3), ğ° = ğ°â‚€)
julia> FHMDDM.âˆ‡âˆ‡loglikelihood!(derivatives)
julia> f(x) = FHMDDM.loglikelihood(derivatives, x)
julia> fauto = f(ğ°â‚€)
julia> gauto = ForwardDiff.gradient(f, ğ°â‚€)
julia> hauto = ForwardDiff.hessian(f, ğ°â‚€)
julia> println("   |Î”â„“|: ", abs(fauto-derivatives.â„“[1]))
julia> println("   max(|Î”gradient|): ", maximum(abs.(gauto.-derivatives.âˆ‡â„“)))
julia> println("   max(|Î”hessian|): ", maximum(abs.(hauto.-derivatives.âˆ‡âˆ‡â„“)))
```
"""
function âˆ‡âˆ‡loglikelihood!(derivatives::PoissonGLMDerivatives)
	@unpack Î”t, â„“, âˆ‡â„“, âˆ‡âˆ‡â„“, ğ°, ğ—, ğ² = derivatives
    ğ‹ = ğ—*ğ°
    dÂ²ğ¥_dğ‹Â², dğ¥_dğ‹, ğ¥ = similar(ğ‹), similar(ğ‹), similar(ğ‹)
    for t in eachindex(ğ‹)
        dÂ²ğ¥_dğ‹Â²[t], dğ¥_dğ‹[t], ğ¥[t] = differentiate_twice_loglikelihood_wrt_linearpredictor(Î”t, ğ‹[t], ğ²[t])
    end
    â„“ .= sum(ğ¥)
    âˆ‡â„“ .= ğ—'*dğ¥_dğ‹
    âˆ‡âˆ‡â„“ .= ğ—'*(dÂ²ğ¥_dğ‹Â².*ğ—)
	return nothing
end

"""
	loglikelihood(derivatives, ğ°)

ForwardDiff-compatible computation of Poisson log-likelihood
"""
function loglikelihood(derivatives::PoissonGLMDerivatives, ğ°::Vector{<:Real})
	ğ‹ = derivatives.ğ—*ğ°
	â„“ = 0
	for (L,y) in zip(ğ‹,derivatives.ğ²)
		â„“ += poissonloglikelihood(derivatives.Î”t, L, y)
	end
	return â„“
end
