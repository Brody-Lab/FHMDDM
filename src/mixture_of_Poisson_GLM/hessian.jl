"""
    update_emissions!(memoryforhessian, mpGLMs, offset, sameacrosstrials, trial)

MODIFIED ARGUMENT
-`memoryforhessian`: a structure containing quantities used in each trial
-`mpGLMs`: vector whose each element is a structure containing the data and parameters of a mixture of Poisson GLM
-`sameacrosstrials`: structure containing intermediate quantities that are fixed across trials
-`trial`: structure containing the data of the trial being used for computation
"""
function update_emissions!(memoryforhessian::Memoryforhessian, mpGLMs::Vector{<:MixturePoissonGLM}, sameacrosstrials::Sameacrosstrials, trial::Trial)
    @unpack ntimesteps, Ï„â‚€, trialsetindex = trial
    ð‹ = memoryforhessian.ð‹[trialsetindex]
    ð›š = memoryforhessian.ð›š[trialsetindex]
	dð›š_db = memoryforhessian.dð›š_db[trialsetindex]
	dÂ²ð›š_dbÂ² = memoryforhessian.dÂ²ð›š_dbÂ²[trialsetindex]
    @unpack Î», âˆ‡logpy, âˆ‡âˆ‡logpy, pY, âˆ‡pY = memoryforhessian
    nÎ¸_py = sameacrosstrials.nÎ¸_py[trialsetindex]
    dL_dð¯ = zeros(length(mpGLMs[1].Î¸.ð¯[1]))
	@inbounds for n in eachindex(mpGLMs)
		conditionalrate!(Î»[n], ð‹[n], ntimesteps, Ï„â‚€)
		for t = 1:ntimesteps
			âˆ‡âˆ‡conditional_log_likelihood!(âˆ‡logpy[t][n], âˆ‡âˆ‡logpy[t][n], dL_dð¯, ð‹[n], Î»[n][t], mpGLMs[n], ð›š[n], dð›š_db[n], dÂ²ð›š_dbÂ²[n], t+Ï„â‚€)
		end
	end
	Îž = length(ð›š[1])
	K = length(mpGLMs[1].Î¸.ð¯)
	@inbounds for t = 1:ntimesteps
		for ij in eachindex(pY[t])
			pY[t][ij] = 1.0
			for n=1:nneurons
				pY[t][ij] *= poissonlikelihood(Î»[n][t][ij]*Î”t, mpGLMs[n].ð²[t+Ï„â‚€])
			end
		end
		r = 0
		for n=1:nneurons
			for q = 1:nÎ¸_py[n]
				r+=1
				for i=1:Îž
					for j=1:K
						âˆ‡pY[t][r][i,j] = âˆ‡logpy[t][n][q][i,j]*pY[t][i,j]
					end
				end
			end
		end
	end
	return nothing
end

"""
    linearpredictor(mpGLMs)

Linear combination of the weights in the j-th accumulator state and k-th coupling state

ARGUMENT
-`trialsets`: a vector of trialsets

RETURN
-`ð‹`: a nested array whose element ð‹[i][n][j,k][t] corresponds to i-th trialset, n-th neuron, j-th accumualtor state, k-th coupling state, and the t-th time bin in the trialset
"""
function linearpredictor(trialsets::Vector{<:Trialset})
    map(trialsets) do trialset
        map(trialset.mpGLMs) do mpGLM
            Îž = mpGLM.Îž
            K = length(mpGLM.Î¸.ð¯)
            map(CartesianIndices((Îž,K))) do index
                j = index[1]
                k = index[2]
                linearpredictor(mpGLM, j, k)
            end
        end
    end
end

"""
	conditionalrate!(Î», ð‹, offset)

MODIFIED ARGUMENT
-`Î»`: matrix whose element `Î»[t][i,j]` is the Poisson rate at the t-th timestep of a trial given the i-th accumulator state and j-th coupling state

UNMODIFIED ARGUMENT
-`ð‹`: matrix whose element `ð‹[i,j][Ï„]` is the linear predictor given the i-th accumulator state and j-th coupling state for the Ï„-timestep in the trialset
-`offset`: the time index in the trialset corresponding to the time index 0 in the trial
"""
function conditionalrate!(Î»::Vector{<:Matrix{<:Real}},
						  ð‹::Matrix{<:Vector{<:Real}},
						  ntimesteps::Integer,
						  offset::Integer)
	for t = 1:ntimesteps
		Ï„ = t + offset
		for jk in eachindex(Î»[t])
			Î»[t][jk] = softplus(ð‹[jk][Ï„])
		end
	end
	return nothing
end

"""
	âˆ‡âˆ‡conditional_log_likelihood!(âˆ‡logpy, âˆ‡âˆ‡logpy, dL_dð¯, ð‹, Î», mpGLM, Ï„)

Gradient and Hessian of the conditional log-likelihood of one neuron at single timestep

MODIFIED ARGUMENT
-`âˆ‡logpy`: Gradient of the conditional log-likelihood of a neuron's response at a single time. Element âˆ‡logpy[i][j,k] correponds to the partial derivative of log p{y(n,t) âˆ£ a(t)=Î¾(j), c(t)=k} with respect to the i-th parameter of the neuron's GLM
-`âˆ‡âˆ‡logpy`: Hessian of the conditional log-likelihood. Element âˆ‡âˆ‡logpy[i,j][k,l] correponds to the partial derivative of log p{y(n,t) âˆ£ a(t)=Î¾(k), c(t)=l} with respect to the i-th and j-th parameters of the neuron's GLM
-`dL_dð¯`: memory for computing the derivative of the linear predictor with respect to the linear filters of the accumulator. The element `dL_dð¯[q]` corresponds to the q-th linear filter in one of the coupling states.

UNMODIFIED ARGUMENT
-`Î±`: overdispersion parameter
-`Î”t`: width of time step
-`ð‹`: linear predictors. Element `ð‹[i,j][Ï„]` corresponds to the i-th accumulator state and j-th coupling state for the Ï„-timestep in the trialset
-`Î»`: Conditional Poisson whose element Î»[i,j] corresponds to a(t)=Î¾(i), c(t)=j
-`mpGLM`: a composite containing the data and parameters of a Poisson mixture generalized linear model
-`ð›š`: transformed values of the accumulator
-`dð›š_db`: first derivative of the transformed values of the accumulator with respect to the transformation parameter
-`dÂ²ð›š_dbÂ²`: second derivative of the transformed values of the accumulator with respect to the transformation parameter
-`Ï„` time step in the trialset
"""
function âˆ‡âˆ‡conditional_log_likelihood!(âˆ‡logpy::Vector{<:Matrix{<:Real}},
										âˆ‡âˆ‡logpy::Matrix{<:Matrix{<:Real}},
										dL_dð¯::Vector{<:Real},
										Î±::Real,
										ð‹::Matrix{<:Vector{<:Real}},
										Î»::Matrix{<:Real},
										mpGLM::MixturePoissonGLM,
										ð›š::Vector{<:Real},
										dð›š_db::Vector{<:Real},
										dÂ²ð›š_dbÂ²::Vector{<:Real},
										Ï„::Integer)
	@unpack Î”t, ð—, Îž, ð•, ð² = mpGLM
	@unpack b, ð®, ð¯, ð›ƒ, fit_ð›ƒ = mpGLM.Î¸
	K = length(ð¯)
	nð® = length(ð®)
	nð¯ = length(ð¯[1])
	indexb = nð® + 2*K*nð¯ + 1
	Vâ‚œáµ€ð¯ = zeros(K)
	for j = 1:K
		for q=1:nð¯
			Vâ‚œáµ€ð¯[j] += ð•[Ï„,q]*ð¯[j][q]
		end
	end
	for i = 1:Îž
		for m=1:nð¯
			dL_dð¯[m] = ð•[Ï„,m]*ð›š[i]
		end
		for j = 1:K
			dÂ²â„“_dLÂ², dâ„“_dL = FHMDDM.differentiate_twice_loglikelihood_wrt_linearpredictor(Î”t, ð‹[i,j][Ï„], Î»[i,j], ð²[Ï„])
			dL_db = Vâ‚œáµ€ð¯[j]*dð›š_db[i]
			dÂ²L_dbÂ² = Vâ‚œáµ€ð¯[j]*dÂ²ð›š_dbÂ²[i]
			offsetð¯ = nð® + (j-1)*nð¯
			offsetð›ƒ = nð® + (K+j-1)*nð¯
			for m=1:nð®
				âˆ‡logpy[m][i,j] = dâ„“_dL*ð—[Ï„,m]
			end
			offset = (fit_ð›ƒ && ((i==1) || (i==Îž))) ? offsetð›ƒ : offsetð¯
			for m=1:nð¯
				âˆ‡logpy[m+offset][i,j] = dâ„“_dL*dL_dð¯[m]
			end
			âˆ‡logpy[indexb][i,j] = dâ„“_dL*dL_db
			for m=1:nð®
				for n=m:nð®
					âˆ‡âˆ‡logpy[m,n][i,j] = dÂ²â„“_dLÂ²*ð—[Ï„,m]*ð—[Ï„,n]
				end
				for n=1:nð¯
					âˆ‡âˆ‡logpy[m,n+offset][i,j] = dÂ²â„“_dLÂ²*ð—[Ï„,m]*dL_dð¯[n]
				end
				âˆ‡âˆ‡logpy[m,indexb][i,j] = dÂ²â„“_dLÂ²*ð—[Ï„,m]*dL_db
			end
			for m=1:nð¯
				for n=m:nð¯
					âˆ‡âˆ‡logpy[m+offset, n+offset][i,j] = dÂ²â„“_dLÂ² * dL_dð¯[m] * dL_dð¯[n]
				end
				dÂ²L_dvdb = ð•[Ï„,m]*dð›š_db[i]
				âˆ‡âˆ‡logpy[m+offset,indexb][i,j] = dÂ²â„“_dLÂ²*dL_dð¯[m]*dL_db + dâ„“_dL*dÂ²L_dvdb
			end
			âˆ‡âˆ‡logpy[indexb,indexb][i,j] = dÂ²â„“_dLÂ²*dL_db^2 + dâ„“_dL*dÂ²L_dbÂ²
		end
	end
	return nothing
end
