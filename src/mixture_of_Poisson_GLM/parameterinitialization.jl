"""
	GLMÎ¸(options, ğ®indices_hist, ğ®indices_move, ğ®indices_time, ğ•)

Randomly initiate the parameters for a mixture of Poisson generalized linear model

ARGUMENT
-`options`: settings of the model
-`ğ®indices_hist`: indices in ğ® corresponding to the temporal basis functions of the postspike filter
-`ğ®indices_move`: indices in ğ® corresponding to the temporal basis functions of the premovement filter
-`ğ®indices_time`: indices in ğ® corresponding to the temporal basis functions of the time-in-trial filter
-`ğ•`: constant and time-varying inputs from the accumulator

OUTPUT
-an instance of `GLMÎ¸`
"""
function GLMÎ¸(options::Options, ğ®indices_hist::UnitRange{<:Integer}, ğ®indices_move::UnitRange{<:Integer}, ğ®indices_time::UnitRange{<:Integer}, ğ•::Matrix{<:AbstractFloat})
	nğ® = ğ®indices_move[end]
	nğ¯ =size(ğ•,2)
	Kğ  = options.gain_state_dependent ? options.K : 1
	Kğ¯ = options.tuning_state_dependent ? options.K : 1
	Î¸ = GLMÎ¸(b = fill(NaN,1),
			b_scalefactor = options.b_scalefactor,
			fit_b = options.fit_b,
			ğ  = fill(NaN, Kğ ),
			ğ® = fill(NaN, nğ®),
			ğ®indices_hist=ğ®indices_hist,
			ğ®indices_move=ğ®indices_move,
			ğ®indices_time=ğ®indices_time,
			ğ¯ = collect(fill(NaN,nğ¯) for k=1:Kğ¯))
	randomizeparameters!(Î¸)
	return Î¸
end

"""
	randomizeparameters!(Î¸)

Randomly initialize parameters of a mixture of Poisson GLM
"""
function randomizeparameters!(Î¸::GLMÎ¸)
	Î¸.b[1] = 0.0
	for i in eachindex(Î¸.ğ®)
		Î¸.ğ®[i] = 0.0 #1.0 .- 2rand()
	end
	Î¸.ğ [1] = 0.0
	for k = 2:length(Î¸.ğ )
		Î¸.ğ [k] = 1.0 .- 2rand()
	end
	if length(Î¸.ğ¯) > 1
		K = length(Î¸.ğ¯)
		ğ¯â‚€ = -0.01:0.02/(K-1):0.01
		for k = 1:K
			Î¸.ğ¯[k] .= ğ¯â‚€[k]
		end
	else
		Î¸.ğ¯[1] .= 0.0
	end
end

"""
	GLMÎ¸(glmÎ¸, elementtype)

Create an uninitialized instance of `GLMÎ¸` with the given element type.

This is for using ForwardDiff

ARGUMENT
-`glmÎ¸`: an instance of GLMÎ¸
-`elementtype`: type of the element in each field of GLMÎ¸

RETURN
-an instance of GLMÎ¸
"""
function GLMÎ¸(glmÎ¸::GLMÎ¸, elementtype)
	GLMÎ¸(b = zeros(elementtype, length(glmÎ¸.b)),
		b_scalefactor = glmÎ¸.b_scalefactor,
		fit_b = glmÎ¸.fit_b,
		ğ  = zeros(elementtype, length(glmÎ¸.ğ )),
		ğ® = zeros(elementtype, length(glmÎ¸.ğ®)),
		ğ¯ = collect(zeros(elementtype, length(ğ¯)) for ğ¯ in glmÎ¸.ğ¯),
		ğ®indices_hist = glmÎ¸.ğ®indices_hist,
		ğ®indices_time = glmÎ¸.ğ®indices_time,
		ğ®indices_move = glmÎ¸.ğ®indices_move)
end

"""
	FHMDDM.copy(glmÎ¸)

Make a copy of a structure containing the parameters of a mixture of Poisson GLM
"""
function FHMDDM.copy(glmÎ¸::GLMÎ¸)
	GLMÎ¸(b = copy(glmÎ¸.b),
		b_scalefactor = glmÎ¸.b_scalefactor,
		fit_b = glmÎ¸.fit_b,
		ğ  = copy(glmÎ¸.ğ ),
		ğ® = copy(glmÎ¸.ğ®),
		ğ¯ = collect(copy(ğ¯â‚–) for ğ¯â‚– in glmÎ¸.ğ¯),
		ğ®indices_hist = copy(glmÎ¸.ğ®indices_hist),
		ğ®indices_time = copy(glmÎ¸.ğ®indices_time),
		ğ®indices_move = copy(glmÎ¸.ğ®indices_move))
end

"""
	initialize(glmÎ¸)

Create an uninitialized instance of `GLMÎ¸`
"""
initialize(glmÎ¸::GLMÎ¸) = GLMÎ¸(glmÎ¸, eltype(glmÎ¸.ğ®))

"""
	initialize_GLM_parameters!(model)

Initialize the GLM parameters

MODIFIED ARGUMENT
-`model`: an instance of the factorial hidden Markov drift-diffusion model
"""
function initialize_GLM_parameters!(model::Model; show_trace::Bool=false)
	memory = FHMDDM.Memoryforgradient(model)
	choiceposteriors!(memory, model)
	for i in eachindex(model.trialsets)
	    for mpGLM in model.trialsets[i].mpGLMs
	        maximize_expectation_of_loglikelihood!(mpGLM, memory.Î³[i]; show_trace=show_trace)
	    end
	end
	if model.options.gain_state_dependent
		for i in eachindex(model.trialsets)
		    for mpGLM in model.trialsets[i].mpGLMs
		        for k = 2:length(mpGLM.Î¸.ğ )
					mpGLM.Î¸.ğ [k] = 1-2rand()
				end
		    end
		end
	end
	if model.options.tuning_state_dependent
		for i in eachindex(model.trialsets)
			for mpGLM in model.trialsets[i].mpGLMs
				vmean = mean(mpGLM.Î¸.ğ¯)
				mpGLM.Î¸.ğ¯[1] .= 3.0.*vmean
				mpGLM.Î¸.ğ¯[2] .= -vmean
			end
		end
	end
end

"""
	maximize_expectation_of_loglikelihood!(mpGLM, Î³)

Learn the filters of a Poisson mixture GLM by maximizing the expectation of the log-likelihood

MODIFIED ARGUMENT
-`mpGLM`: a structure containing the data and parameters of the mixture of Poisson GLM of one neuron

UNMODIFIED ARGUMENT
-`Î³`: posterior probability of the latent variables. Element `Î³[j][Ï„]` corresponds to the posterior probability of the j-th accumulator state  in the Ï„-th time step

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_05_test/data.mat");
julia> maximize_choice_posterior!(model)
julia> Î³ = choiceposteriors(model)[1]
julia> mpGLM = model.trialsets[1].mpGLMs[2]
julia> FHMDDM.maximize_expectation_of_loglikelihood!(mpGLM, Î³)
```
"""
function maximize_expectation_of_loglikelihood!(mpGLM::MixturePoissonGLM, Î³::Matrix{<:Vector{<:Real}}; show_trace::Bool=false, iterations::Integer=20)
	xâ‚€ = concatenateparameters(mpGLM.Î¸; omitb=true)
	nparameters = length(xâ‚€)
	Q = fill(NaN,1)
	âˆ‡Q = fill(NaN, nparameters)
	âˆ‡âˆ‡Q = fill(NaN, nparameters, nparameters)
	f(x) = -expectation_of_loglikelihood!(mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)
	âˆ‡f!(âˆ‡, x) = negexpectation_of_âˆ‡loglikelihood!(âˆ‡,mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)
	âˆ‡âˆ‡f!(âˆ‡âˆ‡, x) = negexpectation_of_âˆ‡âˆ‡loglikelihood!(âˆ‡âˆ‡,mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)
    results = Optim.optimize(f, âˆ‡f!, âˆ‡âˆ‡f!, xâ‚€, NewtonTrustRegion(), Optim.Options(show_trace=show_trace, iterations=iterations))
	sortparameters!(mpGLM.Î¸, Optim.minimizer(results); omitb=true)
	return nothing
end

"""
	expectation_of_loglikelihood!(mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)

Expectation of the log-likelihood under the posterior probability of the latent variables

MODIFIED ARGUMENT
-`mpGLM`: a structure containing the data and parameters of the mixture of Poisson GLM of one neuron
-`Q`: an one-element vector that quantifies the expectation
-`âˆ‡Q`: gradient of the expectation with respect to the filters in the k-th state
-`âˆ‡âˆ‡Q`: Hessian of the expectation with respect to the filters in the k-th state

UNMODIFIED ARGUMENT
-`Î³`: posterior probability of the latent variables. Element `Î³[j][Ï„]` corresponds to the posterior probability of the j-th accumulator state  in the Ï„-th time step
-`x`: filters
"""
function expectation_of_loglikelihood!(mpGLM::MixturePoissonGLM, Q::Vector{<:Real}, âˆ‡Q::Vector{<:Real}, âˆ‡âˆ‡Q::Matrix{<:Real}, Î³::Matrix{<:Vector{<:Real}}, x::Vector{<:Real})
	xâ‚€ = concatenateparameters(mpGLM.Î¸; omitb=true)
	if (x != xâ‚€) || isnan(Q[1])
		sortparameters!(mpGLM.Î¸, x; omitb=true)
		expectation_of_âˆ‡âˆ‡loglikelihood!(Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,mpGLM)
	end
	Q[1]
end

"""
	negexpectation_of_âˆ‡loglikelihood!(âˆ‡,mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)

Gradient of the negative of the expectation of the log-likelihood under the posterior probability of the latent variables

MODIFIED ARGUMENT
-`âˆ‡`: gradient of the negative of the expectation
-`mpGLM`: a structure containing the data and parameters of the mixture of Poisson GLM of one neuron
-`Q`: an one-element vector that quantifies the expectation
-`âˆ‡Q`: gradient of the expectation with respect to the filters in the k-th state
-`âˆ‡âˆ‡Q`: Hessian of the expectation with respect to the filters in the k-th state

UNMODIFIED ARGUMENT
-`Î³`: posterior probability of the latent variables. Element `Î³[j][Ï„]` corresponds to the posterior probability of the j-th accumulator state  in the Ï„-th time step
-`x`: filters
"""
function negexpectation_of_âˆ‡loglikelihood!(âˆ‡::Vector{<:Real}, mpGLM::MixturePoissonGLM, Q::Vector{<:Real}, âˆ‡Q::Vector{<:Real}, âˆ‡âˆ‡Q::Matrix{<:Real}, Î³::Matrix{<:Vector{<:Real}}, x::Vector{<:Real})
	xâ‚€ = concatenateparameters(mpGLM.Î¸; omitb=true)
	if (x != xâ‚€) || isnan(Q[1])
		sortparameters!(mpGLM.Î¸, x; omitb=true)
		expectation_of_âˆ‡âˆ‡loglikelihood!(Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,mpGLM)
	end
	for i in eachindex(âˆ‡)
		âˆ‡[i] = -âˆ‡Q[i]
	end
	return nothing
end

"""
	negexpectation_of_âˆ‡âˆ‡loglikelihood!(âˆ‡âˆ‡,mpGLM,Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,x)

Hessian of the negative of the expectation of the log-likelihood under the posterior probability of the latent variables

MODIFIED ARGUMENT
-`âˆ‡âˆ‡`: Hessian of the negative of the expectation
-`mpGLM`: a structure containing the data and parameters of the mixture of Poisson GLM of one neuron
-`Q`: an one-element vector that quantifies the expectation
-`âˆ‡Q`: gradient of the expectation with respect to the filters in the k-th state
-`âˆ‡âˆ‡Q`: Hessian of the expectation with respect to the filters in the k-th state

UNMODIFIED ARGUMENT
-`Î³`: posterior probability of the latent variables. Element `Î³[j][Ï„]` corresponds to the posterior probability of the j-th accumulator state  in the Ï„-th time step
-`x`: filters
"""
function negexpectation_of_âˆ‡âˆ‡loglikelihood!(âˆ‡âˆ‡::Matrix{<:Real}, mpGLM::MixturePoissonGLM, Q::Vector{<:Real}, âˆ‡Q::Vector{<:Real}, âˆ‡âˆ‡Q::Matrix{<:Real}, Î³::Matrix{<:Vector{<:Real}}, x::Vector{<:Real})
	xâ‚€ = concatenateparameters(mpGLM.Î¸; omitb=true)
	if (x != xâ‚€) || isnan(Q[1])
		sortparameters!(mpGLM.Î¸, x; omitb=true)
		expectation_of_âˆ‡âˆ‡loglikelihood!(Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,mpGLM)
	end
	nparameters = length(x)
	for i =1:nparameters
		for j=i:nparameters
			âˆ‡âˆ‡[i,j] = âˆ‡âˆ‡[j,i] = -âˆ‡âˆ‡Q[i,j]
		end
	end
	return nothing
end

"""
	expectation_of_âˆ‡âˆ‡loglikelihood!(Q,âˆ‡Q,âˆ‡âˆ‡Q,Î³,k,mpGLM)

Compute the expectation of the log-likelihood and its gradient and Hessian

ARGUMENT
-`Q`: expectation of the log-likelihood under the posterior probability of the latent variables. Only the component in the coupling state `k` is included
-`âˆ‡Q`: first-order derivatives of the expectation
-`âˆ‡âˆ‡Q`: second-order derivatives of the expectation

UNMODIFIED ARGUMENT
-`Î³`: posterior probabilities of the latent variables
-`k`: index of the coupling state
-`mpGLM`: a structure containing the data and parameters of the mixture of Poisson GLM of one neuron

EXAMPLE
```julia-repl
julia> using FHMDDM, ForwardDiff, Random
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_05_test/data.mat");
julia> mpGLM = model.trialsets[1].mpGLMs[1]
julia> Î³ = FHMDDM.randomposterior(mpGLM; rng=MersenneTwister(1234))
julia> xâ‚€ = concatenateparameters(mpGLM.Î¸)
julia> nparameters = length(xâ‚€)
julia> fhand, ghand, hhand = fill(NaN,1), fill(NaN,nparameters), fill(NaN,nparameters,nparameters)
julia> FHMDDM.expectation_of_âˆ‡âˆ‡loglikelihood!(fhand, ghand, hhand, Î³, mpGLM)
julia> f(x) = FHMDDM.expectation_of_loglikelihood(Î³, mpGLM, x)
julia> fauto = f(xâ‚€)
julia> gauto = ForwardDiff.gradient(f, xâ‚€)
julia> hauto = ForwardDiff.hessian(f, xâ‚€)
julia> abs(fauto - fhand[1])
julia> maximum(abs.(gauto .- ghand))
julia> maximum(abs.(hauto .- hhand))
```
"""
function expectation_of_âˆ‡âˆ‡loglikelihood!(Q::Vector{<:Real},
										âˆ‡Q::Vector{<:Real},
										âˆ‡âˆ‡Q::Matrix{<:Real},
										Î³::Matrix{<:Vector{<:Real}},
										mpGLM::MixturePoissonGLM)
    @unpack Î”t, ğ•, ğ—, ğ² = mpGLM
	@unpack ğ , ğ®, ğ¯ = mpGLM.Î¸
	ğ›š = transformaccumulator(mpGLM)
	ğ›šÂ² = ğ›š.^2
	Î,K = size(Î³)
	T = length(ğ²)
	âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚– = collect(zeros(T) for k=1:K)
	âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÎ¾áµ¢_dB = collect(zeros(T) for k=1:K)
	âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â² = collect(zeros(T) for k=1:K)
	âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dB = collect(zeros(T) for k=1:K)
	âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dBÂ² = collect(zeros(T) for k=1:K)
	Q[1] = 0.0
	âˆ‡Q .= 0.0
	âˆ‡âˆ‡Q .= 0.0
	@inbounds for i = 1:Î
		for k = 1:K
			ğ‹ = FHMDDM.linearpredictor(mpGLM,i,k)
			for t=1:T
				dÂ²â„“_dLÂ², dâ„“_dL, â„“ = differentiate_twice_loglikelihood_wrt_linearpredictor(Î”t, ğ‹[t], ğ²[t])
				Q[1] += Î³[i,k][t]*â„“
				dQáµ¢â‚–_dLáµ¢â‚– = Î³[i,k][t] * dâ„“_dL
				âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–[k][t] += dQáµ¢â‚–_dLáµ¢â‚–
				âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÎ¾áµ¢_dB[k][t] += dQáµ¢â‚–_dLáµ¢â‚–*ğ›š[i]
				dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â² = Î³[i,k][t] * dÂ²â„“_dLÂ²
				âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²[k][t] += dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²
				âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dB[k][t] += dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²*ğ›š[i]
				âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dBÂ²[k][t] += dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²*ğ›šÂ²[i]
			end
		end
	end
	Kğ  = length(ğ )
	Kğ¯ = length(ğ¯)
	nğ® = length(ğ®)
	nğ¯ = length(ğ¯[1])
	if Kğ  > 1
		indicesğ  = 1:Kğ -1
		indicesğ® = indicesğ [end] .+ (1:nğ®)
	else
		indicesğ® = 1:nğ®
	end
	indicesğ¯ = collect(indicesğ®[end] .+ ((k-1)*nğ¯+1 : k*nğ¯) for k = 1:Kğ¯)
	ğ” = @view ğ—[:, 2:1+nğ®]
	ğ”áµ€, ğ•áµ€ = transpose(ğ”), transpose(ğ•)
	âˆ‘áµ¢â‚–_dQáµ¢â‚–_dLáµ¢â‚– = sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–)
	âˆ‘áµ¢â‚–_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â² = sum(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²)
	âˆ‡Q[indicesğ®] .= ğ”áµ€*âˆ‘áµ¢â‚–_dQáµ¢â‚–_dLáµ¢â‚–
	âˆ‡âˆ‡Q[indicesğ®, indicesğ®] .= ğ”áµ€*(âˆ‘áµ¢â‚–_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â².*ğ”)
	if Kğ  > 1
		@inbounds for k = 2:K
			âˆ‡Q[indicesğ [k-1]] = sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–[k])
			âˆ‡âˆ‡Q[indicesğ [k-1], indicesğ [k-1]] = sum(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²[k])
			âˆ‡âˆ‡Q[indicesğ [k-1], indicesğ®] = transpose(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²[k])*ğ”
		end
		@inbounds for k = 2:Kğ¯
			âˆ‡âˆ‡Q[indicesğ [k-1], indicesğ¯[k]] = transpose(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dB[k])*ğ•
		end
	end
	if Kğ¯ > 1
		@inbounds for k = 1:K
			âˆ‡Q[indicesğ¯[k]] .= ğ•áµ€*âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÎ¾áµ¢_dB[k]
			âˆ‡âˆ‡Q[indicesğ¯[k], indicesğ¯[k]] .= ğ•áµ€*(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dBÂ²[k].*ğ•)
			âˆ‡âˆ‡Q[indicesğ®, indicesğ¯[k]] .= ğ”áµ€*(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dB[k].*ğ•)
		end
	else
		âˆ‡Q[indicesğ¯[1]] .= ğ•áµ€*sum(âˆ‘áµ¢_dQáµ¢â‚–_dLáµ¢â‚–â¨€dÎ¾áµ¢_dB)
		âˆ‡âˆ‡Q[indicesğ¯[1], indicesğ¯[1]] .= ğ•áµ€*(sum(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dBÂ²).*ğ•)
		âˆ‡âˆ‡Q[indicesğ®, indicesğ¯[1]] .= ğ”áµ€*(sum(âˆ‘áµ¢_dÂ²Qáµ¢â‚–_dLáµ¢â‚–Â²â¨€dÎ¾áµ¢_dB).*ğ•)
	end
	for i = 1:size(âˆ‡âˆ‡Q,1)
		for j = i+1:size(âˆ‡âˆ‡Q,2)
			âˆ‡âˆ‡Q[j,i] = âˆ‡âˆ‡Q[i,j]
		end
	end
	return nothing
end
