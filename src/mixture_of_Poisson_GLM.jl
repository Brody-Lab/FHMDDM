"""
    likelihood(mpGLM, j, k)

Conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`ğ©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against
"""
function likelihood(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î”t, ğ², ğ²! = mpGLM
    ğ—ğ° = linearpredictor(mpGLM, j, k)
    ğ© = ğ—ğ° # reuse memory
    for i=1:length(ğ©)
        Î»Î”t = softplus(ğ—ğ°[i])*Î”t
        if ğ²[i]==0
            ğ©[i] = exp(-Î»Î”t)
        elseif ğ²[i]==1
            ğ©[i] = Î»Î”t/exp(Î»Î”t)
        else
            ğ©[i] = Î»Î”t^ğ²[i] / exp(Î»Î”t) / ğ²![i]
        end
    end
    return ğ©
end

"""
    likelihood!(ğ©, mpGLM, j, k)

In-place multiplication of `ğ©` by the conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

MODIFIED ARGUMENT
-`ğ©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`nothing`
"""
function likelihood!(ğ©::Vector{<:Real}, mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î”t, ğ², ğ²! = mpGLM
    ğ—ğ° = linearpredictor(mpGLM, j, k)
    for i=1:length(ğ©)
        Î»Î”t = softplus(ğ—ğ°[i])*Î”t
        if ğ²[i]==0
            ğ©[i] *= exp(-Î»Î”t)
        elseif ğ²[i]==1
            ğ©[i] *= Î»Î”t/exp(Î»Î”t)
        else
            ğ©[i] *= Î»Î”t^ğ²[i] / exp(Î»Î”t) / ğ²![i]
        end
    end
    return nothing
end

"""
	Poissonlikelihood(Î»Î”t, y, y!)

Probability of a Poisson observation

ARGUMENT
-`Î»Î”t`: the expected value
-`y`: the observation
-`y!`: the factorial of the observation

OUTPUT
-the likelihood
"""
function Poissonlikelihood(Î»Î”t::Real, y::Integer, y!::Integer)
	if y==0
		exp(-Î»Î”t)
	elseif y==1
		Î»Î”t/exp(Î»Î”t)
	else
		Î»Î”t^y / exp(Î»Î”t) / y!
	end
end

"""
    linearpredictor(mpGLM, j, k)

Linear combination of the weights in the j-th accumulator state and k-th coupling state

ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model of one neuron
-`j`: state of the accumulator variable
-`k`: state of the coupling variable

RETURN
-`ğ›Œ`: a vector whose element ğ›Œ[t] corresponds to the t-th time bin in the trialset
"""
function linearpredictor(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack ğ”, ğ—, ğ› = mpGLM
    @unpack ğ®, ğ¯, a, b = mpGLM.Î¸
    if k == 1 && ğ›[j] != 0.0
        Î¾ = transformaccumulator(b[1], ğ›[j])
        if ğ›[j] < 0
            ğ° = vcat(ğ®, Î¾.*ğ¯)
        else
            ğ° = vcat(ğ®, rectifya(a[1]).*Î¾.*ğ¯)
        end
        ğ—*ğ°
    else
        ğ”*ğ®
    end
end

"""
    transformaccumulator

Nonlinearly transform the normalized values of the accumulator

ARGUMENT
-`Î¾`: value of the accumulator: expected to be between -1 and 1
-`b`: parameter specifying the transformation

RETURN
-transformed value of the accumulator
"""
function transformaccumulator(b::Real, Î¾::Real)
    if b == 0.0
        Î¾
    else
        if Î¾ < 0
            if b > 709.0 # 709 is close to which exp returns Inf for a 64-bit floating point number
                Î¾ == -1.0 ? -1.0 : 0.0
            else
                -expm1(-b*Î¾)/expm1(b)
                # (exp(-b*Î¾)-1.0)/(1.0-exp(b))
            end
        elseif Î¾ > 0
            if b > 709.0
                Î¾ == 1.0 ? 1.0 : 0.0
            else
                expm1(b*Î¾)/expm1(b)
                # (1.0-exp(b*Î¾))/(1.0-exp(b))
            end
        else
            0.0
        end
    end
end

"""
    dtransformaccumulator

Derivative of the nonlinear transformation of the normalized values of the accumulator with respect to b

ARGUMENT
-`Î¾`: value of the accumulator: expected to be between -1 and 1
-`b`: parameter specifying the transformation

RETURN
-transformed value of the accumulator
"""
function dtransformaccumulator(b::Real, Î¾::Real)
    if Î¾ == -1.0 || Î¾ == 0.0 || Î¾ == 1.0 || b > 709.0 # 709 is close to which exp returns Inf for a 64-bit floating point number
        0.0
    elseif abs(b) < 1e-6
        Î¾ < 0 ? (-Î¾^2-Î¾)/2 : (Î¾^2-Î¾)/2
    elseif Î¾ < 0
        eáµ‡ = exp(b)
        eáµ‡m1 = expm1(b)
        eâ»áµ‡Ë£ = exp(-b*Î¾)
        eâ»áµ‡Ë£m1 = expm1(-b*Î¾)
        if b < 1
            (Î¾*eâ»áµ‡Ë£*eáµ‡m1 + eâ»áµ‡Ë£m1*eáµ‡)/eáµ‡m1^2
        else
            Î¾*eâ»áµ‡Ë£/eáµ‡m1 + eâ»áµ‡Ë£m1/(eáµ‡-2+exp(-b))
        end
    elseif Î¾ > 0
        eáµ‡ = exp(b)
        eáµ‡m1 = expm1(b)
        eáµ‡Ë£ = exp(b*Î¾)
        eáµ‡Ë£m1 = expm1(b*Î¾)
        if b < 1
            Î¾*eáµ‡Ë£/eáµ‡m1 - eáµ‡Ë£m1*eáµ‡/eáµ‡m1^2
        else
            Î¾*eáµ‡Ë£/eáµ‡m1 - eáµ‡Ë£m1/(eáµ‡-2+exp(-b))
        end
    end
end

"""
    rectifya(a)

Map a parameter from real space to positive values

A value of 0 in real space corresponds to 1.0

ARGUMENT:
-`a`: parameter in real space

OUTPUT
-positive-valued parameter
"""
function rectifya(a::Real)
    # softplus(a+log(exp(1)-1.0))
    # 0.2 + 4.5 *logistic(a + logit(8.0/45.0))
    a+1.0
end

"""
    drectifya(a)

Derivative of the mapping of a parameter from real space to positive values

ARGUMENT:
-`a`: parameter in real space

OUTPUT
-the derivative
"""
function drectifya(a::Real)
    # logistic(a+log(exp(1)-1.0))
    # logistica = logistic(a + logit(8.0/45.0))
    # 4.5*logistica*(1.0-logistica)
    1.0
end

"""
    estimatefilters!(trialsets, Î³)

Update the filters in the mixture of Poisson generalized linear models

MODIFIED ARGUMENT
-`trialsets`: vector of data for each group of trials

UNMODIFIED ARGUMENT
-`Î³`: joint posterior likelihood of each accumulator state and each coupling state at each time bin. `Î³[i][Î¾,k][t]` corresponds to the joint posterior of accumulator state Î¾ and coupling state k at the t-th time bin concatenated across trials in the i-th trialset

RETURN
-nothing
"""
function estimatefilters!(trialsets::Vector{<:Trialset},
                          Î³::Vector{<:Matrix{<:Vector{<:AbstractFloat}}},
                          options::Options;
                          show_trace::Bool=true)
    concatentatedÎ¸ = map(trialsets, Î³) do trialset, Î³
                        pmap(trialset.mpGLMs) do mpGLM
                            estimatefilters(Î³, mpGLM; show_trace=show_trace)
                        end
                    end
    Páµ¤ = length(trialsets[1].mpGLMs[1].Î¸.ğ®)
    Páµ¥ = length(trialsets[1].mpGLMs[1].Î¸.ğ¯)
    for i in eachindex(concatentatedÎ¸)
        for n in eachindex(concatentatedÎ¸[i])
            trialsets[i].mpGLMs[n].Î¸.ğ® .= concatentatedÎ¸[i][n][1:Páµ¤]
            trialsets[i].mpGLMs[n].Î¸.ğ¯ .= concatentatedÎ¸[i][n][Páµ¤+1:Páµ¤+Páµ¥]
        end
    end
    return nothing
end

"""
    estimatefilters(Î³, mpGLM)

Estimate the filters of the Poisson mixture GLM of one neuron

ARGUMENT
-`Î³`: posterior probabilities of the latent
-`mpGLM`: the Poisson mixture GLM of one neuron

OPTIONAL ARGUMENT
-`show_trace`: whether to show information about each step of the optimization
-`fit_a`: whether to fit the asymmetric scaling factor
-`fit_b`: whether to fit the nonlinearity factor

RETURN
-weights concatenated into a single vector
"""
function estimatefilters(Î³::Matrix{<:Vector{<:AbstractFloat}},
                         mpGLM::MixturePoissonGLM;
                         iterations::Integer=20,
                         show_trace::Bool=true)
    @unpack ğ®, ğ¯ = mpGLM.Î¸
    xâ‚€ = vcat(ğ®, ğ¯)
    f(x) = negativeexpectation(Î³, mpGLM, x)
    g!(âˆ‡, x) = âˆ‡negativeexpectation!(âˆ‡, Î³, mpGLM, x)
    h!(ğ‡, x) = ğ‡negativeexpectation!(ğ‡, Î³, mpGLM, x)
    results = Optim.optimize(f, g!, h!, xâ‚€, NewtonTrustRegion(), Optim.Options(show_trace=show_trace, iterations=iterations))
    show_trace && println("The model converged: ", Optim.converged(results))
    return Optim.minimizer(results)
end

"""
    negativeexpectation(Î³, mpGLM, x)

Negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

ARGUMENT
-`Î³`: posterior probability of the latent variable
-`mpGLM`: the GLM of one neuron
-`x`: weights of the linear filters of the GLM concatenated as a vector of floating-point numbers

RETURN
-expectation of the log-likelihood of the spike train of one neuron
"""
function negativeexpectation(Î³::Matrix{<:Vector{<:AbstractFloat}},
                             mpGLM::MixturePoissonGLM,
                             x::Vector{<:Real})
    @unpack Î”t, K, ğ”, ğš½, ğ›, ğ—, ğ² = mpGLM
    Páµ¤ = size(ğ”,2)
    Páµ¥ = size(ğš½,2)
    ğ® = x[1:Páµ¤]
    ğ¯ = x[Páµ¤+1:Páµ¤+Páµ¥]
    ğ”ğ® = ğ”*ğ®
    T = length(ğ”ğ®)
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    negğ’¬ = 0.0
    for k = 1:K
        for i = 1:Î
            if k == 2 || i == zeroindex
                ğ—ğ° = ğ”ğ®
            else
                ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ¯)
            end
            for t = 1:T
                Î» = softplus(ğ—ğ°[t])
                if ğ²[t] == 0
                    negğ’¬ += Î³[i,k][t]*(Î»*Î”t)
                elseif ğ²[t] == 1
                    negğ’¬ += Î³[i,k][t]*(Î»*Î”t - log(Î»))
                else
                    negğ’¬ += Î³[i,k][t]*(Î»*Î”t - ğ²[t]*log(Î»))
                end
            end
        end
    end
    return negğ’¬
end

"""
    âˆ‡negativeexpectation!(âˆ‡, Î³, mpGLM, x)

Gradient of the negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

MODIFIED ARGUMENT
-`âˆ‡`: The gradient

UNMODIFIED ARGUMENT
-`Î³`: Joint posterior probability of the accumulator and coupling variable. Î³[i,k][t] corresponds to the i-th accumulator state and the k-th coupling state in the t-th time bin in the trialset.
-`mpGLM`: structure containing information for the mixture of Poisson GLM for one neuron
-`x`: vector of parameters for the mixture of Poisson GLM

RETURN
-nothing
"""
function âˆ‡negativeexpectation!( âˆ‡::Vector{<:Real},
                                Î³::Matrix{<:Vector{<:Real}},
                                mpGLM::MixturePoissonGLM,
                                x::Vector{<:type}) where {type<:Real}
    @unpack Î”t, ğ”, ğš½, ğ—, ğ›, ğ² = mpGLM
    Páµ¤ = size(mpGLM.ğ”,2)
    Páµ¥ = size(mpGLM.ğš½,2)
    ğ® = x[1:Páµ¤]
    ğ¯ = x[Páµ¤+1:Páµ¤+Páµ¥]
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    ğ”ğ® = ğ”*ğ®
    T = length(ğ²)
    if size(Î³,2) > 1 # i.e, the coupling variable has more than one state
        âˆ‘Î³decoupled = Î³[zeroindex,1] .+ sum(Î³[:,2])
    else
        âˆ‘Î³decoupled = Î³[zeroindex,1]
    end
    âˆ‘ğ® = ğ”ğ®
    for t in eachindex(âˆ‘ğ®)
        âˆ‘ğ®[t] = âˆ‘Î³decoupled[t]*differentiate_negative_loglikelihood(Î”t, ğ”ğ®[t], ğ²[t])
    end
    âˆ‘ğ¯ = zeros(type, T)
    for i = 1:Î
        if i == zeroindex
            continue
        end
        ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ¯)
        dnegâ„“ = ğ—ğ°
        for t in eachindex(dnegâ„“)
            dnegâ„“[t] = differentiate_negative_loglikelihood(Î”t, ğ—ğ°[t], ğ²[t])
        end
        Î¶ = Î³[i,1] .* dnegâ„“
        âˆ‘ğ® .+= Î¶
        âˆ‘ğ¯ .+= ğ›[i].*Î¶
    end
    âˆ‡[1:Páµ¤] = transpose(ğ”)*âˆ‘ğ®
    âˆ‡[Páµ¤+1:Páµ¤+Páµ¥] = transpose(ğš½)*âˆ‘ğ¯
    return nothing
end

"""
    âˆ‡negativeexpectation(Î³, mpGLM)

Gradient of the negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

ARGUMENT
-`Î³`: Joint posterior probability of the accumulator and coupling variable. Î³[i,k][t] corresponds to the i-th accumulator state and the k-th coupling state in the t-th time bin in the trialset.
-`mpGLM`: structure containing information for the mixture of Poisson GLM for one neuron

RETURN
-âˆ‡: the gradient
"""
function âˆ‡negativeexpectation(Î³::Matrix{<:Vector{type}},
                              mpGLM::MixturePoissonGLM;
                              fit_a::Bool=true,
                              fit_b::Bool=true) where {type<:Real}
    @unpack Î”t, K, ğ”, ğš½, ğ—, ğ›, ğ² = mpGLM
    @unpack ğ®, ğ¯, a, b = mpGLM.Î¸
    Î = size(Î³,1)
    zeroindex = (Î+1)/2
    ğ”ğ® = ğ”*ğ®
    fa = rectifya(a[1])
    T = length(ğ²)
    âˆ‘ğ®, âˆ‘left, âˆ‘right = zeros(type, T), zeros(type, T), zeros(type, T)
    fit_b && (âˆ‘b = zeros(type, T))
    ğ›ˆ = ğ”ğ® # reuse memory
    for t in eachindex(ğ›ˆ)
        ğ›ˆ[t] = differentiate_negative_loglikelihood(Î”t, ğ”ğ®[t], ğ²[t])
    end
    for k = 1:K
        for i = 1:Î
            if k == 2 || i == zeroindex
                dnegâ„“ = ğ›ˆ
            else
                fÎ¾ = transformaccumulator(b[1], ğ›[i])
                if i < zeroindex
                    ğ° = vcat(ğ®, fÎ¾.*ğ¯)
                else
                    ğ° = vcat(ğ®, fa.*fÎ¾.*ğ¯)
                end
                ğ—ğ° = ğ—*ğ°
                dnegâ„“ = ğ—ğ° # reuse memory
                for t in eachindex(dnegâ„“)
                    dnegâ„“[t] = differentiate_negative_loglikelihood(Î”t, ğ—ğ°[t], ğ²[t])
                end
            end
            Î¶ = Î³[i,k] .* dnegâ„“
            âˆ‘ğ® .+= Î¶
            if k == 1 &&  i != zeroindex
                if i < zeroindex
                    âˆ‘left .+= fÎ¾.*Î¶
                    fit_b && (âˆ‘b .+= dtransformaccumulator(b[1], ğ›[i]).*Î¶)
                elseif i > zeroindex
                    âˆ‘right .+= fÎ¾.*Î¶
                    fit_b && (âˆ‘b .+= fa.*dtransformaccumulator(b[1], ğ›[i]).*Î¶)
                end
            end
        end
    end
    âˆ‘ğ¯ = âˆ‘left # reuse memory
    âˆ‘ğ¯ .+= fa.*âˆ‘right
    ğ¯áµ€ğš½áµ€ = transpose(ğš½*ğ¯)
    Páµ¤ = length(ğ®)
    Páµ¥ = length(ğ¯)
    âˆ‡ = zeros(type, Páµ¤+Páµ¥+fit_a+fit_b)
    âˆ‡[1:Páµ¤] = transpose(ğ”)*âˆ‘ğ®
    âˆ‡[Páµ¤+1:Páµ¤+Páµ¥] = transpose(ğš½)*âˆ‘ğ¯
    counter = Páµ¤+Páµ¥
    if fit_a
        âˆ‡[counter+=1] = drectifya(a[1])*(ğ¯áµ€ğš½áµ€*âˆ‘right) # the parentheses avoid unnecessary memory allocation
    end
    if fit_b
        âˆ‡[counter+=1] = ğ¯áµ€ğš½áµ€*âˆ‘b
    end
    return âˆ‡
end

"""
    differentiate_negative_loglikelihood

Differentiate the negative of the log-likelihood of a Poisson GLM with respect to the linear predictor

The Poisson GLM is assumed to have a a softplus nonlinearity

ARGUMENT
-`Î”t`: duration of time step
-`xw`: linear predictor at one time step
-`y`: observation at that time step

RETURN
-the derivative with respect to the linear predictor
"""
function differentiate_negative_loglikelihood(Î”t::AbstractFloat, xw::Real, y::Integer)
    if y > 0
        if xw > -100.0
            logistic(xw)*(Î”t - y/softplus(xw))
        else
            logistic(xw)*Î”t - y # the limit of logistic(x)/softplus(x) as x goes to -âˆ is 1
        end
    else
        logistic(xw)*Î”t
    end
end

"""
    ğ‡negativeexpection(ğ‡, Î³, mpGLM, x)

Compute the Hessian of the negative of the terms in the expectation that depend on the GLM filters

MODIFIED ARGUMENT
-`ğ‡`: Hessian matrix

UNMODIFIED ARGUMENT
-`Î³`: posterior probabilities of the latents
-`mpGLM`: the Poisson mixture GLM of one neuron
-`x`: filters of the Poisson mixture GLM

RETURN
-nothing
"""
function ğ‡negativeexpectation!(ğ‡::Matrix{<:AbstractFloat},
                               Î³::Matrix{<:Vector{<:AbstractFloat}},
                               mpGLM::MixturePoissonGLM,
                               x::Vector{<:AbstractFloat})
    @unpack Î”t, ğ”, ğš½, ğ›, ğ—, ğ² = mpGLM
    Páµ¤ = size(ğ”,2)
    Páµ¥ = size(ğš½,2)
    indicesğ® = 1:Páµ¤
    indicesğ¯ = Páµ¤+1:Páµ¤+Páµ¥
    ğ® = x[indicesğ®]
    ğ¯ = x[indicesğ¯]
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    if size(Î³,2) > 1 # i.e, the coupling variable has more than one state
        âˆ‘Î³decoupled = Î³[zeroindex,1] .+ sum(Î³[:,2])
    else
        âˆ‘Î³decoupled = Î³[zeroindex,1]
    end
    T = length(ğ²)
    âˆ‘ğ®ğ¯, âˆ‘ğ¯ğ¯ = zeros(T), zeros(T)
    ğ”ğ® = ğ”*ğ®
    âˆ‘ğ®ğ® = ğ”ğ®
    for t in eachindex(âˆ‘ğ®ğ®)
        âˆ‘ğ®ğ®[t] = âˆ‘Î³decoupled[t]*differentiate_twice_negative_loglikelihood(Î”t, ğ”ğ®[t], ğ²[t])
    end
    for i = 1:Î
        if i == zeroindex
            continue
        end
        ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ¯)
        dÂ²negâ„“ = ğ—ğ°
        for t in eachindex(dÂ²negâ„“)
            dÂ²negâ„“[t] = differentiate_twice_negative_loglikelihood(Î”t, ğ—ğ°[t], ğ²[t])
        end
        Î¶ = Î³[i,1] .* dÂ²negâ„“
        âˆ‘ğ®ğ® .+= Î¶
        âˆ‘ğ¯ğ¯ .+= ğ›[i]^2 .* Î¶
        âˆ‘ğ®ğ¯ .+= ğ›[i].*Î¶
    end
    ğ”áµ€ = transpose(ğ”)
    ğš½áµ€ = transpose(ğš½)
    ğ”áµ€_âˆ‘ğ®ğ¯_ğš½ = ğ”áµ€*(âˆ‘ğ®ğ¯.*ğš½)
    # ğ‡ .= 0
    ğ‡[indicesğ®, indicesğ®] = ğ”áµ€*(âˆ‘ğ®ğ®.*ğ”)
    ğ‡[indicesğ¯, indicesğ¯] = ğš½áµ€*(âˆ‘ğ¯ğ¯.*ğš½)
    ğ‡[indicesğ®, indicesğ¯] = ğ”áµ€_âˆ‘ğ®ğ¯_ğš½
    ğ‡[indicesğ¯, indicesğ®] = transpose(ğ”áµ€_âˆ‘ğ®ğ¯_ğš½)
    return nothing
end

"""
    differentiate_twice_negative_loglikelihood

Second derivative the negative of the log-likelihood of a Poisson GLM with respect to the linear predictor

The Poisson GLM is assumed to have a a softplus nonlinearity

ARGUMENT
-`Î”t`: duration of time step
-`xw`: linear predictor at one time step
-`y`: observation at that time step

RETURN
-the derivative with respect to the linear predictor
"""
function differentiate_twice_negative_loglikelihood(Î”t::AbstractFloat, xw::Real, y::Integer)
    fâ‚ = logistic(xw) # first derivative of softplus(xw) with respect to xw
    fâ‚‚ = fâ‚*(1.0-fâ‚) # second derivative
    if y > 0 && xw > -50.0
        fâ‚€ = softplus(xw)
        fâ‚‚*Î”t - y*(fâ‚€*fâ‚‚ - fâ‚^2)/fâ‚€^2 # the limit of the second term is 0 as xw goes to -âˆ
    else
        fâ‚‚*Î”t
    end
end

"""
	GLMÎ¸(K, ğ‡, ğ”, ğ•)

Randomly initiate the parameters for a mixture of Poisson generalized linear model

ARGUMENT
-`K`: number of coupling states
-`ğ‡`: time-varying inputs from spike history
-`ğ”`: time-varying inputs from trial events
-`ğ•`: time-varying inputs from the accumulator

OUTPUT
-an instance of `GLMÎ¸`
"""
function GLMÎ¸(K::Integer,
			ğ‡::Matrix{<:AbstractFloat},
			ğ”::Matrix{<:AbstractFloat},
			ğ•::Matrix{<:AbstractFloat})
	nğ¡ = size(ğ‡,2)
	nğ® = size(ğ”,2)
	nğ¯ = size(ğ•,2)
	Î¸ = GLMÎ¸(ğ¡ = 1.0 .- 2.0.*rand(nğ¡),
			 ğ° = 1.0 .- 2.0.*rand(K),
			 ğ® = collect(1.0 .- 2.0.*rand(nğ®) for k=1:K),
			 ğ¯ = collect(1.0 .- 2.0.*rand(nğ¯) for k=1:K))
end
