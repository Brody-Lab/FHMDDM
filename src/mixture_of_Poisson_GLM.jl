"""
    likelihood(mpGLM, j, k)

Conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`ğ©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against
"""
function likelihood(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î”t, ğ², ğ²! = mpGLM
    ğ›Œ = lambda(mpGLM, j, k)
    ğ© = ğ›Œ # reuse memory
    for i in eachindex(ğ›Œ)
        ğ©[i] = (ğ›Œ[i]*Î”t)^ğ²[i] / exp(ğ›Œ[i]*Î”t) / ğ²![i]
    end
    return ğ©
end

"""
    likelihood!(ğ©, mpGLM, j, k)

In-place multiplication of `ğ©` by the conditional likelihood of the spike train, given the index of the state of the accumulator `j` and the state of the coupling `k`, and also by the prior likelihood of the regression weights

MODIFIED ARGUMENT
-`ğ©`: a vector by which the conditional likelihood of the spike train and the prior likelihood of the regression weights are multiplied against

UNMODIFIED ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model for one neuron
-`j`: state of accumulator variable
-`k`: state of the coupling variable

RETURN
-`nothing`
"""
function likelihood!(ğ©, mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î”t, ğ², ğ²! = mpGLM
    ğ›Œ = lambda(mpGLM, j, k)
    for i in eachindex(ğ›Œ)
        ğ©[i] *= (ğ›Œ[i]*Î”t)^ğ²[i] / exp(ğ›Œ[i]*Î”t) / ğ²![i]
    end
    return nothing
end

"""
    loglikelihood(mpGLM, Î¾, k)

Compute the conditional log-likelihood of the spike train and the input weights given the state of the accumulator variable and of the coupling variable

ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model of one neuron
-`j`: state of the accumulator variable
-`k`: state of the coupling variable

RETURN
-a vector whose ğ‘¡-th element is the log-likelihood ğ‘™ğ‘œğ‘” ğ‘(ğ²[t] âˆ£ ğ®, ğ¥, ğ«, ğ”, ğš½)
"""
function loglikelihood(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack Î”t, ğ², log_ğ²! = mpGLM
    ğ›Œ = lambda(mpGLM, j, k)
    ğ².*log.(ğ›Œ.*Î”t) .- ğ›Œ.*Î”t .- log_ğ²!
end

"""
    lambda(mpGLM, j, k)

Compute Î» of the mixture of Poisson GLM given the j-th accumulator state and k-th coupling state

ARGUMENT
-`mpGLM`: the mixture of Poisson generalized linear model of one neuron
-`j`: state of the accumulator variable
-`k`: state of the coupling variable

RETURN
-`ğ›Œ`: a vector whose element ğ›Œ[t] corresponds to the t-th time bin in the trialset
"""
function lambda(mpGLM::MixturePoissonGLM, j::Integer, k::Integer)
    @unpack ğ”, ğ®, ğ—, ğ›, ğ¥, ğ« = mpGLM
    if k == 1 && ğ›[j] != 0.0
        if ğ›[j] < 0
            ğ° = vcat(ğ®, ğ›[j].*ğ¥)
        else
            ğ° = vcat(ğ®, ğ›[j].*ğ«)
        end
        softplus.(ğ—*ğ°)
    else
        softplus.(ğ”*ğ®)
    end
end

"""
    estimatefilters!(trialsets, Î³)

Update the filters in the mixture of Poisson generalized linear models

MODIFIED ARGUMENT
-`trialsets`: vector of data for each group of trials

UNMODIFIED ARGUMENT
-`Î³`: joint posterior likelihood of each accumulator state and each coupling state at each time bin. `Î³[i][Î¾,k][t]` corresponds to the joint posterior of accumulator state Î¾ and coupling state k at the t-th time bin concatenated across trials in the i-th trialset

RETURN
-nothing
"""
function estimatefilters!(trialsets::Vector{<:Trialset},
                          Î³::Vector{<:Matrix{<:Vector{<:AbstractFloat}}};
                          show_trace::Bool=true)
    concatentatedÎ¸ = map(trialsets, Î³) do trialset, Î³
                        pmap(trialset.mpGLMs) do mpGLM
                            estimatefilters(Î³, mpGLM,; show_trace=show_trace)
                        end
                    end
    Páµ¤ = length(trialsets[1].mpGLMs[1].ğ®)
    Pâ‚— = length(trialsets[1].mpGLMs[1].ğ¥)
    for i in eachindex(concatentatedÎ¸)
        for n in eachindex(concatentatedÎ¸[i])
            trialsets[i].mpGLMs[n].ğ® .= concatentatedÎ¸[i][n][1:Páµ¤]
            trialsets[i].mpGLMs[n].ğ¥ .= concatentatedÎ¸[i][n][Páµ¤+1:Páµ¤+Pâ‚—]
            trialsets[i].mpGLMs[n].ğ« .= concatentatedÎ¸[i][n][Páµ¤+Pâ‚—+1:end]
        end
    end
    return nothing
end

"""
    estimatefilters(Î³, mpGLM; show_trace)

Estimate the filters of the Poisson mixture GLM of one neuron

ARGUMENT
-`Î³`: posterior probabilities of the latent
-`mpGLM`: the Poisson mixture GLM of one neuron

OPTIONAL ARGUMENT
-`show_trace`: whether to show information about each step of the optimization

RETURN
-weights concatenated into a single vector
"""
function estimatefilters(Î³::Matrix{<:Vector{<:AbstractFloat}},
                         mpGLM::MixturePoissonGLM;
                         show_trace::Bool=true)
    @unpack ğ®, ğ¥, ğ« = mpGLM
    xâ‚€ = vcat(ğ®, ğ¥, ğ«)
    f(x) = negativeexpectation(Î³, mpGLM, x)
    g!(âˆ‡, x) = âˆ‡negativeexpectation!(âˆ‡, Î³, mpGLM, x)
    h!(ğ‡, x) = ğ‡negativeexpectation!(ğ‡, Î³, mpGLM, x)
    results = Optim.optimize(f, g!, h!, xâ‚€, NewtonTrustRegion(), Optim.Options(show_trace=show_trace))
    show_trace && println("The model converged: ", Optim.converged(results))
    return Optim.minimizer(results)
end

"""
    negativeexpectation(Î³, mpGLM, x)

Negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

ARGUMENT
-`Î³`: posterior probability of the latent variable
-`mpGLM`: the GLM of one neuron
-`x`: weights of the linear filters of the GLM concatenated as a vector of floating-point numbers

RETURN
-expectation of the log-likelihood of the spike train of one neuron
"""
function negativeexpectation(Î³::Matrix{<:Vector{<:AbstractFloat}},
                             mpGLM::MixturePoissonGLM,
                             x::Vector{<:AbstractFloat})
    @unpack Î”t, ğ”, ğš½, ğ›, ğ—, ğ² = mpGLM
    Páµ¤ = size(ğ”,2)
    Pâ‚— = size(ğš½,2)
    ğ® = x[1:Páµ¤]
    ğ¥ = x[Páµ¤+1:Páµ¤+Pâ‚—]
    ğ« = x[Páµ¤+Pâ‚—+1:end]
    ğ”ğ® = ğ”*ğ®
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    if size(Î³,2) > 1 # i.e, the coupling variable has more than one state
        âˆ‘Î³decoupled = Î³[zeroindex,1] .+ sum(Î³[:,2])
    else
        âˆ‘Î³decoupled = Î³[zeroindex,1]
    end
    fğ—ğ° = softplus.(ğ”ğ®)
    negğ’¬ = âˆ‘Î³decoupled â‹… (fğ—ğ°.*Î”t .- ğ².*log.(fğ—ğ°))
    for i=1:Î
        if i != zeroindex
            if i < zeroindex
                fğ—ğ° = softplus.(ğ—*vcat(ğ®, ğ›[i].*ğ¥))
            else
                fğ—ğ° = softplus.(ğ—*vcat(ğ®, ğ›[i].*ğ«))
            end
            negğ’¬ += Î³[i,1] â‹… (fğ—ğ°.*Î”t .- ğ².*log.(fğ—ğ°))
        end
    end
    return negğ’¬
end

"""
    âˆ‡negativeexpectation!(âˆ‡, Î³, mpGLM, x)

Gradient of the negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

MODIFIED ARGUMENT
-`âˆ‡`: The gradient

UNMODIFIED ARGUMENT
-`Î³`: Joint posterior probability of the accumulator and coupling variable. Î³[i,k][t] corresponds to the i-th accumulator state and the k-th coupling state in the t-th time bin in the trialset.
-`mpGLM`: structure containing information for the mixture of Poisson GLM for one neuron
-`x`: vector of parameters for the mixture of Poisson GLM

RETURN
-nothing
"""
function âˆ‡negativeexpectation!(âˆ‡::Vector{<:AbstractFloat},
                               Î³::Matrix{<:Vector{<:AbstractFloat}},
                               mpGLM::MixturePoissonGLM,
                               x::Vector{<:AbstractFloat})
    Páµ¤ = size(mpGLM.ğ”,2)
    Pâ‚— = size(mpGLM.ğš½,2)
    mpGLM.ğ® .= x[1:Páµ¤]
    mpGLM.ğ¥ .= x[Páµ¤+1:Páµ¤+Pâ‚—]
    mpGLM.ğ« .= x[Páµ¤+Pâ‚—+1:end]
    âˆ‡ .= âˆ‡negativeexpectation(Î³, mpGLM)
end

"""
    âˆ‡negativeexpectation(Î³, mpGLM)

Gradient of the negative of the expectation of the log-likelihood of the mixture of Poisson generalized model of one neuron

ARGUMENT
-`Î³`: Joint posterior probability of the accumulator and coupling variable. Î³[i,k][t] corresponds to the i-th accumulator state and the k-th coupling state in the t-th time bin in the trialset.
-`mpGLM`: structure containing information for the mixture of Poisson GLM for one neuron

RETURN
-âˆ‡: the gradient
"""
function âˆ‡negativeexpectation(Î³::Matrix{<:Vector{<:AbstractFloat}},
                              mpGLM::MixturePoissonGLM)
    @unpack Î”t, ğ”, ğš½, ğ—, ğ›, ğ², ğ®, ğ¥, ğ« = mpGLM
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    if size(Î³,2) > 1 # i.e, the coupling variable has more than one state
        âˆ‘Î³decoupled = Î³[zeroindex,1] .+ sum(Î³[:,2])
    else
        âˆ‘Î³decoupled = Î³[zeroindex,1]
    end
    ğ”ğ® = ğ”*ğ®
    tmpğ® = âˆ‘Î³decoupled .* logistic.(ğ”ğ®) .* (Î”t .- ğ² ./ softplus.(ğ”ğ®))
    tmpğ¥ = zeros(size(ğ²))
    tmpğ« = zeros(size(ğ²))
    for i=1:zeroindex-1
        ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ¥)
        tmp = Î³[i,1] .* logistic.(ğ—ğ°) .* (Î”t .- ğ² ./ softplus.(ğ—ğ°))
        tmpğ¥ .+= ğ›[i].*tmp
        tmpğ® .+= tmp
    end
    for i=zeroindex+1:Î
        ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ«)
        tmp = Î³[i,1] .* logistic.(ğ—ğ°) .* (Î”t .- ğ² ./ softplus.(ğ—ğ°))
        tmpğ« .+= ğ›[i].*tmp
        tmpğ® .+= tmp
    end
    Páµ¤ = length(ğ®)
    Pâ‚— = length(ğ¥)
    ğš½áµ€ = transpose(ğš½)
    âˆ‡ = zeros(Páµ¤+2Pâ‚—)
    âˆ‡[1:Páµ¤] = transpose(ğ”)*tmpğ®
    âˆ‡[Páµ¤+1:Páµ¤+Pâ‚—] = ğš½áµ€*tmpğ¥
    âˆ‡[Páµ¤+Pâ‚—+1:end] = ğš½áµ€*tmpğ«
    return âˆ‡
end

"""
    ğ‡negativeexpection(ğ‡, Î³, mpGLM, x)

Compute the Hessian of the negative of the terms in the expectation that depend on the GLM filters

MODIFIED ARGUMENT
-`ğ‡`: Hessian matrix

UNMODIFIED ARGUMENT
-`Î³`: posterior probabilities of the latents
-`mpGLM`: the Poisson mixture GLM of one neuron
-`x`: filters of the Poisson mixture GLM

RETURN
-nothing
"""
function ğ‡negativeexpectation!(ğ‡::Matrix{<:AbstractFloat},
                               Î³::Matrix{<:Vector{<:AbstractFloat}},
                               mpGLM::MixturePoissonGLM,
                               x::Vector{<:AbstractFloat})
    @unpack Î”t, ğ”, ğš½, ğ›, ğ—, ğ² = mpGLM
    Páµ¤ = size(ğ”,2)
    Pâ‚— = size(ğš½,2)
    indicesğ® = 1:Páµ¤
    indicesğ¥ = Páµ¤+1:Páµ¤+Pâ‚—
    indicesğ« = Páµ¤+Pâ‚—+1:Páµ¤+2Pâ‚—
    ğ® = x[indicesğ®]
    ğ¥ = x[indicesğ¥]
    ğ« = x[indicesğ«]
    ğ”ğ® = ğ”*ğ®
    ğ”áµ€ = transpose(ğ”)
    ğš½áµ€ = transpose(ğš½)
    T = length(ğ²)
    Î = size(Î³,1)
    zeroindex = cld(Î,2)
    if size(Î³,2) > 1 # i.e, the coupling variable has more than one state
        âˆ‘Î³decoupled = Î³[zeroindex,1] .+ sum(Î³[:,2])
    else
        âˆ‘Î³decoupled = Î³[zeroindex,1]
    end
    fâ‚€ = softplus.(ğ”ğ®)
    fâ‚ = logistic.(ğ”ğ®) # first derivative
    fâ‚‚ = fâ‚ .* (1 .- fâ‚) # second derivative
    tmpğ®ğ® = âˆ‘Î³decoupled .* (fâ‚‚.*Î”t .- ğ².*(fâ‚€.*fâ‚‚ .- fâ‚.^2)./fâ‚€.^2)
    tmpğ¥ğ® = zeros(T)
    tmpğ«ğ® = zeros(T)
    tmpğ¥ğ¥ = zeros(T)
    tmpğ«ğ« = zeros(T)
    for i = 1:Î
        if i < zeroindex
            ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ¥)
        elseif i > zeroindex
            ğ—ğ° = ğ—*vcat(ğ®, ğ›[i].*ğ«)
        else
            continue
        end
        fâ‚€ = softplus.(ğ—ğ°)
        fâ‚ = logistic.(ğ—ğ°) # first derivative
        fâ‚‚ = fâ‚ .* (1 .- fâ‚) # second derivative
        tmp = Î³[i,1].*(fâ‚‚.*Î”t .- ğ².*(fâ‚€.*fâ‚‚ .- fâ‚.^2)./fâ‚€.^2)
        if i < zeroindex
            tmpğ¥ğ¥ .+= ğ›[i]^2 .* tmp
            tmpğ¥ğ® .+= ğ›[i].*tmp
        elseif i > zeroindex
            tmpğ«ğ« .+= ğ›[i]^2 .* tmp
            tmpğ«ğ® .+= ğ›[i].*tmp
        end
        tmpğ®ğ® .+= tmp
    end
    ğ”áµ€_tmpğ¥ğ®_ğš½ = ğ”áµ€*(tmpğ¥ğ®.*ğš½)
    ğ”áµ€_tmpğ«ğ®_ğš½ = ğ”áµ€*(tmpğ«ğ®.*ğš½)
    ğ‡ .= 0
    ğ‡[indicesğ®, indicesğ®] = ğ”áµ€*(tmpğ®ğ®.*ğ”)
    ğ‡[indicesğ¥, indicesğ¥] = ğš½áµ€*(tmpğ¥ğ¥.*ğš½)
    ğ‡[indicesğ«, indicesğ«] = ğš½áµ€*(tmpğ«ğ«.*ğš½)
    ğ‡[indicesğ®, indicesğ¥] = ğ”áµ€_tmpğ¥ğ®_ğš½
    ğ‡[indicesğ®, indicesğ«] = ğ”áµ€_tmpğ«ğ®_ğš½
    ğ‡[indicesğ¥, indicesğ®] = transpose(ğ”áµ€_tmpğ¥ğ®_ğš½)
    ğ‡[indicesğ«, indicesğ®] = transpose(ğ”áµ€_tmpğ«ğ®_ğš½)
    return nothing
end
