"""
    test(datapath)

Run a number of test on the model

ARGUMENT
-`datapath`: full path of the data file

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> datapath = "/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_08_08c_test/T176_2018_05_03/data.mat"
julia> test(datapath)
julia>
```
"""
function test(datapath::String)
    println(" ")
    println("---------")
    println("testing `expectation_of_âˆ‡âˆ‡loglikelihood(Î³, mpGLM, x)`")
    test_expectation_of_âˆ‡âˆ‡loglikelihood!(datapath)
    println(" ")
    println("---------")
    println("testing 'expectation_âˆ‡loglikelihood!(âˆ‡Q, Î³, mpGLM)'")
    test_expectation_âˆ‡loglikelihood!(datapath)
    println(" ")
    println("---------")
    println("testing 'âˆ‡negativeloglikelihood!(âˆ‡nâ„“, memory, model, concatenatedÎ¸)'")
    test_âˆ‡negativeloglikelihood!(datapath)
    println(" ")
    println("---------")
    println("testing hessian of the log-likelihood of the model")
    test_âˆ‡âˆ‡loglikelihood(datapath)
    println("---------")
    println("testing gradient of log evidence")
    model = Model(datapath)
    max_abs_norm_diff_âˆ‡ð¸, abs_norm_diff_ð¸ = FHMDDM.check_âˆ‡logevidence(model; simulate=false)
    println("   max(|Î”ð¸|): ", abs_norm_diff_ð¸)
    println("   max(|Î”âˆ‡ð¸|): ", max_abs_norm_diff_âˆ‡ð¸)
    println("---------")
    println("testing parameter learning")
    model = Model(datapath)
    learnparameters!(model)
    println(" ")
    println("---------")
    println("testing saving model parameters, hessian, and predictions in `test.mat`")
    âˆ‡âˆ‡â„“ = âˆ‡âˆ‡loglikelihood(model)[3]
    Î»Î”t, pchoice = expectedemissions(model)
    save(âˆ‡âˆ‡â„“, Î»Î”t, model, pchoice; filename="test.mat")
    return nothing
end

"""
    test_expectation_of_âˆ‡âˆ‡loglikelihood(datapath)

Check the hessian and gradient of the expectation of the log-likelihood of one neuron's GLM.

The function being checked is used in parameter initialization.
"""
function test_expectation_of_âˆ‡âˆ‡loglikelihood!(datapath::String)
    model = Model(datapath)
    mpGLM = model.trialsets[1].mpGLMs[1]
    Î³ = FHMDDM.randomposterior(mpGLM; rng=MersenneTwister(1234))
    xâ‚€ = concatenateparameters(mpGLM.Î¸; omitb=true)
    nparameters = length(xâ‚€)
    fhand, ghand, hhand = fill(NaN,1), fill(NaN,nparameters),
    fill(NaN,nparameters,nparameters)
    FHMDDM.expectation_of_âˆ‡âˆ‡loglikelihood!(fhand, ghand, hhand, Î³, mpGLM)
    f(x) = FHMDDM.expectation_of_loglikelihood(Î³, mpGLM, x; omitb=true);
    fauto = f(xâ‚€);
    gauto = ForwardDiff.gradient(f, xâ‚€);
    hauto = ForwardDiff.hessian(f, xâ‚€);
    println("   |Î”Q|: ", abs(fauto - fhand[1]))
    println("   max(|Î”gradient|): ", maximum(abs.(gauto .- ghand)))
    println("   max(|Î”hessian|): ", maximum(abs.(hauto .- hhand)))
end

"""
    test_expectation_âˆ‡loglikelihood(datapath)

Check the gradient of the expectation of the log-likelihood of one neuron's GLM.

The function being checked is used in computing the gradient of the log-likelihood of the entire model.
"""
function test_expectation_âˆ‡loglikelihood!(datapath::String)
    model = Model(datapath)
    mpGLM = model.trialsets[1].mpGLMs[1]
    if length(mpGLM.Î¸.b) > 0
        while abs(mpGLM.Î¸.b[1]) < 1e-4
            mpGLM.Î¸.b[1] = 1 - 2rand()
        end
    end
    Î³ = FHMDDM.randomposterior(mpGLM; rng=MersenneTwister(1234))
    âˆ‡Q = FHMDDM.GLMÎ¸(mpGLM.Î¸, eltype(mpGLM.Î¸.ð®))
    FHMDDM.expectation_âˆ‡loglikelihood!(âˆ‡Q, Î³, mpGLM)
    ghand = FHMDDM.concatenateparameters(âˆ‡Q)
    concatenatedÎ¸ = FHMDDM.concatenateparameters(mpGLM.Î¸)
    f(x) = FHMDDM.expectation_of_loglikelihood(Î³, mpGLM, x)
    gauto = ForwardDiff.gradient(f, concatenatedÎ¸)
    println("   max(|Î”gradient|): ", maximum(abs.(gauto .- ghand)))
end

"""
    test_âˆ‡negativeloglikelihood!(datapath)

Check the gradient of the negative of the log-likelihood of the model
"""
function test_âˆ‡negativeloglikelihood!(datapath::String)
    model = Model(datapath)
    for trialset in model.trialsets
        for mpGLM in trialset.mpGLMs
            if length(mpGLM.Î¸.b) > 0
                while abs(mpGLM.Î¸.b[1]) < 1e-4
                    mpGLM.Î¸.b[1] = 1 - 2rand()
                end
            end
        end
    end
    concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
    âˆ‡nâ„“ = similar(concatenatedÎ¸)
    memory = FHMDDM.Memoryforgradient(model)
    FHMDDM.âˆ‡negativeloglikelihood!(âˆ‡nâ„“, memory, model, concatenatedÎ¸)
    f(x) = -FHMDDM.loglikelihood(x, indexÎ¸, model)
    â„“_auto = f(concatenatedÎ¸)
    âˆ‡nâ„“_auto = ForwardDiff.gradient(f, concatenatedÎ¸)
    println("   max(|Î”loss|): ", abs(â„“_auto + memory.â„“[1]))
    println("   max(|Î”gradient|): ", maximum(abs.(âˆ‡nâ„“_auto .- âˆ‡nâ„“)))
end

"""
    test_âˆ‡âˆ‡loglikelihood(datapath)

Check the computation of the hessian of the log-likelihood
"""
function test_âˆ‡âˆ‡loglikelihood(datapath::String)
    model = Model(datapath)
    for trialset in model.trialsets
        for mpGLM in trialset.mpGLMs
            if length(mpGLM.Î¸.b) > 0
                while abs(mpGLM.Î¸.b[1]) < 1e-4
                    mpGLM.Î¸.b[1] = 1 - 2rand()
                end
            end
        end
    end
    absdiffâ„“, absdiffâˆ‡, absdiffâˆ‡âˆ‡ = FHMDDM.check_âˆ‡âˆ‡loglikelihood(model)
    println("   max(|Î”loss|): ", absdiffâ„“)
    println("   max(|Î”gradient|): ", maximum(absdiffâˆ‡))
    println("   max(|Î”hessian|): ", maximum(absdiffâˆ‡âˆ‡))
end
