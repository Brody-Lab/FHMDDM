"""
	maximize_choice_posterior!(model)

Learn the parameters that maximize the L2-regularized log-likelihood of the behavioral choices

OPTIONAL ARGUMENT
-`extended_trace`: save additional information
-`f_tol`: threshold for determining convergence in the objective value
-`g_tol`: threshold for determining convergence in the gradient
-`iterations`: number of inner iterations that will be run before the algorithm gives up
-`outer_iterations`: number of outer iterations that will be run before the algorithm gives up
-`show_every`: trace output is printed every `show_every`th iteration.
-`show_trace`: should a trace of the optimization algorithm's state be shown?
-`x_tol`: threshold for determining convergence in the input vector

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> datapath = "/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_07a/T176_2018_05_03/data.mat"
julia> model = Model(datapath)
julia> FHMDDM.maximize_choice_posterior!(model)
```
"""
function maximize_choice_posterior!(model::Model;
						 L2coefficient::Real=0.1,
		                 extended_trace::Bool=true,
		                 f_tol::AbstractFloat=1e-9,
		                 g_tol::AbstractFloat=1e-8,
		                 iterations::Integer=1000,
		                 show_every::Integer=10,
		                 show_trace::Bool=true,
		                 x_tol::AbstractFloat=1e-5)
	memory = Memoryforgradient(model; choicemodel=true)
    f(concatenatedÎ¸) = -choiceLL!(memory, model, concatenatedÎ¸) + L2coefficient*dot(concatenatedÎ¸,concatenatedÎ¸)
	function g!(âˆ‡, concatenatedÎ¸)
		âˆ‡negativechoiceLL!(âˆ‡, memory, model, concatenatedÎ¸)
		âˆ‡ .+= 2.0.*L2coefficient.*concatenatedÎ¸
		return nothing
	end
    Optim_options = Optim.Options(extended_trace=extended_trace,
								  f_tol=f_tol,
                                  g_tol=g_tol,
                                  iterations=iterations,
                                  show_every=show_every,
                                  show_trace=show_trace,
                                  x_tol=x_tol)
	algorithm = LBFGS(linesearch = LineSearches.BackTracking())
	Î¸â‚€ = concatenate_choice_related_parameters(model)[1]
	optimizationresults = Optim.optimize(f, g!, Î¸â‚€, algorithm, Optim_options)
    println(optimizationresults)
	Î¸â‚˜â‚— = Optim.minimizer(optimizationresults)
	sortparameters!(model, Î¸â‚˜â‚—, memory.indexÎ¸.latentÎ¸)
end

"""
	maximizechoiceLL!(model)

Learn the parameters that maximize the log-likelihood of the behavioral choices

OPTIONAL ARGUMENT
-see documentation of 'maximize_choice_posterior'
"""
function maximizechoiceLL!(model::Model;
		                 extended_trace::Bool=true,
		                 f_tol::AbstractFloat=1e-9,
		                 g_tol::AbstractFloat=1e-8,
		                 iterations::Integer=1000,
		                 show_every::Integer=10,
		                 show_trace::Bool=true,
		                 x_tol::AbstractFloat=1e-5)
	memory = Memoryforgradient(model; choicemodel=true)
    f(concatenatedÎ¸) = -choiceLL!(memory, model, concatenatedÎ¸)
    g!(âˆ‡, concatenatedÎ¸) = âˆ‡negativechoiceLL!(âˆ‡, memory, model, concatenatedÎ¸)
    Optim_options = Optim.Options(extended_trace=extended_trace,
								  f_tol=f_tol,
                                  g_tol=g_tol,
                                  iterations=iterations,
                                  show_every=show_every,
                                  show_trace=show_trace,
                                  x_tol=x_tol)
	algorithm = LBFGS(linesearch = LineSearches.BackTracking())
	Î¸â‚€ = concatenate_choice_related_parameters(model)[1]
	optimizationresults = Optim.optimize(f, g!, Î¸â‚€, algorithm, Optim_options)
    println(optimizationresults)
	Î¸â‚˜â‚— = Optim.minimizer(optimizationresults)
	sortparameters!(model, Î¸â‚˜â‚—, memory.indexÎ¸.latentÎ¸)
end

"""
	choiceLL!(memory, model, concatenatedÎ¸)

Log-likelihood of the choices

MODIFIED ARGUMENT
-`model`: an instance of FHM-DDM
-`memory`: a container of variables used by both the log-likelihood and gradient computation

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: a vector of concatenated parameter values

RETURN
-log-likelihood
"""
function choiceLL!(memory::Memoryforgradient,
					model::Model,
					concatenatedÎ¸::Vector{<:Real})
	if concatenatedÎ¸ != memory.concatenatedÎ¸
		P = update_for_choiceLL!(memory, model, concatenatedÎ¸)
		memory.â„“[1] = 0.0
		@inbounds for trialset in model.trialsets
			for trial in trialset.trials
				choiceLL!(memory, P, model.Î¸native, trial)
			end
		end
	end
	memory.â„“[1]
end

"""
	choiceLL!(memory, P, Î¸native, trial)

Log-likelihood of the choice in a single trial

MODIFIED ARGUMENT
-`memory`: memory allocated for computing the gradient. The log-likelihood is updated.
-`P`: a structure containing allocated memory for computing the accumulator's initial and transition probabilities as well as the partial derivatives of these probabilities

UNMODIFIED ARGUMENT
-`Î¸native`: parameters of the latent variables in native space
-`trial`: a struct containing the stimuli and behavioral response of one trial

RETURN
-log-likelihood
"""
function choiceLL!(memory::Memoryforgradient, P::Probabilityvector, Î¸native::LatentÎ¸, trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒinput, Aáµƒsilent, â„“, Ï€á¶œáµ€ = memory
	priorprobability!(P, trial.previousanswer)
	f = copy(P.ğ›‘)
	if length(clicks.time) > 0
		adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	end
	@inbounds for t = 2:trial.ntimesteps
		if isempty(clicks.inputindex[t])
			Aáµƒ = Aáµƒsilent
		else
			Aáµƒ = Aáµƒinput[clicks.inputindex[t][1]]
			update_for_transition_probabilities!(P, adaptedclicks, clicks, t)
			transitionmatrix!(Aáµƒ, P)
		end
		f = Aáµƒ*f
	end
	conditional_probability_of_choice!(f, trial.choice, Î¸native.Ïˆ[1])
	â„“[1] += log(sum(f))
	return nothing
end

"""
	choiceLL(concatenatedÎ¸, indexÎ¸, model)

ForwardDiff-compatible computation of the log-likelihood of the choices

MODIFIED ARGUMENT
-`model`: an instance of FHM-DDM
-`memory`: a container of variables used by both the log-likelihood and gradient computation

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: a vector of concatenated parameter values

RETURN
-log-likelihood

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_05_test/data.mat"; randomize=true);
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenate_choice_related_parameters(model)
julia> â„“ = FHMDDM.choiceLL(concatenatedÎ¸, indexÎ¸.latentÎ¸, model)
julia> memory = FHMDDM.Memoryforgradient(model; choicemodel=true)
julia> â„“2 = FHMDDM.choiceLL!(memory, model, concatenatedÎ¸) #ForwardDiff-incompatible
julia> abs(â„“2-â„“)
```
"""
function choiceLL(concatenatedÎ¸::Vector{T},
				indexÎ¸::LatentÎ¸,
				model::Model) where {T<:Real}
	model = Model(concatenatedÎ¸, indexÎ¸, model)
	@unpack options, Î¸native, Î¸real, trialsets = model
	@unpack Î”t, Î = options
	Aáµƒinput, Aáµƒsilent = zeros(T,Î,Î), zeros(T,Î,Î)
	expÎ»Î”t = exp(Î¸native.Î»[1]*Î”t)
	dÎ¼_dÎ”c = differentiate_Î¼_wrt_Î”c(Î”t, Î¸native.Î»[1])
	dğ›_dB = (2 .*collect(1:Î) .- Î .- 1)./(Î-2)
	ğ› = Î¸native.B[1].*dğ›_dB
	transitionmatrix!(Aáµƒsilent, expÎ»Î”t.*ğ›, âˆš(Î”t*Î¸native.ÏƒÂ²â‚[1]), ğ›)
	â„“ = zero(T)
	@inbounds for s in eachindex(trialsets)
		for m in eachindex(trialsets[s].trials)
			trial = trialsets[s].trials[m]
			f = probabilityvector(Î¸native.Î¼â‚€[1]+Î¸native.wâ‚•[1]*trial.previousanswer, âˆšÎ¸native.ÏƒÂ²áµ¢[1], ğ›)
			if length(trial.clicks.time) > 0
				adaptedclicks = adapt(trial.clicks, Î¸native.k[1], Î¸native.Ï•[1])
			end
			for t=2:trial.ntimesteps
				if t âˆˆ trial.clicks.inputtimesteps
					cL = sum(adaptedclicks.C[trial.clicks.left[t]])
					cR = sum(adaptedclicks.C[trial.clicks.right[t]])
					ğ› = expÎ»Î”t.*ğ› .+ (cR-cL)*dÎ¼_dÎ”c
					Ïƒ = âˆš((cR+cL)*Î¸native.ÏƒÂ²â‚›[1] + Î”t*Î¸native.ÏƒÂ²â‚[1])
					transitionmatrix!(Aáµƒinput, ğ›, Ïƒ, ğ›)
					Aáµƒ = Aáµƒinput
				else
					Aáµƒ = Aáµƒsilent
				end
				f = Aáµƒ*f
			end
			conditional_probability_of_choice!(f, trial.choice, Î¸native.Ïˆ[1])
			â„“+=log(sum(f))
		end
	end
	â„“
end


"""
	âˆ‡negativechoiceLL!(âˆ‡nâ„“, memory, model, concatenatedÎ¸)

Update the gradient of the negative log-likelihood of choices

MODIFIED ARGUMENT
-`âˆ‡nâ„“`: the vector representing the gradient
-`memory`: memory allocated for computing the gradient. The log-likelihood is updated.
-`model`: structure containing the data, parameters, and hyperparameters of the model

ARGUMENT
-`concatenatedÎ¸`: values of the model's choice-related parameters concatenated into a vector

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_05_test/data.mat"; randomize=true);
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenate_choice_related_parameters(model)
julia> âˆ‡nâ„“ = similar(concatenatedÎ¸)
julia> memory = FHMDDM.Memoryforgradient(model; choicemodel=true)
julia> FHMDDM.âˆ‡negativechoiceLL!(âˆ‡nâ„“, memory, model, concatenatedÎ¸)
julia> using ForwardDiff
julia> f(x) = -FHMDDM.choiceLL(x, indexÎ¸.latentÎ¸, model)
julia> âˆ‡nâ„“_auto = ForwardDiff.gradient(f, concatenatedÎ¸)
julia> maximum(abs.(âˆ‡nâ„“_auto .- âˆ‡nâ„“))

julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_05_test/data.mat"; randomize=true);
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenate_choice_related_parameters(model)
julia> concatenatedÎ¸ = rand(length(concatenatedÎ¸))
julia> â„“ = FHMDDM.choiceLL(concatenatedÎ¸, indexÎ¸.latentÎ¸, model)
julia> âˆ‡nâ„“ = similar(concatenatedÎ¸)
julia> memory = FHMDDM.Memoryforgradient(model; choicemodel=true)
julia> FHMDDM.âˆ‡negativechoiceLL!(âˆ‡nâ„“, memory, model, concatenatedÎ¸)
julia> â„“ = FHMDDM.choiceLL(concatenatedÎ¸, indexÎ¸.latentÎ¸, model)
julia> abs(â„“ - memory.â„“[1])
```

```compare speeds of automatic and hand-coded gradients
julia> using FHMDDM, ForwardDiff, BenchmarkTools
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_05_07a/T176_2018_05_03/data.mat"; randomize=true);
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenate_choice_related_parameters(model);
julia> memory = FHMDDM.Memoryforgradient(model; choicemodel=true);
julia> ghand!(âˆ‡, concatenatedÎ¸) = FHMDDM.âˆ‡negativechoiceLL!(âˆ‡, memory, model, concatenatedÎ¸);
julia> f(x) = FHMDDM.choiceLL(x, indexÎ¸.latentÎ¸, model);
julia> gauto!(âˆ‡, x) = ForwardDiff.gradient!(âˆ‡, f, x);
julia> g1, g2 = similar(concatenatedÎ¸), similar(concatenatedÎ¸);
julia> ghand!(g1, concatenatedÎ¸);
julia> ghand!(g2, concatenatedÎ¸);
julia> maximum(abs.(g1.-g2))
julia> @benchmark ghand!(g1, concatenatedÎ¸) #4.6s
julia> @benchmark gauto!(g2, concatenatedÎ¸) #9.2s
```
"""
function âˆ‡negativechoiceLL!(âˆ‡nâ„“::Vector{<:Real},
							memory::Memoryforgradient,
							model::Model,
						    concatenatedÎ¸::Vector{<:Real})
	if concatenatedÎ¸ != memory.concatenatedÎ¸
		P = update_for_choiceLL!(memory, model, concatenatedÎ¸)
	else
		P = Probabilityvector(model.options.Î”t, model.Î¸native, model.options.Î)
	end
	âˆ‡choiceLL!(memory,model,P)
	indexall = 0
	indexfit = 0
	for field in fieldnames(LatentÎ¸)
		indexall+=1
		if (getfield(memory.indexÎ¸.latentÎ¸, field)[1] > 0) && (field != :Aá¶œâ‚â‚) && (field != :Aá¶œâ‚‚â‚‚) && (field != :Ï€á¶œâ‚)
			indexfit +=1
			âˆ‡nâ„“[indexfit] = -memory.âˆ‡â„“latent[indexall]
		end
	end
	native2real!(âˆ‡nâ„“, memory.indexÎ¸.latentÎ¸, model)
end

"""
	âˆ‡choiceLL!(memory, model, P)

Update the gradient of the log-likelihood of the choices across trialsets

MODIFIED ARGUMENT
-`memory`: memory allocated for computing the gradient. The log-likelihood is updated.
-`P`: a structure containing allocated memory for computing the accumulator's initial and transition probabilities as well as the partial derivatives of these probabilities

UNMODIFIED ARGUMENT
-`Î¸native`: parameters of the latent variables in native space
-`trial`: a struct containing the stimuli and behavioral response of one trial
"""
function âˆ‡choiceLL!(memory::Memoryforgradient, model::Model, P::Probabilityvector)
	memory.â„“ .= 0.0
	memory.âˆ‡â„“latent .= 0.0
	@inbounds for trialset in model.trialsets
		for trial in trialset.trials
			âˆ‡choiceLL!(memory, P, model.Î¸native, trial)
		end
	end
	return nothing
end

"""
	âˆ‡choiceLL!(memory, P, Î¸native, trial)

Update the gradient of the log-likelihood of the choice in one trial

MODIFIED ARGUMENT
-`memory`: memory allocated for computing the gradient. The log-likelihood is updated.
-`P`: a structure containing allocated memory for computing the accumulator's initial and transition probabilities as well as the partial derivatives of these probabilities

UNMODIFIED ARGUMENT
-`Î¸native`: parameters of the latent variables in native space
-`trial`: a struct containing the stimuli and behavioral response of one trial
"""
function âˆ‡choiceLL!(memory::Memoryforgradient,
					P::Probabilityvector,
					Î¸native::LatentÎ¸,
					trial::Trial)
	@unpack clicks = trial
	@unpack inputtimesteps, inputindex = clicks
	@unpack Aáµƒinput, âˆ‡Aáµƒinput, Aáµƒsilent, âˆ‡Aáµƒsilent, D, f, indexÎ¸_paâ‚, indexÎ¸_paâ‚œaâ‚œâ‚‹â‚, indexÎ¸_Ïˆ, â„“, âˆ‡â„“latent, nÎ¸_paâ‚, nÎ¸_paâ‚œaâ‚œâ‚‹â‚, âˆ‡paâ‚, Î = memory
	t = 1
	âˆ‡priorprobability!(âˆ‡paâ‚, P, trial.previousanswer)
	f[t] .= P.ğ›‘
	if length(clicks.time) > 0
		adaptedclicks = âˆ‡adapt(trial.clicks, Î¸native.k[1], Î¸native.Ï•[1])
	end
	@inbounds for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			clickindex = clicks.inputindex[t][1]
			Aáµƒ = Aáµƒinput[clickindex]
			âˆ‡Aáµƒ = âˆ‡Aáµƒinput[clickindex]
			update_for_âˆ‡transition_probabilities!(P, adaptedclicks, clicks, t)
			âˆ‡transitionmatrix!(âˆ‡Aáµƒ, Aáµƒ, P)
		else
			Aáµƒ = Aáµƒsilent
		end
		f[t] = Aáµƒ * f[t-1]
	end
	pğ‘‘_a = conditional_probability_of_choice(trial.choice, Î¸native.Ïˆ[1], Î)
	pğ‘‘ = dot(pğ‘‘_a, f[trial.ntimesteps])
	â„“[1] += log(pğ‘‘)
	b = pğ‘‘_a./pğ‘‘ # backward term for the last time step
	Î³ = b.*f[trial.ntimesteps] # posterior probability for the last time step
	âˆ‡â„“latent[indexÎ¸_Ïˆ[1]] += expectation_derivative_logpğ‘‘_wrt_Ïˆ(trial.choice, Î³, Î¸native.Ïˆ[1])
	@inbounds for t = trial.ntimesteps:-1:1
		if t < trial.ntimesteps
			if t+1 âˆˆ clicks.inputtimesteps
				clickindex = clicks.inputindex[t+1][1]
				Aáµƒâ‚œâ‚Šâ‚ = Aáµƒinput[clickindex]
			else
				Aáµƒâ‚œâ‚Šâ‚ = Aáµƒsilent
			end
			b = transpose(Aáµƒâ‚œâ‚Šâ‚) * b
		end
		if t > 1
			if t âˆˆ clicks.inputtimesteps
				clickindex = clicks.inputindex[t][1]
				âˆ‡Aáµƒ = âˆ‡Aáµƒinput[clickindex]
			else
				âˆ‡Aáµƒ = âˆ‡Aáµƒsilent
			end
			for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
				âˆ‡â„“latent[indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]] += (transpose(b)*âˆ‡Aáµƒ[i]*f[t-1])[1]
			end
		end
	end
	@inbounds for i = 1:nÎ¸_paâ‚
		âˆ‡â„“latent[indexÎ¸_paâ‚[i]] += dot(b, âˆ‡paâ‚[i])
	end
	return nothing
end

"""
    conditional_probability_of_choice!(f, choice, Ïˆ)

Probability of a choice conditioned on the accumulator state

ARGUMENT
-`choice`: the observed choice, either right (`choice`=true) or left.
-`Ïˆ`: the prior probability of a lapse state

RETURN
`p`: conditional probability of the choice
"""
function conditional_probability_of_choice(choice::Bool, Ïˆ::T, Î::Integer) where {T<:Real}
	p = zeros(T, Î)
	zeroindex = cld(Î,2)
    p[zeroindex] = 0.5
    if choice
        p[1:zeroindex-1]   .= Ïˆ/2
        p[zeroindex+1:end] .= 1-Ïˆ/2
    else
        p[1:zeroindex-1]   .= 1-Ïˆ/2
        p[zeroindex+1:end] .= Ïˆ/2
    end
	p
end

"""
    conditional_probability_of_choice!(f, choice, Ïˆ)

Probability of a choice conditioned on the accumulator state

MODIFIED ARGUMENT
-`f`: the forward term

ARGUMENT
-`choice`: the observed choice, either right (`choice`=true) or left.
-`Ïˆ`: the prior probability of a lapse state
"""
function conditional_probability_of_choice!(f::Array{<:Real}, choice::Bool, Ïˆ::Real)
	Î = length(f)
	zeroindex = cld(Î,2)
    f[zeroindex] *= 0.5
    if choice
        f[1:zeroindex-1]   .*= Ïˆ/2
        f[zeroindex+1:end] .*= 1-Ïˆ/2
    else
        f[1:zeroindex-1]   .*= 1-Ïˆ/2
        f[zeroindex+1:end] .*= Ïˆ/2
    end
    return nothing
end

"""
	update_for_choiceLL!(model, memory, concatenatedÎ¸)

Update the model and the memory quantities according to new parameter values

MODIFIED ARGUMENT
-`memory`: structure containing variables memory between computations of the model's log-likelihood and its gradient
-`model`: structure with information concerning a factorial hidden Markov drift-diffusion model

ARGUMENT
-`concatenatedÎ¸`: newest values of the model's parameters

RETURN
-`P`: an instance of `Probabilityvector`

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_27_test/data.mat"; randomize=true);
julia> memory, P = FHMDDM.Memoryforgradient(model; choicemodel=true)
julia> P = update_for_choiceLL!(model, memory, rand(length(memory.concatenatedÎ¸)))
"""
function update_for_choiceLL!(memory::Memoryforgradient,
							 model::Model,
							 concatenatedÎ¸::Vector{<:Real})
	memory.concatenatedÎ¸ .= concatenatedÎ¸
	sortparameters!(model, memory.concatenatedÎ¸, memory.indexÎ¸.latentÎ¸)
	real2native!(model.Î¸native, model.options, model.Î¸real)
	@unpack options, Î¸native = model
	@unpack Î”t, K, Î = options
	P = Probabilityvector(Î”t, Î¸native, Î)
	update_for_âˆ‡transition_probabilities!(P)
	âˆ‡transitionmatrix!(memory.âˆ‡Aáµƒsilent, memory.Aáµƒsilent, P)
	return P
end
