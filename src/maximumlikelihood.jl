"""
    maximizelikelihood!(model)

Learn the parameters of the factorial hidden Markov drift-diffusion model by maximizing the likelihood of the data

MODIFIED ARGUMENT
- a structure containing information for a factorial hidden Markov drift-diffusion model

OPTIONAL ARGUMENT
-`extended_trace`: save additional information
-`f_tol`: threshold for determining convergence in the objective value
-`g_tol`: threshold for determining convergence in the gradient
-`iterations`: number of inner iterations that will be run before the algorithm gives up
-`outer_iterations`: number of outer iterations that will be run before the algorithm gives up
-`show_every`: trace output is printed every `show_every`th iteration.
-`show_trace`: should a trace of the optimization algorithm's state be shown?
-`x_tol`: threshold for determining convergence in the input vector
"""
function maximizelikelihood!(model::Model;
			                 extended_trace::Bool=true,
			                 f_tol::AbstractFloat=1e-9,
			                 g_tol::AbstractFloat=1e-8,
			                 iterations::Integer=1000,
							 outer_iterations::Integer=10,
			                 show_every::Integer=1,
			                 show_trace::Bool=true,
			                 x_tol::AbstractFloat=1e-5)
	shared = Shared(model)
	@unpack K, Î = model.options
	Î³ =	map(model.trialsets) do trialset
			map(CartesianIndices((Î,K))) do index
				zeros(trialset.ntimesteps)
			end
		end
    f(concatenatedÎ¸) = -loglikelihood!(model, shared, concatenatedÎ¸)
    g!(âˆ‡, concatenatedÎ¸) = âˆ‡negativeloglikelihood!(âˆ‡, Î³, model, shared, concatenatedÎ¸)
	# lowerbounds, upperbounds = concatenatebounds(shared.indexÎ¸, model.options)
    Optim_options = Optim.Options(extended_trace=extended_trace,
								  f_tol=f_tol,
                                  g_tol=g_tol,
                                  iterations=iterations,
								  outer_iterations=outer_iterations,
                                  show_every=show_every,
                                  show_trace=show_trace,
                                  x_tol=x_tol)
	# algorithm = Fminbox(LBFGS(linesearch = LineSearches.BackTracking()))
	algorithm = LBFGS(linesearch = LineSearches.BackTracking())
	Î¸â‚€ = deepcopy(shared.concatenatedÎ¸)
	# optimizationresults = Optim.optimize(f, g!, lowerbounds, upperbounds, Î¸â‚€, algorithm, Optim_options)
	optimizationresults = Optim.optimize(f, g!, Î¸â‚€, algorithm, Optim_options)
    println(optimizationresults)
    maximumlikelihoodÎ¸ = Optim.minimizer(optimizationresults)
	sortparameters!(model, maximumlikelihoodÎ¸, shared.indexÎ¸)
    return nothing
end

"""
    loglikelihood!(model, shared, concatenatedÎ¸)

Compute the log-likelihood

ARGUMENT
-`model`: an instance of FHM-DDM
-`shared`: a container of variables used by both the log-likelihood and gradient computation

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: a vector of concatenated parameter values

RETURN
-log-likelihood
"""
function loglikelihood!(model::Model,
						shared::Shared,
					    concatenatedÎ¸::Vector{<:Real})
	if concatenatedÎ¸ != shared.concatenatedÎ¸
		update!(model, shared, concatenatedÎ¸)
	end
	@unpack options, Î¸native, trialsets = model
	trialinvariant = Trialinvariant(options, Î¸native; purpose="loglikelihood")
	â„“ = map(trialsets, shared.pğ˜ğ‘‘) do trialset, pğ˜ğ‘‘
			pmap(trialset.trials, pğ˜ğ‘‘) do trial, pğ˜ğ‘‘
				loglikelihood(pğ˜ğ‘‘, Î¸native, trial, trialinvariant)
			end
		end
	return sum(sum(â„“))
end

"""
	loglikelihood(pğ˜ğ‘‘, trialinvariant, Î¸native, trial)

Compute the log-likelihood of the data from one trial

ARGUMENT
-`pğ˜ğ‘‘`: a matrix whose element `pğ˜ğ‘‘[t][i,j]` represents the conditional likelihood `p(ğ˜â‚œ, d âˆ£ ğšâ‚œ=i, ğœâ‚œ=j)`
-`Î¸native`: model parameters in their native space
-`trial`: stimulus and behavioral information of one trial
-`trialinvariant`: a structure containing quantities that are used in each trial

RETURN
-`â„“`: log-likelihood of the data from one trial
"""
function loglikelihood(pğ˜ğ‘‘::Vector{<:Matrix{<:Real}},
					   Î¸native::LatentÎ¸,
					   trial::Trial,
					   trialinvariant::Trialinvariant)
	@unpack clicks = trial
	@unpack Aáµƒsilent, Aá¶œáµ€, Î”t, Ï€á¶œáµ€, ğ›, Î = trialinvariant
	C = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	Î¼ = Î¸native.Î¼â‚€[1] + trial.previousanswer*Î¸native.wâ‚•[1]
	Ïƒ = âˆšÎ¸native.ÏƒÂ²áµ¢[1]
	Ï€áµƒ = probabilityvector(Î¼, Ïƒ, ğ›)
	f = pğ˜ğ‘‘[1] .* Ï€áµƒ .* Ï€á¶œáµ€
	D = sum(f)
	f /= D
	â„“ = log(D)
	T = eltype(pğ˜ğ‘‘[1])
	Aáµƒ = zeros(T, Î, Î)
	@inbounds for t = 2:trial.ntimesteps
		if isempty(clicks.inputindex[t])
			f = Aáµƒsilent * f * Aá¶œáµ€
		else
			cL = sum(C[clicks.left[t]])
			cR = sum(C[clicks.right[t]])
			stochasticmatrix!(Aáµƒ, cL, cR, trialinvariant, Î¸native)
			f = Aáµƒ * f * Aá¶œáµ€
		end
		f .*= pğ˜ğ‘‘[t]
		D = sum(f)
		f /= D
		â„“ += log(D)
	end
	return â„“
end

"""
    âˆ‡negativeloglikelihood!(âˆ‡, Î³, model, shared, concatenatedÎ¸)

Gradient of the negative log-likelihood of the factorial hidden Markov drift-diffusion model

MODIFIED INPUT
-`âˆ‡`: a vector of partial derivatives
-`Î³`: posterior probability of the latent variables
-`model`: a structure containing information of the factorial hidden Markov drift-diffusion model
-`shared`: structure containing variables shared between computations of the model's log-likelihood and its gradient

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: parameter values concatenated into a vetor
"""
function âˆ‡negativeloglikelihood!(âˆ‡::Vector{<:AbstractFloat},
								 Î³::Vector{<:Matrix{<:Vector{<:AbstractFloat}}},
								 model::Model,
								 shared::Shared,
								 concatenatedÎ¸::Vector{<:AbstractFloat})
	if concatenatedÎ¸ != shared.concatenatedÎ¸
		update!(model, shared, concatenatedÎ¸)
	end
	@unpack indexÎ¸, pğ˜ğ‘‘ = shared
	@unpack options, Î¸native, Î¸real, trialsets = model
	@unpack K = options
	trialinvariant = Trialinvariant(options, Î¸native; purpose="gradient")
	output=	map(trialsets, pğ˜ğ‘‘) do trialset, pğ˜ğ‘‘
				pmap(trialset.trials, pğ˜ğ‘‘) do trial, pğ˜ğ‘‘
					âˆ‡loglikelihood(pğ˜ğ‘‘, trialinvariant, Î¸native, trial)
				end
			end
	latentâˆ‡ = output[1][1][1] # reuse this memory
	for field in fieldnames(LatentÎ¸)
		latentâˆ‚ = getfield(latentâˆ‡, field)
		for i in eachindex(output)
			start = i==1 ? 2 : 1
			for m in start:length(output[i])
				latentâˆ‚[1] += getfield(output[i][m][1], field)[1] #output[i][m][1] are the partial derivatives
			end
		end
	end
	latentâˆ‡.B[1] *= Î¸native.B[1]*logistic(-Î¸real.B[1])
	latentâˆ‡.k[1] *= Î¸native.k[1]
	latentâˆ‡.Ï•[1] *= Î¸native.Ï•[1]*(1.0 - Î¸native.Ï•[1])
	latentâˆ‡.ÏƒÂ²â‚[1] *= Î¸native.ÏƒÂ²â‚[1]
	latentâˆ‡.ÏƒÂ²áµ¢[1] *= Î¸native.ÏƒÂ²áµ¢[1]
	latentâˆ‡.ÏƒÂ²â‚›[1] *= Î¸native.ÏƒÂ²â‚›[1]
	for field in fieldnames(LatentÎ¸)
		index = getfield(indexÎ¸.latentÎ¸,field)[1]
		if index != 0
			âˆ‡[index] = -getfield(latentâˆ‡,field)[1] # note the negative sign
		end
	end
	@inbounds for i in eachindex(output)
        t = 0
        for m in eachindex(output[i])
            for tâ‚˜ in eachindex(output[i][m][2]) # output[i][m][2] is `fb` of trial `m` in trialset `i`
                t += 1
                for jk in eachindex(output[i][m][2][tâ‚˜])
                    Î³[i][jk][t] = output[i][m][2][tâ‚˜][jk]
                end
            end
        end
    end
	Páµ¤ = length(trialsets[1].mpGLMs[1].ğ®)
	Pâ‚— = length(trialsets[1].mpGLMs[1].ğ¥)
	for i in eachindex(trialsets)
		âˆ‡ğ° = pmap(mpGLM->âˆ‡negativeexpectation(Î³[i], mpGLM), trialsets[i].mpGLMs)
		for n in eachindex(trialsets[i].mpGLMs)
			âˆ‡[indexÎ¸.ğ®[i][n]] .= âˆ‡ğ°[n][1:Páµ¤]
			âˆ‡[indexÎ¸.ğ¥[i][n]] .= âˆ‡ğ°[n][Páµ¤+1:Páµ¤+Pâ‚—]
			âˆ‡[indexÎ¸.ğ«[i][n]] .= âˆ‡ğ°[n][Páµ¤+Pâ‚—+1:end]
		end
	end
	return nothing
end

"""
	âˆ‡loglikelihood(pğ˜ğ‘‘, trialinvariant, Î¸native, trial)

Compute quantities needed for the gradient of the log-likelihood of the data observed in one trial

ARGUMENT
-`pğ˜ğ‘‘`: A vector of matrices of floating-point numbers whose element `pğ˜ğ‘‘[t][i,j]` represents the likelihood of the emissions (spike trains and choice) at time step `t` conditioned on the accumulator variable being in state `i` and the coupling variable in state `j`
-`trialinvariant`: structure containing quantities used across trials
-`Î¸native`: parameters for the latent variables in their native space
-`trial`: information on the stimuli and behavioral choice of one trial

RETURN
-`latentâˆ‡`: gradient of the log-likelihood of the data observed in one trial with respect to the parameters specifying the latent variables
-`fb`: joint posterior probabilities of the accumulator and coupling variables
"""
function âˆ‡loglikelihood(pğ˜ğ‘‘::Vector{<:Matrix{<:AbstractFloat}},
						trialinvariant::Trialinvariant,
						Î¸native::LatentÎ¸,
						trial::Trial)
	@unpack clicks = trial
	@unpack inputtimesteps, inputindex = clicks
	@unpack Aáµƒsilent, dAáµƒsilentdÎ¼, dAáµƒsilentdÏƒÂ², dAáµƒsilentdB, Aá¶œ, Aá¶œáµ€, Î”t, K, ğ›š, Ï€á¶œáµ€, Î, ğ› = trialinvariant
	dâ„“dk, dâ„“dÎ», dâ„“dÏ•, dâ„“dÏƒÂ²â‚, dâ„“dÏƒÂ²â‚›, dâ„“dB = 0., 0., 0., 0., 0., 0.
	âˆ‘Ï‡á¶œ = zeros(K,K)
	Î¼ = Î¸native.Î¼â‚€[1] + trial.previousanswer*Î¸native.wâ‚•[1]
	Ïƒ = âˆšÎ¸native.ÏƒÂ²áµ¢[1]
	Ï€áµƒ, dÏ€áµƒdÎ¼, dÏ€áµƒdÏƒÂ², dÏ€áµƒdB = zeros(Î), zeros(Î), zeros(Î), zeros(Î)
	probabilityvector!(Ï€áµƒ, dÏ€áµƒdÎ¼, dÏ€áµƒdÏƒÂ², dÏ€áµƒdB, Î¼, ğ›š, Ïƒ, ğ›)
	n_steps_with_input = length(clicks.inputtimesteps)
	Aáµƒ = map(x->zeros(Î,Î), clicks.inputtimesteps)
	dAáµƒdÎ¼ = map(x->zeros(Î,Î), clicks.inputtimesteps)
	dAáµƒdÏƒÂ² = map(x->zeros(Î,Î), clicks.inputtimesteps)
	dAáµƒdB = map(x->zeros(Î,Î), clicks.inputtimesteps)
	Î”c = zeros(n_steps_with_input)
	âˆ‘c = zeros(n_steps_with_input)
	C, dCdk, dCdÏ• = âˆ‡adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	for i in 1:n_steps_with_input
		t = clicks.inputtimesteps[i]
		cL = sum(C[clicks.left[t]])
		cR = sum(C[clicks.right[t]])
		stochasticmatrix!(Aáµƒ[i], dAáµƒdÎ¼[i], dAáµƒdÏƒÂ²[i], dAáµƒdB[i], cL, cR, trialinvariant, Î¸native)
		Î”c[i] = cR-cL
		âˆ‘c[i] = cL+cR
	end
	D, f = forward(Aáµƒ, inputindex, Ï€áµƒ, pğ˜ğ‘‘, trialinvariant)
	fb = f # reuse memory
	b = ones(Î,K)
	Aá¶œreshaped = reshape(Aá¶œ, 1, 1, K, K)
	Î»Î”t = Î¸native.Î»[1]*Î”t
	expÎ»Î”t = exp(Î»Î”t)
	dÎ¼dÎ”c = (expÎ»Î”t - 1.0)/Î»Î”t
	Î· = (expÎ»Î”t - dÎ¼dÎ”c)/Î¸native.Î»[1]
	ğ›áµ€Î”texpÎ»Î”t = transpose(ğ›)*Î”t*expÎ»Î”t
	@inbounds for t = trial.ntimesteps:-1:1
		if t < trial.ntimesteps # backward step
			Aáµƒâ‚œâ‚Šâ‚ = isempty(inputindex[t+1]) ? Aáµƒsilent : Aáµƒ[inputindex[t+1][1]]
			b .*= pğ˜ğ‘‘[t+1]
			b = transpose(Aáµƒâ‚œâ‚Šâ‚) * b * Aá¶œ / D[t+1]
			fb[t] .*= b
		end
		if t > 1 # joint posterior over consecutive time bins, computations involving the transition matrix
			if isempty(inputindex[t])
				Aáµƒâ‚œ = Aáµƒsilent
				dAáµƒâ‚œdÎ¼ = dAáµƒsilentdÎ¼
				dAáµƒâ‚œdÏƒÂ² = dAáµƒsilentdÏƒÂ²
				dAáµƒâ‚œdB = dAáµƒsilentdB
			else
				i = inputindex[t][1]
				Aáµƒâ‚œ = Aáµƒ[i]
				dAáµƒâ‚œdÎ¼ = dAáµƒdÎ¼[i]
				dAáµƒâ‚œdÏƒÂ² = dAáµƒdÏƒÂ²[i]
				dAáµƒâ‚œdB = dAáµƒdB[i]
			end
			Ï‡_oslash_Aáµƒ = reshape(pğ˜ğ‘‘[t].*b, Î, 1, K, 1) .* reshape(f[t-1], 1, Î, 1, K) .* Aá¶œreshaped ./ D[t]
	        âˆ‘Ï‡á¶œ += dropdims(sum(Ï‡_oslash_Aáµƒ.*Aáµƒâ‚œ, dims=(1,2)); dims=(1,2))
			Ï‡áµƒ_Aáµƒ = dropdims(sum(Ï‡_oslash_Aáµƒ, dims=(3,4)); dims=(3,4))
			Ï‡áµƒ_dlogAáµƒdÎ¼ = Ï‡áµƒ_Aáµƒ .* dAáµƒâ‚œdÎ¼ # Ï‡áµƒâŠ™ d/dÎ¼{log(Aáµƒ)} = Ï‡áµƒâŠ˜ AáµƒâŠ™ d/dÎ¼{Aáµƒ}
			âˆ‘_Ï‡áµƒ_dlogAáµƒdÎ¼ = sum(Ï‡áµƒ_dlogAáµƒdÎ¼)
			âˆ‘_Ï‡áµƒ_dlogAáµƒdÏƒÂ² = sum(Ï‡áµƒ_Aáµƒ .* dAáµƒâ‚œdÏƒÂ²) # similarly, Ï‡áµƒâŠ™ d/dÏƒÂ²{log(Aáµƒ)} = Ï‡áµƒâŠ˜ AáµƒâŠ™ d/dÏƒÂ²{Aáµƒ}
			dâ„“dÏƒÂ²â‚ += âˆ‘_Ï‡áµƒ_dlogAáµƒdÏƒÂ² # the Î”t is multiplied after summing across time steps
			dâ„“dB += sum(Ï‡áµƒ_Aáµƒ .* dAáµƒâ‚œdB)
			if isempty(inputindex[t])
				dÎ¼dÎ» = ğ›áµ€Î”texpÎ»Î”t
			else
				dÎ¼dÎ» = ğ›áµ€Î”texpÎ»Î”t .+ Î”c[i].*Î·
				dâ„“dÏƒÂ²â‚› += âˆ‘_Ï‡áµƒ_dlogAáµƒdÏƒÂ²*âˆ‘c[i]
				dcLdÏ• = sum(dCdÏ•[clicks.left[t]])
				dcRdÏ• = sum(dCdÏ•[clicks.right[t]])
				dcLdk = sum(dCdk[clicks.left[t]])
				dcRdk = sum(dCdk[clicks.right[t]])
				dÏƒÂ²dÏ• = Î¸native.ÏƒÂ²â‚›[1]*(dcLdÏ• + dcRdÏ•)
				dÏƒÂ²dk = Î¸native.ÏƒÂ²â‚›[1]*(dcLdk + dcRdk)
				dâ„“dÏ• += âˆ‘_Ï‡áµƒ_dlogAáµƒdÎ¼*dÎ¼dÎ”c*(dcRdÏ• - dcLdÏ•) + âˆ‘_Ï‡áµƒ_dlogAáµƒdÏƒÂ²*dÏƒÂ²dÏ•
				dâ„“dk += âˆ‘_Ï‡áµƒ_dlogAáµƒdÎ¼*dÎ¼dÎ”c*(dcRdk - dcLdk) + âˆ‘_Ï‡áµƒ_dlogAáµƒdÏƒÂ²*dÏƒÂ²dk
			end
			dâ„“dÎ» += sum(Ï‡áµƒ_dlogAáµƒdÎ¼.*dÎ¼dÎ»)
		end
	end
	dâ„“dÏƒÂ²â‚ *= Î”t
	dâ„“dAá¶œâ‚â‚ = âˆ‘Ï‡á¶œ[1,1]*Aá¶œ[2,1] - âˆ‘Ï‡á¶œ[2,1]*Aá¶œ[1,1]
	dâ„“dAá¶œâ‚‚â‚‚ = âˆ‘Ï‡á¶œ[2,2]*Aá¶œ[1,2] - âˆ‘Ï‡á¶œ[1,2]*Aá¶œ[2,2]
	âˆ‘Î³á¶œâ‚ = sum(fb[1], dims=1)
	dâ„“dxÏ€á¶œâ‚ = âˆ‘Î³á¶œâ‚[1] - Î¸native.Ï€á¶œâ‚[1]
	Î³áµƒâ‚_oslash_Ï€áµƒ = sum(pğ˜ğ‘‘[1] .* Ï€á¶œáµ€ ./ D[1] .* b, dims=2)
	âˆ‘_Î³áµƒâ‚_dlogÏ€áµƒdÎ¼ = Î³áµƒâ‚_oslash_Ï€áµƒ â‹… dÏ€áµƒdÎ¼ # similar to above, Î³áµƒâ‚âŠ™ d/dÎ¼{log(Ï€áµƒ)} = Î³áµƒâ‚âŠ˜ Ï€áµƒâŠ™ d/dÎ¼{Ï€áµƒ}
	dâ„“dÎ¼â‚€ = âˆ‘_Î³áµƒâ‚_dlogÏ€áµƒdÎ¼
	dâ„“dwâ‚• = âˆ‘_Î³áµƒâ‚_dlogÏ€áµƒdÎ¼ * trial.previousanswer
	dâ„“dÏƒÂ²áµ¢ = Î³áµƒâ‚_oslash_Ï€áµƒ â‹… dÏ€áµƒdÏƒÂ²
	dâ„“dB += Î³áµƒâ‚_oslash_Ï€áµƒ â‹… dÏ€áµƒdB
	dâ„“dxÏˆ = differentiateâ„“_wrt_xÏˆ(trial.choice, f[end], Î¸native.Ïˆ[1])
	latentâˆ‡ = LatentÎ¸(	Aá¶œâ‚â‚ = [dâ„“dAá¶œâ‚â‚],
						Aá¶œâ‚‚â‚‚ = [dâ„“dAá¶œâ‚‚â‚‚],
						k	 = [dâ„“dk],
						Î»	 = [dâ„“dÎ»],
						Î¼â‚€	 = [dâ„“dÎ¼â‚€],
						Ï•	 = [dâ„“dÏ•],
						Ï€á¶œâ‚	 = [dâ„“dxÏ€á¶œâ‚],
						Ïˆ	 = [dâ„“dxÏˆ],
						ÏƒÂ²â‚	 = [dâ„“dÏƒÂ²â‚],
						ÏƒÂ²áµ¢	 = [dâ„“dÏƒÂ²áµ¢],
						ÏƒÂ²â‚›	 = [dâ„“dÏƒÂ²â‚›],
						wâ‚•	 = [dâ„“dwâ‚•],
						B	 = [dâ„“dB])
	return latentâˆ‡, fb
end

"""
	forward(Aáµƒ, inputindex, Ï€áµƒ, pğ˜d, trialinvariant)

Forward pass of the forward-backward algorithm

ARGUMENT
-`Aáµƒ`: transition probabilities of the accumulator variable. Aáµƒ[t][j,k] â‰¡ p(aâ‚œ=Î¾â±¼ âˆ£ aâ‚œâ‚‹â‚=Î¾â‚–)
`inputindex`: index of the time steps with auditory input. For time step `t`, if the element `inputindex[t]` is nonempty, then `Aáµƒ[inputindex[t][1]]` is the transition matrix for that time step. If `inputindex[t]` is empty, then the corresponding transition matrix is `Aáµƒsilent`.
-`Ï€áµƒ`: a vector of floating-point numbers specifying the prior probability of each accumulator state
-`pğ˜ğ‘‘`: likelihood of the emissions in each time bin in this trial. pğ˜ğ‘‘[t][j,k] = âˆâ‚™ p(ğ²â‚™(t) âˆ£ ğ‘â‚œ=Î¾â±¼, ğ‘§â‚œ=k) and pğ˜ğ‘‘[end][j,k] = p(ğ‘‘âˆ£ ğ‘â‚œ=Î¾â±¼, ğ‘§â‚œ=k) âˆâ‚™ p(ğ²â‚™(t) âˆ£ ğ‘â‚œ=Î¾â±¼, ğ‘§â‚œ=k)
-`trialinvariant`: a structure containing quantities that are used in each trial

RETURN
-`D`: scaling factors with element `D[t]` â‰¡ p(ğ˜â‚œ âˆ£ ğ˜â‚, ... ğ˜â‚œâ‚‹â‚)
-`f`: Forward recursion terms. `f[t][j,k]` â‰¡ p(aâ‚œ=Î¾â±¼, zâ‚œ=k âˆ£ ğ˜â‚, ... ğ˜â‚œ) where ğ˜ refers to all the spike trains

"""
function forward(Aáµƒ::Vector{<:Matrix{<:AbstractFloat}},
 				 inputindex::Vector{<:Vector{<:Integer}},
				 Ï€áµƒ::Vector{<:AbstractFloat},
				 pğ˜ğ‘‘::Vector{<:Matrix{<:AbstractFloat}},
				 trialinvariant::Trialinvariant)
	@unpack Aáµƒsilent, Aá¶œáµ€, K, Ï€á¶œáµ€, Î, ğ› = trialinvariant
	ntimesteps = length(inputindex)
	f = map(x->zeros(Î,K), 1:ntimesteps)
	D = zeros(ntimesteps)
	f[1] = pğ˜ğ‘‘[1] .* Ï€áµƒ .* Ï€á¶œáµ€
	D[1] = sum(f[1])
	f[1] /= D[1]
	@inbounds for t = 2:ntimesteps
		if isempty(inputindex[t])
			Aáµƒâ‚œ = Aáµƒsilent
		else
			i = inputindex[t][1]
			Aáµƒâ‚œ = Aáµƒ[i]
		end
		f[t] = Aáµƒâ‚œ * f[t-1] * Aá¶œáµ€
		f[t] .*= pğ˜ğ‘‘[t]
		D[t] = sum(f[t])
		f[t] /= D[t]
	end
	return D,f
end

"""
	differentiateâ„“wrtÏˆ(choice, Î³_end, Ïˆ)

Partial derivative of the log-likelihood of the data from one trial with respect to the lapse rate Ïˆ

ARGUMENT
-`choice`: a Boolean specifying whether the choice was to the right
-`Î³_end`: a matrix of floating-point numbers representing the posterior likelihood of the latent variables at the end of the trial (i.e., last time step). Element `Î³_end[i,j]` = p(aáµ¢=1, câ±¼=1 âˆ£ ğ˜, d). Rows correspond to states of the accumulator state variable ğš, and columns to states of the coupling variable ğœ.
-`Ïˆ`: a floating-point number specifying the lapse rate

RETURN
-a floating-point number quantifying the partial derivative of the log-likelihood of one trial's data with respect to the lapse rate Ïˆ
"""
function differentiateâ„“wrtÏˆ(choice::Bool, Î³_end::Array{<:AbstractFloat}, Ïˆ::AbstractFloat)
	Î³áµƒ_end = sum(Î³_end, dims=2)
	zeroindex = cld(length(Î³áµƒ_end), 2)
	# Î³áµƒ_end0_div2 = Î³áµƒ_end[zeroindex]/2
	if choice
		choiceconsistent   = sum(Î³áµƒ_end[zeroindex+1:end])
		choiceinconsistent = sum(Î³áµƒ_end[1:zeroindex-1])
	else
		choiceconsistent   = sum(Î³áµƒ_end[1:zeroindex-1])
		choiceinconsistent = sum(Î³áµƒ_end[zeroindex+1:end])
	end
	return choiceconsistent/(Ïˆ-2) + choiceinconsistent/Ïˆ
end

"""
	differentiateâ„“_wrt_xÏˆ(choice, Î³_end, Ïˆ)

Partial derivative of the log-likelihood of the data from one trial with respect to the lapse rate Ïˆ in real space

ARGUMENT
-`choice`: a Boolean specifying whether the choice was to the right
-`Î³_end`: a matrix of floating-point numbers representing the posterior likelihood of the latent variables at the end of the trial (i.e., last time step). Element `Î³_end[i,j]` = p(aáµ¢=1, câ±¼=1 âˆ£ ğ˜, d). Rows correspond to states of the accumulator state variable ğš, and columns to states of the coupling variable ğœ.
-`Ïˆ`: a floating-point number specifying the lapse rate

RETURN
-a floating-point number quantifying the partial derivative of the log-likelihood of one trial's data with respect to the lapse rate Ïˆ
"""
function differentiateâ„“_wrt_xÏˆ(choice::Bool, Î³_end::Array{<:AbstractFloat}, Ïˆ::AbstractFloat)
	Î³áµƒ_end = sum(Î³_end, dims=2)
	zeroindex = cld(length(Î³áµƒ_end), 2)
	# Î³áµƒ_end0_div2 = Î³áµƒ_end[zeroindex]/2
	if choice
		choiceconsistent   = sum(Î³áµƒ_end[zeroindex+1:end])
		choiceinconsistent = sum(Î³áµƒ_end[1:zeroindex-1])
	else
		choiceconsistent   = sum(Î³áµƒ_end[1:zeroindex-1])
		choiceinconsistent = sum(Î³áµƒ_end[zeroindex+1:end])
	end
	return (1-Ïˆ)*(choiceconsistent*Ïˆ/(Ïˆ-2) + choiceinconsistent)
end

"""
	Trialinvariant(options, Î¸native)

Compute quantities that are used in each trial for computing gradient of the log-likelihood

ARGUMENT
-`options`: model settings
-`Î¸native`: model parameters in their native space
"""
function Trialinvariant(options::Options, Î¸native::LatentÎ¸; purpose="gradient")
	@unpack Î”t, K, Î = options
	Î» = Î¸native.Î»[1]
	B = Î¸native.B[1]
	Aá¶œâ‚â‚ = Î¸native.Aá¶œâ‚â‚[1]
	Aá¶œâ‚‚â‚‚ = Î¸native.Aá¶œâ‚‚â‚‚[1]
	Ï€á¶œâ‚ = Î¸native.Ï€á¶œâ‚[1]
	Aá¶œ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚‚â‚‚; 1-Aá¶œâ‚â‚ Aá¶œâ‚‚â‚‚]
	Aá¶œáµ€ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚â‚; 1-Aá¶œâ‚‚â‚‚ Aá¶œâ‚‚â‚‚]
	Ï€á¶œáµ€ = [Ï€á¶œâ‚ 1-Ï€á¶œâ‚]
	ğ› = B*(2collect(1:Î) .- Î .- 1)/(Î-2)
	ğ› = conditionedmean(0.0, Î”t, Î¸native.Î»[1], ğ›)
	Ïƒ = âˆš(Î¸native.ÏƒÂ²â‚[1]*Î”t)
	Aáµƒsilent = zeros(eltype(ğ›),Î,Î)
	if purpose=="gradient"
		ğ›š = (2collect(1:Î) .- Î .- 1)/2
		Î© = ğ›š .- transpose(ğ›š).*exp.(Î».*Î”t)
		dAáµƒsilentdÎ¼ = zeros(Î,Î)
		dAáµƒsilentdÏƒÂ² = zeros(Î,Î)
		dAáµƒsilentdB = zeros(Î,Î)
		stochasticmatrix!(Aáµƒsilent, dAáµƒsilentdÎ¼, dAáµƒsilentdÏƒÂ², dAáµƒsilentdB, ğ›, Ïƒ, Î©, ğ›)
		Trialinvariant( Aáµƒsilent=Aáµƒsilent,
					Aá¶œ=Aá¶œ,
					Aá¶œáµ€=Aá¶œáµ€,
					dAáµƒsilentdÎ¼=dAáµƒsilentdÎ¼,
					dAáµƒsilentdÏƒÂ²=dAáµƒsilentdÏƒÂ²,
					dAáµƒsilentdB=dAáµƒsilentdB,
					Î”t=options.Î”t,
					ğ›š=ğ›š,
					Î©=Î©,
					Ï€á¶œáµ€=Ï€á¶œáµ€,
					Î=Î,
 				    K=K,
					ğ›=ğ›)
	elseif purpose=="loglikelihood"
		stochasticmatrix!(Aáµƒsilent, ğ›, Ïƒ, ğ›)
		Trialinvariant(Aáµƒsilent=Aáµƒsilent,
				   Aá¶œáµ€=Aá¶œáµ€,
				   Î”t=options.Î”t,
				   Ï€á¶œáµ€=Ï€á¶œáµ€,
				   ğ›=ğ›,
				   K=K,
				   Î=Î)
	end
end

"""
    likelihood!(pğ˜ğ‘‘, trialset, Ïˆ)

Update the conditional likelihood of the emissions (spikes and/or behavioral choice)

MODIFIED ARGUMENT
-`pğ˜ğ‘‘`: Conditional probability of the emissions (spikes and/or choice) at each time bin. For time bins of each trial other than the last, it is the product of the conditional likelihood of all spike trains. For the last time bin, it corresponds to the product of the conditional likelihood of the spike trains and the choice. Element pğ˜ğ‘‘[i][m][t][j,k] corresponds to âˆâ‚™á´º p(ğ²â‚™(t) | aâ‚œ = Î¾â±¼, zâ‚œ=k) across N neural units at the t-th time bin in the m-th trial of the i-th trialset. The last element pğ˜ğ‘‘[i][m][end][j,k] of each trial corresponds to p(ğ‘‘ | aâ‚œ = Î¾â±¼, zâ‚œ=k) âˆâ‚™á´º p(ğ²â‚™(t) | aâ‚œ = Î¾â±¼, zâ‚œ=k)

UNMODIFIED ARGUMENT
-`trialsets`: data used to constrain the model
-`Ïˆ`: lapse rate

RETURN
-`nothing`
"""
function likelihood!(pğ˜ğ‘‘::Vector{<:Vector{<:Vector{<:Matrix{<:AbstractFloat}}}},
                     trialsets::Vector{<:Trialset},
                     Ïˆ::Real)
	Î = size(pğ˜ğ‘‘[1][1][end],1)
	K = size(pğ˜ğ‘‘[1][1][end],2)
	zeroindex = cld(Î,2)
    @inbounds for i in eachindex(pğ˜ğ‘‘)
		N = length(trialsets[i].mpGLMs)
		ğ©decoupled = likelihood(trialsets[i].mpGLMs[1], zeroindex, 2)
		for n = 2:N
			likelihood!(ğ©decoupled, trialsets[i].mpGLMs[n], zeroindex, 2)
		end
	    for j = 1:Î
	        for k = 1:K
	            if k == 2 || j==zeroindex
					ğ© = ğ©decoupled
				else
					ğ© = likelihood(trialsets[i].mpGLMs[1], j, k)
		            for n = 2:N
					    likelihood!(ğ©, trialsets[i].mpGLMs[n], j, k)
		            end
				end
	            t = 0
	            for m in eachindex(pğ˜ğ‘‘[i])
	                for tâ‚˜ in eachindex(pğ˜ğ‘‘[i][m])
	                    t += 1
	                    pğ˜ğ‘‘[i][m][tâ‚˜][j,k] = ğ©[t]
	                end
	            end
	        end
	    end
		for m in eachindex(pğ˜ğ‘‘[i])
			likelihood!(pğ˜ğ‘‘[i][m][end], trialsets[i].trials[m].choice, Ïˆ; zeroindex=zeroindex)
		end
    end
    return nothing
end

"""
    likelihood!(pğ˜â‚œğ‘‘, choice, Ïˆ)

Multiply against the conditional probability of a right choice given the state of the accumulator

MODIFIED ARGUMENT
-`pğ˜â‚œğ‘‘`: A matrix whose element pğ˜â‚œğ‘‘[j,k] â‰¡ p(ğ˜â‚œ, ğ‘‘ âˆ£ aâ‚œ = Î¾â±¼, zâ‚œ = k) for time bin t that is the at the end of the trial

UNMODIFIED ARGUMENT
-`choice`: the observed choice, either right (`choice`=true) or left.
-`Ïˆ`: the prior probability of a lapse state

OPTIONAL ARGUMENT
- `zeroindex`: the index of the bin for which the accumulator variable equals zero
"""
function likelihood!(pğ˜â‚œğ‘‘,
		             choice::Bool,
		             Ïˆ::Real;
		             zeroindex=cld(size(pğ˜â‚œğ‘‘,1),2))
    pğ˜â‚œğ‘‘[zeroindex,:] .*= 0.5
    if choice
        pğ˜â‚œğ‘‘[1:zeroindex-1,:] .*= Ïˆ/2
        pğ˜â‚œğ‘‘[zeroindex+1:end,:] .*= 1-Ïˆ/2
    else
        pğ˜â‚œğ‘‘[1:zeroindex-1,:]   .*= 1-Ïˆ/2
        pğ˜â‚œğ‘‘[zeroindex+1:end,:] .*= Ïˆ/2
    end
    return nothing
end

"""
	sortparameters!(model, concatenatedÎ¸, indexÎ¸)

Sort a vector of concatenated parameter values and convert the values from real space to native space

MODIFIED ARGUMENT
-`model`: a factorial hidden Markov drift-diffusion model

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: a vector of concatenated parameter values
-`indexÎ¸`: struct indexing of each parameter in the vector of concatenated values
"""
function sortparameters!(model::Model,
				 		 concatenatedÎ¸::Vector{<:AbstractFloat},
				 		 indexÎ¸::IndexÎ¸)
	@unpack options, Î¸native, Î¸real, trialsets = model
	for field in fieldnames(LatentÎ¸) # `LatentÎ¸` is the type of `indexÎ¸.latentÎ¸`
		index = getfield(indexÎ¸.latentÎ¸, field)[1]
		if index != 0 # an index of 0 indicates that the parameter is not being fit
			getfield(Î¸real, field)[1] = concatenatedÎ¸[index]
		end
	end
	for field in (:ğ®, :ğ¥, :ğ«)
		index = getfield(indexÎ¸, field)
		for i in eachindex(index)
			for n in eachindex(index[i])
				if !isempty(index[i][n])
					getfield(trialsets[i].mpGLMs[n], field) .= concatenatedÎ¸[index[i][n]]
				end
			end
		end
	end
	real2native!(Î¸native, options, Î¸real)
	return nothing
end

"""
    concatenateparameters(model)

Concatenate values of parameters being fitted into a vector of floating point numbers

ARGUMENT
-`model`: the factorial hidden Markov drift-diffusion model

RETURN
-`concatenatedÎ¸`: a vector of the concatenated values of the parameters being fitted
-`indexÎ¸`: a structure indicating the index of each model parameter in the vector of concatenated values
"""
function concatenateparameters(model::Model)
    @unpack options, Î¸real, trialsets = model
	concatenatedÎ¸ = zeros(0)
    counter = 0
	latentÎ¸ = LatentÎ¸(collect(zeros(Int64,1) for i in fieldnames(LatentÎ¸))...)
	tofit = true
	for field in fieldnames(LatentÎ¸)
		if field == :Aá¶œâ‚â‚ || field == :Aá¶œâ‚‚â‚‚ || field == :Ï€á¶œâ‚
			tofit = options.K == 2
		else
			options_field = Symbol("fit_"*String(field))
			if hasfield(typeof(options), options_field)
				tofit = getfield(options, options_field)
			else
				error("Unrecognized field: "*String(field))
			end
		end
		if tofit
			counter += 1
			getfield(latentÎ¸, field)[1] = counter
			concatenatedÎ¸ = vcat(concatenatedÎ¸, getfield(Î¸real, field)[1])
		else
			getfield(latentÎ¸, field)[1] = 0
		end
	end
    ğ® = map(trialset->map(mpGLM->zeros(Int, length(mpGLM.ğ®)), trialset.mpGLMs), trialsets)
    ğ¥ = map(trialset->map(mpGLM->zeros(Int, length(mpGLM.ğ¥)), trialset.mpGLMs), trialsets)
    ğ« = map(trialset->map(mpGLM->zeros(Int, length(mpGLM.ğ«)), trialset.mpGLMs), trialsets)
    for i in eachindex(trialsets)
        for n in eachindex(trialsets[i].mpGLMs)
            concatenatedÎ¸ = vcat(concatenatedÎ¸, trialsets[i].mpGLMs[n].ğ®)
            p = length(trialsets[i].mpGLMs[n].ğ®)
            ğ®[i][n] = collect(counter+1:counter+p)
            counter += p
            concatenatedÎ¸ = vcat(concatenatedÎ¸, trialsets[i].mpGLMs[n].ğ¥)
            p = length(trialsets[i].mpGLMs[n].ğ¥)
            ğ¥[i][n] = collect(counter+1:counter+p)
            counter += p
            concatenatedÎ¸ = vcat(concatenatedÎ¸, trialsets[i].mpGLMs[n].ğ«)
            p = length(trialsets[i].mpGLMs[n].ğ«)
            ğ«[i][n] = collect(counter+1:counter+p)
            counter += p
        end
    end
    indexÎ¸ = IndexÎ¸(latentÎ¸=latentÎ¸,
					ğ®=ğ®,
					ğ¥=ğ¥,
					ğ«=ğ«)
    return concatenatedÎ¸, indexÎ¸
end

"""
    concatenatebounds(options, Î¸indices; boundtype)

Concatenate lower and upper bounds of the parameters being fitted

INPUT
-`indexÎ¸`: a structure indicating the index of each model parameter in the vector of concatenated values
-`options`: settings of the model

RETURN
-two vectors representing the lower and upper bounds of the parameters being fitted, respectively
"""
function concatenatebounds(indexÎ¸::IndexÎ¸, options::Options)
	lowerbounds, upperbounds = zeros(0), zeros(0)
	for field in fieldnames(typeof(indexÎ¸.latentÎ¸))
		if getfield(indexÎ¸.latentÎ¸, field)[1] != 0
			field_in_options = Symbol("bounds_"*String(field))
			bounds = getfield(options, field_in_options)
			lowerbounds = vcat(lowerbounds, bounds[1])
			upperbounds = vcat(upperbounds, bounds[2])
		end
	end
	nweights = 0
	for i in eachindex(indexÎ¸.ğ®)
		for n in eachindex(indexÎ¸.ğ®[i])
			nweights += length(indexÎ¸.ğ®[i][n]) +
				  		length(indexÎ¸.ğ¥[i][n]) +
						length(indexÎ¸.ğ«[i][n])
		end
	end
	lowerbounds = vcat(lowerbounds, -Inf*ones(nweights))
	upperbounds = vcat(upperbounds,  Inf*ones(nweights))
	return lowerbounds, upperbounds
end

"""
	Shared(model)

Create variables that are shared by the computations of the log-likelihood and its gradient

ARGUMENT
-`model`: structure with information about the factorial hidden Markov drift-diffusion model

OUTPUT
-an instance of the custom type `Shared`, which contains the shared quantities
"""
function Shared(model::Model)
	@unpack K, Î = model.options
	pğ˜ğ‘‘=map(model.trialsets) do trialset
			map(trialset.trials) do trial
				map(1:trial.ntimesteps) do t
					ones(Î,K)
				end
			end
		end
	likelihood!(pğ˜ğ‘‘, model.trialsets, model.Î¸native.Ïˆ[1])
	concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
	Shared(	concatenatedÎ¸=concatenatedÎ¸,
			indexÎ¸=indexÎ¸,
			pğ˜ğ‘‘=pğ˜ğ‘‘)
end

"""
	update!(model, shared, concatenatedÎ¸)

Update the model and the shared quantities according to new parameter values

ARGUMENT
-`model`: structure with information concerning a factorial hidden Markov drift-diffusion model
-`shared`: structure containing variables shared between computations of the model's log-likelihood and its gradient
-`concatenatedÎ¸`: newest values of the model's parameters
"""
function update!(model::Model,
				 shared::Shared,
				 concatenatedÎ¸::Vector{<:Real})
	shared.concatenatedÎ¸ .= concatenatedÎ¸
	sortparameters!(model, shared.concatenatedÎ¸, shared.indexÎ¸)
	if !isempty(shared.pğ˜ğ‘‘[1][1][1])
	    likelihood!(shared.pğ˜ğ‘‘, model.trialsets, model.Î¸native.Ïˆ[1])
	end
	return nothing
end
