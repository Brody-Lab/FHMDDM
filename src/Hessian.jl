"""
	âˆ‡âˆ‡loglikelihood(model)

Hessian of the log-likelihood of data under a factorial hidden Markov drift-diffusion model (FHMDDM).

The gradient and the log-likelihood are also returned

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = FHMDDM.âˆ‡âˆ‡loglikelihood(model)
```
"""
function âˆ‡âˆ‡loglikelihood(model::Model)
	sameacrosstrials = Sameacrosstrials(model)
	@unpack trialsets = model
	output =map(trialsets, eachindex(trialsets)) do trialset, s
				glmÎ¸s = collect(trialset.mpGLMs[n].Î¸ for n = 1:length(trialset.mpGLMs))
		 		map(trialset.trials) do trial #pmap
					âˆ‡âˆ‡loglikelihood(glmÎ¸s, model.Î¸native, s, sameacrosstrials, trial)
				end
			end
	â„“ = output[1][1][1]
	âˆ‡â„“ = output[1][1][2]
	âˆ‡âˆ‡â„“ = output[1][1][3]
	for i in eachindex(output)
		for m = 2:length(output[i])
			â„“ += output[i][m][1]
			âˆ‡â„“ .+= output[i][m][2]
			âˆ‡âˆ‡â„“ .+= output[i][m][3]
		end
	end
	return â„“, âˆ‡â„“, Symmetric(âˆ‡âˆ‡â„“)
end

"""
	âˆ‡âˆ‡loglikelihood(glmÎ¸s, Î¸native, s, sameacrosstrials, trial)

Hessian of the log-likelihood of the observations from one trial

The gradient and the log-likelihood are also returned

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`s`: index of the trialset
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood
"""
function âˆ‡âˆ‡loglikelihood(glmÎ¸s::Vector{<:GLMÎ¸},
						 Î¸native::LatentÎ¸,
						 s::Integer,
						 sameacrosstrials::Sameacrosstrials,
						 trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒsilent, âˆ‡Aáµƒsilent, âˆ‡âˆ‡Aáµƒsilent, Aá¶œáµ€, âˆ‡Aá¶œáµ€, Î”t, indexÎ¸_paâ‚, indexÎ¸_paâ‚œaâ‚œâ‚‹â‚, indexÎ¸_pcâ‚, indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚, indexÎ¸_Ïˆ, K, Ï€á¶œáµ€, âˆ‡Ï€á¶œáµ€, Î, nÎ¸_all, nÎ¸_paâ‚, nÎ¸_paâ‚œaâ‚œâ‚‹â‚, nÎ¸_pcâ‚, nÎ¸_pcâ‚œcâ‚œâ‚‹â‚, nÎ¸_Ïˆ, index_paâ‚_in_Î¸, index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸, index_pcâ‚_in_Î¸, index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸, index_Ïˆ_in_Î¸ = sameacrosstrials
	indexÎ¸_pY = sameacrosstrials.indexÎ¸_pY[s]
	nÎ¸_pY = sameacrosstrials.nÎ¸_pY[s]
	index_pY_in_Î¸ = sameacrosstrials.index_pY_in_Î¸[s]
	âˆ‡f = map(i->zeros(Î,K), 1:nÎ¸_all)
	âˆ‡âˆ‡f = map(i->zeros(Î,K), CartesianIndices((nÎ¸_all,nÎ¸_all)))
	P = Probabilityvector(Î”t, Î¸native, Î)
	âˆ‡âˆ‡paâ‚ = map(i->zeros(Î), CartesianIndices((nÎ¸_paâ‚,nÎ¸_paâ‚)))
 	âˆ‡paâ‚ = map(i->zeros(Î), 1:nÎ¸_paâ‚)
	âˆ‡âˆ‡priorprobability!(âˆ‡âˆ‡paâ‚, âˆ‡paâ‚, P, trial.previousanswer)
	paâ‚ = P.ğ›‘
	pY = zeros(Î,K)
	âˆ‡pY = collect(zeros(Î,K) for n=1:nÎ¸_pY)
	âˆ‡âˆ‡pY = map(i->zeros(Î,K), CartesianIndices((nÎ¸_pY,nÎ¸_pY)))
	âˆ‡âˆ‡conditionallikelihood!(âˆ‡âˆ‡pY, âˆ‡pY, pY, glmÎ¸s, 1, trial.spiketrainmodels, sameacrosstrials)
	pYâ‚â¨€pcâ‚ = pY .* Ï€á¶œáµ€
	for i = 1:nÎ¸_paâ‚
		q = indexÎ¸_paâ‚[i]
		for j = i:nÎ¸_paâ‚
			r = indexÎ¸_paâ‚[j]
			âˆ‡âˆ‡f[q,r] = âˆ‡âˆ‡paâ‚[i,j] .* pYâ‚â¨€pcâ‚
		end
	end
	paâ‚â¨€pcâ‚ = paâ‚ .* Ï€á¶œáµ€
	for i = 1:nÎ¸_pY
		q = indexÎ¸_pY[i]
		for j = i:nÎ¸_pY
			r = indexÎ¸_pY[j]
			âˆ‡âˆ‡f[q,r] = âˆ‡âˆ‡pY[i,j] .* paâ‚â¨€pcâ‚
		end
	end
	for q = 1:nÎ¸_all
		for r = q:nÎ¸_all
			i = index_pcâ‚_in_Î¸[q]
			j = index_pY_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* paâ‚ .* âˆ‡Ï€á¶œáµ€[i]
			end
			i = index_paâ‚_in_Î¸[q]
			j = index_pY_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* âˆ‡paâ‚[i] .* Ï€á¶œáµ€
			end
			i = index_paâ‚_in_Î¸[q]
			j = index_pcâ‚_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= pY .* âˆ‡paâ‚[i] .* âˆ‡Ï€á¶œáµ€[j]
			end
			i = index_pcâ‚_in_Î¸[q]
			j = index_paâ‚_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= pY .* âˆ‡paâ‚[j] .* âˆ‡Ï€á¶œáµ€[i]
			end
		end
	end
	for i = 1:nÎ¸_pY
		q = indexÎ¸_pY[i]
		âˆ‡f[q] = âˆ‡pY[i] .* paâ‚â¨€pcâ‚
	end
	for i = 1:nÎ¸_paâ‚
		q = indexÎ¸_paâ‚[i]
		âˆ‡f[q] = âˆ‡paâ‚[i] .* pYâ‚â¨€pcâ‚
	end
	for i = 1:nÎ¸_pcâ‚
		q = indexÎ¸_pcâ‚[i]
		âˆ‡f[q] .= paâ‚ .* pY .* âˆ‡Ï€á¶œáµ€[i]
	end
	f = pY .* paâ‚â¨€pcâ‚
	âˆ‡âˆ‡â„“ = zeros(nÎ¸_all, nÎ¸_all)
	âˆ‡â„“ = zeros(nÎ¸_all)
	â„“ = zeros(1)
	forward!(âˆ‡âˆ‡f, âˆ‡f, f, âˆ‡âˆ‡â„“, âˆ‡â„“, â„“)
	if !isempty(clicks.inputtimesteps)
		adaptedclicks = âˆ‡âˆ‡adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
		âˆ‡âˆ‡Aáµƒinput = map(i->zeros(Î,Î), CartesianIndices((nÎ¸_paâ‚œaâ‚œâ‚‹â‚,nÎ¸_paâ‚œaâ‚œâ‚‹â‚)))
		âˆ‡Aáµƒinput = map(i->zeros(Î,Î), 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚)
		Aáµƒinput = zeros(Î,Î)
		Aáµƒinput[1,1] = Aáµƒinput[Î, Î] = 1.0
	end
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			update_for_âˆ‡âˆ‡transition_probabilities!(P, adaptedclicks, clicks, t)
			âˆ‡âˆ‡transitionmatrix!(âˆ‡âˆ‡Aáµƒinput, âˆ‡Aáµƒinput, Aáµƒinput, P)
			âˆ‡âˆ‡Aáµƒ = âˆ‡âˆ‡Aáµƒinput
			âˆ‡Aáµƒ = âˆ‡Aáµƒinput
			Aáµƒ = Aáµƒinput
		else
			âˆ‡âˆ‡Aáµƒ = âˆ‡âˆ‡Aáµƒsilent
			âˆ‡Aáµƒ = âˆ‡Aáµƒsilent
			Aáµƒ = Aáµƒsilent
		end
		âˆ‡âˆ‡conditionallikelihood!(âˆ‡âˆ‡pY, âˆ‡pY, pY, glmÎ¸s, t, trial.spiketrainmodels, sameacrosstrials)
		if t==trial.ntimesteps
			âˆ‚pYğ‘‘_âˆ‚Ïˆ = âˆ‡conditionallikelihood(pY, trial.choice, Î¸native.Ïˆ[1])
			conditionallikelihood!(pY, trial.choice, Î¸native.Ïˆ[1])
		end
		fâ¨‰Aá¶œáµ€ = f * Aá¶œáµ€
		Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ = Aáµƒ * fâ¨‰Aá¶œáµ€
		for q = 1:nÎ¸_all
			for r = q:nÎ¸_all
				âˆ‡âˆ‡f[q,r] = pY .* (Aáµƒ * âˆ‡âˆ‡f[q,r] * Aá¶œáµ€)
			end
		end
		if t==trial.ntimesteps
			dpğ‘‘_dÏˆ = differentiate_pğ‘‘_wrt_Ïˆ(trial.choice, K, Î)
			for q = 1:nÎ¸_all
				for r = q:nÎ¸_all
					i = index_Ïˆ_in_Î¸[q]
					if i > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * âˆ‡f[r] * Aá¶œáµ€)
					end
					j = index_Ïˆ_in_Î¸[r]
					if j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
					end
					i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
					# j = index_Ïˆ_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * f * âˆ‡Aá¶œáµ€[i])
					end
					i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
					# j = index_Ïˆ_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (âˆ‡Aáµƒ[i] * f * Aá¶œáµ€)
					end
					i = index_Ïˆ_in_Î¸[q]
					j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (âˆ‡Aáµƒ[j] * f * Aá¶œáµ€)
					end
					# i = index_Ïˆ_in_Î¸[q]
					j = index_pY_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= dpğ‘‘_dÏˆ .* âˆ‡pY[j] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
					end
				end
			end
			for i = 1:nÎ¸_pY
				conditionallikelihood!(âˆ‡pY[i], trial.choice, Î¸native.Ïˆ[1])
				for j = i:nÎ¸_pY
					conditionallikelihood!(âˆ‡âˆ‡pY[i,j], trial.choice, Î¸native.Ïˆ[1])
				end
			end
		end
		for i = 1:nÎ¸_pY
			q = indexÎ¸_pY[i]
			for j = i:nÎ¸_pY
				r = indexÎ¸_pY[j]
				âˆ‡âˆ‡f[q,r] .+= âˆ‡âˆ‡pY[i,j] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
			end
		end
		for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
			q = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]
			for j = i:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
				r = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[j]
				âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡âˆ‡Aáµƒ[i,j] * fâ¨‰Aá¶œáµ€)
			end
		end
		for q = 1:nÎ¸_all
			for r = q:nÎ¸_all
				i = index_pY_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[i] .* (Aáµƒ * âˆ‡f[r] * Aá¶œáµ€)
				end
				j = index_pY_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
				end
				i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[i] * âˆ‡f[r] * Aá¶œáµ€)
				end
				j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[j] * âˆ‡f[q] * Aá¶œáµ€)
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (Aáµƒ * âˆ‡f[r] * âˆ‡Aá¶œáµ€[i])
				end
				j = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (Aáµƒ * âˆ‡f[q] * âˆ‡Aá¶œáµ€[j])
				end
				i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_pY_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (âˆ‡Aáµƒ[i] * fâ¨‰Aá¶œáµ€)
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_pY_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (Aáµƒ * f * âˆ‡Aá¶œáµ€[i])
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[j] * f * âˆ‡Aá¶œáµ€[i])
				end
			end
		end
		for q = 1:nÎ¸_all
			âˆ‡f[q] = pY .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
		end
		for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
			q = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]
			âˆ‡f[q] .+= pY .* (âˆ‡Aáµƒ[i] * fâ¨‰Aá¶œáµ€)
		end
		for i = 1:nÎ¸_pY
			q = indexÎ¸_pY[i]
			âˆ‡f[q] .+= âˆ‡pY[i] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
		end
		Aáµƒâ¨‰f = Aáµƒ * f
		for i = 1:nÎ¸_pcâ‚œcâ‚œâ‚‹â‚
			q = indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚[i]
			âˆ‡f[q] .+= pY .* (Aáµƒâ¨‰f * âˆ‡Aá¶œáµ€[i])
		end
		if t==trial.ntimesteps
			q = indexÎ¸_Ïˆ[1]
			âˆ‡f[q] = âˆ‚pYğ‘‘_âˆ‚Ïˆ .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
		end
		f = pY .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
		forward!(âˆ‡âˆ‡f, âˆ‡f, f, âˆ‡âˆ‡â„“, âˆ‡â„“, â„“)
	end
	return â„“[1], âˆ‡â„“, âˆ‡âˆ‡â„“
end

"""
	loglikelihood_Î¸native(concatenatedÎ¸native, model)

Log-likelihood of the data given the complete set of parameters in their native space

ARGUMENT
-`x`: vector of concatenated parameters in their native space. This vector needs to include all parameters, regardless whether they are being fitted
-`model`: a structure containing the

RETURN
-log-likelihood of the data

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> x = FHMDDM.concatenate_native_parameters(model)
julia> â„“ = FHMDDM.loglikelihood_Î¸native(x, model)
```
"""
function loglikelihood_Î¸native(x::Vector{<:Real}, model::Model)
	model = sort_native_parameters(x, model)
	@unpack options, trialsets = model
	output =map(trialsets) do trialset
				glmÎ¸s = collect(trialset.mpGLMs[n].Î¸ for n = 1:length(trialset.mpGLMs))
		 		map(trialset.trials) do trial #pmap
					loglikelihood(glmÎ¸s, options, model.Î¸native, trial)
				end
			end
	â„“ = output[1][1]
	for i in eachindex(output)
		for m = 2:length(output[i])
			â„“ += output[i][m]
		end
	end
	return â„“
end

"""
	loglikelihood(glmÎ¸s, Î¸native, sameacrosstrials, trial)

Log-likelihood of the data in one trial

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
"""
function loglikelihood(glmÎ¸s::Vector{<:GLMÎ¸},
   					   options::Options,
					   Î¸native::LatentÎ¸,
					   trial::Trial)
	@unpack clicks = trial
	@unpack Î”t, K, Î = options
	type = eltype(glmÎ¸s[1].ğ®[1])
	adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	Aáµƒinput, Aáµƒsilent = zeros(type,Î,Î), zeros(type,Î,Î)
	expÎ»Î”t = exp(Î¸native.Î»[1]*Î”t)
	dÎ¼_dÎ”c = differentiate_Î¼_wrt_Î”c(Î”t, Î¸native.Î»[1])
	dğ›_dB = (2 .*collect(1:Î) .- Î .- 1)./(Î-2)
	ğ› = Î¸native.B[1].*dğ›_dB
	transitionmatrix!(Aáµƒsilent, expÎ»Î”t.*ğ›, âˆš(Î”t*Î¸native.ÏƒÂ²â‚[1]), ğ›)
	Aá¶œâ‚â‚ = Î¸native.Aá¶œâ‚â‚[1]
	Aá¶œâ‚‚â‚‚ = Î¸native.Aá¶œâ‚‚â‚‚[1]
	Ï€á¶œâ‚ = Î¸native.Ï€á¶œâ‚[1]
	if K == 2
		Aá¶œáµ€ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚â‚; 1-Aá¶œâ‚‚â‚‚ Aá¶œâ‚‚â‚‚]
		Ï€á¶œáµ€ = [Ï€á¶œâ‚ 1-Ï€á¶œâ‚]
	else
		Aá¶œáµ€ = ones(1,1)
		Ï€á¶œáµ€ = ones(1,1)
	end
	paâ‚ = probabilityvector(Î¸native.Î¼â‚€[1]+Î¸native.wâ‚•[1]*trial.previousanswer, âˆšÎ¸native.ÏƒÂ²áµ¢[1], ğ›)
	pY = zeros(type, Î, K)
	conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, 1, trial.spiketrainmodels)
	f = pY .* paâ‚ .* Ï€á¶œáµ€
	â„“ = zeros(type, 1)
	forward!(f, â„“)
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			cL = sum(adaptedclicks.C[clicks.left[t]])
			cR = sum(adaptedclicks.C[clicks.right[t]])
			ğ› = expÎ»Î”t.*ğ› .+ (cR-cL)*dÎ¼_dÎ”c
			Ïƒ = âˆš((cR+cL)*Î¸native.ÏƒÂ²â‚›[1] + Î”t*Î¸native.ÏƒÂ²â‚[1])
			transitionmatrix!(Aáµƒinput, ğ›, Ïƒ, ğ›)
			Aáµƒ = Aáµƒinput
		else
			Aáµƒ = Aáµƒsilent
		end
		conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, t, trial.spiketrainmodels)
		if t==trial.ntimesteps
			conditionallikelihood!(pY, trial.choice, Î¸native.Ïˆ[1])
		end
		f = pY .* (Aáµƒ * f * Aá¶œáµ€)
		forward!(f, â„“)
	end
	return â„“[1]
end

"""
	compare_gradients_hessians_Î¸native(model)

Compare the automatically computed and hand-coded gradients and hessians with respect the parameters in their native space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a factorial hidden-Markov drift-diffusion model

RETURN
-`absdiffâ„“`: absolute difference in the log-likelihood evaluted using the algorithm bein automatically differentiated and the hand-coded algorithm
-`absdiffâˆ‡`: absolute difference in the gradients
-`absdiffâˆ‡âˆ‡`: absolute difference in the hessians

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> absdiffâ„“, absdiffâˆ‡, absdiffâˆ‡âˆ‡ = FHMDDM.compare_gradients_hessians_Î¸native(model)
julia> maximum(absdiffâˆ‡âˆ‡)
```
"""
function compare_gradients_hessians_Î¸native(model::Model)
	x0 = FHMDDM.concatenate_native_parameters(model)
	f(x) = loglikelihood_Î¸native(x, model)
	â„“auto = f(x0)
	âˆ‡auto = ForwardDiff.gradient(f, x0)
	âˆ‡âˆ‡auto = ForwardDiff.hessian(f, x0)
	â„“hand, âˆ‡hand, âˆ‡âˆ‡hand = FHMDDM.âˆ‡âˆ‡loglikelihood(model)
	return abs(â„“auto-â„“hand), abs.(âˆ‡auto .- âˆ‡hand), abs.(âˆ‡âˆ‡auto .- âˆ‡âˆ‡hand)
end

"""
	forward!(âˆ‡âˆ‡f,âˆ‡f,f,âˆ‡âˆ‡â„“,âˆ‡â„“,â„“)

Normalize the forward term and its first- and second-order partial derivatives and update the log-likelihood and its first- and second-order partial derivatives

For computational efficiency, no entry below the main diagonal of the Hessian matrix of the log-likelihood is updated

ARGUMENT
-`âˆ‡âˆ‡f`: Second-order partial derivatives of the un-normalized forward term. Element `âˆ‡âˆ‡f[q,r][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th and r-th parameter.
-`âˆ‡f`: first-order partial derivatives of the un-normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th parameter.
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood for the data before the current time-step
-`âˆ‡â„“`: gradient of the log-likelihood for the data before the current time-step
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`âˆ‡âˆ‡f`: Second-order partial derivatives of the normalized forward term. Element `âˆ‡âˆ‡f[q,r][i,j]` corresponds to `âˆ‚Â²p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)âˆ‚Î¸(r)`
-`âˆ‡f`: first-order partial derivatives of the normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to `âˆ‚p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)`
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood for the data up to the current time-step
-`âˆ‡â„“`: gradient of the log-likelihood for the data up to the current time-step
-`â„“`: log-likelihood for the data before the up to the current time-step

"""
function forward!(âˆ‡âˆ‡f::Matrix{<:Matrix{<:Real}},
				  âˆ‡f::Vector{<:Matrix{<:Real}},
				  f::Matrix{<:Real},
				  âˆ‡âˆ‡â„“::Matrix{<:Real},
 				  âˆ‡â„“::Vector{<:Real},
				  â„“::Vector{<:Real})
	âˆ‡D, D = forward!(âˆ‡f,f,âˆ‡â„“,â„“)
	nparameters = length(âˆ‡f)
	for i = 1:nparameters
		for j = i:nparameters
			âˆ‡âˆ‡Dáµ¢â±¼ = sum(âˆ‡âˆ‡f[i,j])
			âˆ‡âˆ‡â„“[i,j] += (âˆ‡âˆ‡Dáµ¢â±¼ - âˆ‡D[i]*âˆ‡D[j]/D)/D
			âˆ‡âˆ‡f[i,j] = (âˆ‡âˆ‡f[i,j] .- âˆ‡f[i].*âˆ‡D[j] .- âˆ‡f[j].*âˆ‡D[i] .- f.*âˆ‡âˆ‡Dáµ¢â±¼)./D
		end
	end
	return nothing
end

"""
	forward!(âˆ‡f,f,âˆ‡â„“,â„“)

Normalize the forward term and its first-order partial derivatives and update the log-likelihood and its first-partial derivatives

ARGUMENT
-`âˆ‡f`: first-order partial derivatives of the un-normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th parameter.
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`âˆ‡â„“`: gradient of the log-likelihood for the data before the current time-step
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`âˆ‡f`: first-order partial derivatives of the normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to `âˆ‚p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)`
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`âˆ‡â„“`: gradient of the log-likelihood for the data up to the current time-step
-`â„“`: log-likelihood for the data before the up to the current time-step

RETURN
-`âˆ‡D`: gradient of the past-conditioned emissions likelihood for the current time step
-`D`: past-conditioned emissions likelihood: `p{ğ˜(t) âˆ£ ğ˜(1:t-1))`
"""
function forward!(âˆ‡f::Vector{<:Matrix{<:Real}},
				  f::Matrix{<:Real},
 				  âˆ‡â„“::Vector{<:Real},
				  â„“::Vector{<:Real})
	D = forward!(f,â„“)
	âˆ‡D = map(sum, âˆ‡f)
	âˆ‡â„“ .+= âˆ‡D./D
	for i in eachindex(âˆ‡f)
		âˆ‡f[i] = (âˆ‡f[i] .- f.*âˆ‡D[i])./D
	end
	return âˆ‡D, D
end

"""
	forward!(f,â„“)

Normalize the forward term and update the log-likelihood to include the emissions from the current time step

ARGUMENT
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`â„“`: log-likelihood for the data before the up to the current time-step

RETURN
-`D`: past-conditioned emissions likelihood: `p{ğ˜(t) âˆ£ ğ˜(1:t-1))`
"""
function forward!(f::Matrix{<:Real},
				  â„“::Vector{<:Real})
	D = sum(f)
	â„“[1] += log(D)
	f ./= D
	return D
end

"""
	âˆ‡conditionallikelihood(pY, ğ‘‘, Ïˆ)

Partial derivatives of the conditional likelihood of the emissions at the last time step with respect to the lapse rate

ARGUMENT
-`pY`: conditional likelihood of the population spiking at the last time step `T`. Element `pY[i,j]` represents p{Y(T) âˆ£ a(T)=Î¾(i), c(T)=j}
-`ğ‘‘`: left (false) or right (true) choice of the animal
-`Ïˆ`: lapse rate

RETURN
-`âˆ‚pYğ‘‘_âˆ‚Ïˆ`: partial derivative of the emissions at the last time step (population spiking and the choice) with respect to the lapse rate. Element `âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j]` represents:
	âˆ‚p{Y(T), ğ‘‘ âˆ£ a(T)=Î¾(i), c(T)=j}}/âˆ‚Ïˆ
"""
function âˆ‡conditionallikelihood(pY::Matrix{<:Real}, ğ‘‘::Bool, Ïˆ::Real)
	if ğ‘‘
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = 0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = -0.5
	else
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = -0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = 0.5
	end
	âˆ‚pYğ‘‘_âˆ‚Ïˆ = copy(pY)
	Î,K = size(pY)
	zeroindex = cld(Î,2)
	for j = 1:K
		for i = 1:zeroindex-1
			âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j] *= âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ
		end
		âˆ‚pYğ‘‘_âˆ‚Ïˆ[zeroindex,j] = 0.0
		for i = zeroindex+1:Î
			âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j] *= âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ
		end
	end
	return âˆ‚pYğ‘‘_âˆ‚Ïˆ
end

"""
	differentiate_pğ‘‘_wrt_Ïˆ(ğ‘‘,K,Î)

Derivative of the conditional likelihood of the choice with respect to Ïˆ

ARGUMENT
-`ğ‘‘`: choice: left(false) or right(true)
-`K`: number of coupling states
-`Î`: number of accumulator states

RETURN
-`dpğ‘‘_dÏˆ`: a matrix whose element `dpğ‘‘_dÏˆ[i,j]` represents âˆ‚p(ğ‘‘ âˆ£ a=i, c=j)/âˆ‚Ïˆ
"""
function differentiate_pğ‘‘_wrt_Ïˆ(ğ‘‘::Bool, K::Integer, Î::Integer)
	dpğ‘‘_dÏˆ = zeros(Î,K)
	if ğ‘‘
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = 0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = -0.5
	else
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = -0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = 0.5
	end
	zeroindex = cld(Î,2)
	for j = 1:K
		for i = 1:zeroindex-1
			dpğ‘‘_dÏˆ[i,j] = âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ
		end
		for i = zeroindex+1:Î
			dpğ‘‘_dÏˆ[i,j] = âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ
		end
	end
	return dpğ‘‘_dÏˆ
end
"""
	conditionallikelihood!(P, ğ‘‘, Ïˆ)

Multiply elements of a matrix by the conditional likelihood of the choice

ARGUMENT
-`P`: a matrix whose element `P[i,j]` corresponds to the i-th accumulator state and j-th coupling state
-`ğ‘‘`: left (false) or right (true) choice of the animal
-`Ïˆ`: lapse rate

MODIFIED ARGUMENT
-`P`: Each element `P[i,j]` has been multiplied with p{ğ‘‘ âˆ£ a(T)=Î¾(i), c(T)=j}
"""
function conditionallikelihood!(P::Matrix{<:Real}, ğ‘‘::Bool, Ïˆ::Real)
	if ğ‘‘
		pğ‘‘_Î¾â» = Ïˆ/2
		pğ‘‘_Î¾âº = 1-Ïˆ/2
	else
		pğ‘‘_Î¾â» = 1-Ïˆ/2
		pğ‘‘_Î¾âº = Ïˆ/2
	end
	Î,K = size(P)
	zeroindex = cld(Î,2)
	for j = 1:K
		for i = 1:zeroindex-1
			P[i,j] *= pğ‘‘_Î¾â»
		end
		P[zeroindex,j] /= 2
		for i = zeroindex+1:Î
			P[i,j] *= pğ‘‘_Î¾âº
		end
	end
	return nothing
end

"""
	Sameacrosstrials(model)

Make a structure containing quantities that are used in each trial

ARGUMENT
-`model`: data, parameters, and hyperparameters of the factorial hidden-Markov drift-diffusion model

RETURN
-a structure containing quantities that are used in each trial
"""
function Sameacrosstrials(model::Model)
	@unpack options, Î¸native, Î¸real = model
	@unpack Î”t, K, Î = options
	Aá¶œâ‚â‚ = Î¸native.Aá¶œâ‚â‚[1]
	Aá¶œâ‚‚â‚‚ = Î¸native.Aá¶œâ‚‚â‚‚[1]
	Ï€á¶œâ‚ = Î¸native.Ï€á¶œâ‚[1]
	if K == 2
		Aá¶œáµ€ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚â‚; 1-Aá¶œâ‚‚â‚‚ Aá¶œâ‚‚â‚‚]
		âˆ‡Aá¶œáµ€ = [[1.0 -1.0; 0.0 0.0], [0.0 0.0; -1.0 1.0]]
		Ï€á¶œáµ€ = [Ï€á¶œâ‚ 1-Ï€á¶œâ‚]
		âˆ‡Ï€á¶œáµ€ = [[1.0 -1.0]]
	else
		Aá¶œáµ€ = ones(1,1)
		âˆ‡Aá¶œáµ€ = [zeros(1,1), zeros(1,1)]
		Ï€á¶œáµ€ = ones(1,1)
		âˆ‡Ï€á¶œáµ€ = [zeros(1,1)]
	end
	indexÎ¸_paâ‚ = [3,6,11,13]
	indexÎ¸_paâ‚œaâ‚œâ‚‹â‚ = [3,4,5,7,10,12]
	indexÎ¸_pcâ‚ = [8]
	indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚ = [1,2]
	indexÎ¸_Ïˆ = [9]
	indexÎ¸_pY = map(model.trialsets) do trialset
		counter = 0
		for n in eachindex(trialset.mpGLMs)
			counter += length(trialset.mpGLMs[1].Î¸.ğ®)
			counter += length(trialset.mpGLMs[1].Î¸.ğ¯)
		end
		collect(1:counter)
	end
	counter = 13
	for i in eachindex(indexÎ¸_pY)
		indexÎ¸_pY[i] .+= counter
		counter = indexÎ¸_pY[i][end]
	end
	nÎ¸_all = indexÎ¸_pY[end][end]
	index_paâ‚_in_Î¸, index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸, index_pcâ‚_in_Î¸, index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸, index_Ïˆ_in_Î¸ = zeros(Int, nÎ¸_all), zeros(Int, nÎ¸_all), zeros(Int, nÎ¸_all), zeros(Int, nÎ¸_all), zeros(Int, nÎ¸_all)
	index_paâ‚_in_Î¸[indexÎ¸_paâ‚] .= 1:length(indexÎ¸_paâ‚)
	index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[indexÎ¸_paâ‚œaâ‚œâ‚‹â‚] .= 1:length(indexÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	index_pcâ‚_in_Î¸[indexÎ¸_pcâ‚] .= 1:length(indexÎ¸_pcâ‚)
	index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚] .= 1:length(indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚)
	index_Ïˆ_in_Î¸[indexÎ¸_Ïˆ] .= 1:length(indexÎ¸_Ïˆ)
	index_pY_in_Î¸ = map(x->zeros(Int, nÎ¸_all), indexÎ¸_pY)
	for i = 1:length(index_pY_in_Î¸)
		index_pY_in_Î¸[i][indexÎ¸_pY[i]] = 1:length(indexÎ¸_pY[i])
	end

	nÎ¸_paâ‚œaâ‚œâ‚‹â‚ = length(indexÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	P = Probabilityvector(Î”t, Î¸native, Î)
	update_for_âˆ‡âˆ‡transition_probabilities!(P)
	âˆ‡âˆ‡Aáµƒsilent = map(i->zeros(Î,Î), CartesianIndices((nÎ¸_paâ‚œaâ‚œâ‚‹â‚,nÎ¸_paâ‚œaâ‚œâ‚‹â‚)))
	âˆ‡Aáµƒsilent = map(i->zeros(Î,Î), 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	Aáµƒsilent = zeros(typeof(Î¸native.B[1]), Î, Î)
	Aáµƒsilent[1,1] = Aáµƒsilent[Î, Î] = 1.0
	âˆ‡âˆ‡transitionmatrix!(âˆ‡âˆ‡Aáµƒsilent, âˆ‡Aáµƒsilent, Aáµƒsilent, P)
	Sameacrosstrials(Aáµƒsilent=Aáµƒsilent,
					âˆ‡Aáµƒsilent=âˆ‡Aáµƒsilent,
					âˆ‡âˆ‡Aáµƒsilent=âˆ‡âˆ‡Aáµƒsilent,
					Aá¶œáµ€=Aá¶œáµ€,
					âˆ‡Aá¶œáµ€=âˆ‡Aá¶œáµ€,
					Î”t=options.Î”t,
					indexÎ¸_paâ‚=indexÎ¸_paâ‚,
					indexÎ¸_paâ‚œaâ‚œâ‚‹â‚=indexÎ¸_paâ‚œaâ‚œâ‚‹â‚,
					indexÎ¸_pcâ‚=indexÎ¸_pcâ‚,
					indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚=indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚,
					indexÎ¸_Ïˆ=indexÎ¸_Ïˆ,
					indexÎ¸_pY=indexÎ¸_pY,
					K=K,
					Ï€á¶œáµ€=Ï€á¶œáµ€,
					âˆ‡Ï€á¶œáµ€=âˆ‡Ï€á¶œáµ€,
					Î=Î)
end
