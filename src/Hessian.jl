"""
	âˆ‡âˆ‡negativeloglikelihood!(h,concatenatedÎ¸, fgh, indexÎ¸)

Hessian of the negative log-likelihood

MODIFIED ARGUMENT
-`h`: hessian matrix, with respect to only the parameters being fitted and their values in real space

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: values of the parameters in real space concatenated as a vector
-`fgh`: structure containing the negative log-likelihood, its gradient, and its hessian, as well as the parameters values used to compute each of these quantities
-`indexÎ¸`: a structure for sorting (i.e., un-concatenating) the parameters
-`model`: a structure containing the data and hyperparameters of the factorial hidden drift-diffusion model

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
julia> fgh = FHMDDM.FGH(model)
julia> h = similar(fgh.h)
julia> FHMDDM.âˆ‡âˆ‡negativeloglikelihood!(h, concatenatedÎ¸, fgh, model)
```
"""
function âˆ‡âˆ‡negativeloglikelihood!(h::Matrix{<:Real}, concatenatedÎ¸::Vector{<:Real}, fgh::FGH, model::Model)
	if concatenatedÎ¸ != fgh.x_h
		â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = âˆ‡âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)
		fgh.f[1] = -â„“
		for i in eachindex(âˆ‡â„“)
			fgh.g[i] = -âˆ‡â„“[i]
		end
		for ij in eachindex(âˆ‡âˆ‡â„“)
			fgh.h[ij] = -âˆ‡âˆ‡â„“[ij]
		end
		copyto!(fgh.x_f, concatenatedÎ¸)
		copyto!(fgh.x_g, concatenatedÎ¸)
		copyto!(fgh.x_h, concatenatedÎ¸)
	end
	if h != fgh.h
		copyto!(h, fgh.h)
	end
	return nothing
end

"""
	FGH(model)

Makes a structure storing the negative log-likelihood, its gradient, its Hessian, the parameter values used to compute each of these quantities, and the index of the parameters.
"""
function FGH(model::Model)
	concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
	â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = âˆ‡âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)
	FGH(x_f=concatenatedÎ¸, x_g=concatenatedÎ¸, x_h=concatenatedÎ¸, f=[â„“], g=âˆ‡â„“, h=âˆ‡âˆ‡â„“, indexÎ¸=indexÎ¸)
end

"""
	âˆ‡âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)

Sort a vector of parameters and compute the log-likelihood, its gradient, and its hessian

ARGUMENT
-`model`: a structure containing the data and hyperparameters of the factorial hidden drift-diffusion model
-`concatenatedÎ¸`: values of the parameters in real space concatenated as a vector
-`indexÎ¸`: a structure for sorting (i.e., un-concatenating) the parameters

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood with respect to fitted parameters in real space
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood with respect to fitted parameters in real space

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenateparameters(model)
julia> â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = FHMDDM.âˆ‡âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)
```
"""
function âˆ‡âˆ‡loglikelihood!(model::Model, concatenatedÎ¸::Vector{<:Real}, indexÎ¸::IndexÎ¸)
	sortparameters!(model, concatenatedÎ¸, indexÎ¸)
	â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = âˆ‡âˆ‡loglikelihood(model)
	native2real!(âˆ‡â„“, âˆ‡âˆ‡â„“, indexÎ¸.latentÎ¸, model)
	âˆ‡â„“ = sortparameters(indexÎ¸.latentÎ¸, âˆ‡â„“)
	âˆ‡âˆ‡â„“ = sortparameters(indexÎ¸.latentÎ¸, âˆ‡âˆ‡â„“)
	return â„“, âˆ‡â„“, âˆ‡âˆ‡â„“
end

"""
	âˆ‡âˆ‡loglikelihood(model)

Hessian of the log-likelihood of data under a factorial hidden Markov drift-diffusion model (FHMDDM).

The gradient and the log-likelihood are also returned

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in native space
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood with respect to all parameters in native space

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> â„“, âˆ‡â„“, âˆ‡âˆ‡â„“ = FHMDDM.âˆ‡âˆ‡loglikelihood(model)
```
"""
function âˆ‡âˆ‡loglikelihood(model::Model)
	sameacrosstrials = Sameacrosstrials(model)
	@unpack trialsets = model
	output =map(trialsets, eachindex(trialsets)) do trialset, s
				glmÎ¸s = collect(trialset.mpGLMs[n].Î¸ for n = 1:length(trialset.mpGLMs))
		 		map(trialset.trials) do trial #pmap
					âˆ‡âˆ‡loglikelihood(glmÎ¸s, model.Î¸native, s, sameacrosstrials, trial)
				end
			end
	â„“ = output[1][1][1]
	âˆ‡â„“ = output[1][1][2]
	âˆ‡âˆ‡â„“ = output[1][1][3]
	for i in eachindex(output)
		for m = 2:length(output[i])
			â„“ += output[i][m][1]
			âˆ‡â„“ .+= output[i][m][2]
			âˆ‡âˆ‡â„“ .+= output[i][m][3]
		end
	end
	for i = 1:size(âˆ‡âˆ‡â„“,1)
		for j = i+1:size(âˆ‡âˆ‡â„“,2)
			âˆ‡âˆ‡â„“[j,i] = âˆ‡âˆ‡â„“[i,j]
		end
	end
	return â„“, âˆ‡â„“, âˆ‡âˆ‡â„“
end

"""
	âˆ‡âˆ‡loglikelihood(glmÎ¸s, Î¸native, s, sameacrosstrials, trial)

Hessian of the log-likelihood of the observations from one trial

The gradient and the log-likelihood are also returned

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`s`: index of the trialset
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood
"""
function âˆ‡âˆ‡loglikelihood(glmÎ¸s::Vector{<:GLMÎ¸},
						 Î¸native::LatentÎ¸,
						 s::Integer,
						 sameacrosstrials::Sameacrosstrials,
						 trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒsilent, âˆ‡Aáµƒsilent, âˆ‡âˆ‡Aáµƒsilent, Aá¶œáµ€, âˆ‡Aá¶œáµ€, Î”t, indexÎ¸_paâ‚, indexÎ¸_paâ‚œaâ‚œâ‚‹â‚, indexÎ¸_pcâ‚, indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚, indexÎ¸_Ïˆ, K, Ï€á¶œáµ€, âˆ‡Ï€á¶œáµ€, Î, nÎ¸_paâ‚, nÎ¸_paâ‚œaâ‚œâ‚‹â‚, nÎ¸_pcâ‚, nÎ¸_pcâ‚œcâ‚œâ‚‹â‚, nÎ¸_Ïˆ, index_paâ‚_in_Î¸, index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸, index_pcâ‚_in_Î¸, index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸, index_Ïˆ_in_Î¸ = sameacrosstrials
	indexÎ¸_pY = sameacrosstrials.indexÎ¸_pY[s]
	nÎ¸_pY = sameacrosstrials.nÎ¸_pY[s]
	index_pY_in_Î¸ = sameacrosstrials.index_pY_in_Î¸[s]
	indexÎ¸_trialset = sameacrosstrials.indexÎ¸_trialset[s]
	nÎ¸_trialset = sameacrosstrials.nÎ¸_trialset[s]
	âˆ‡f = map(i->zeros(Î,K), 1:nÎ¸_trialset)
	âˆ‡âˆ‡f = map(i->zeros(Î,K), CartesianIndices((nÎ¸_trialset,nÎ¸_trialset)))
	P = Probabilityvector(Î”t, Î¸native, Î)
	âˆ‡âˆ‡paâ‚ = map(i->zeros(Î), CartesianIndices((nÎ¸_paâ‚,nÎ¸_paâ‚)))
 	âˆ‡paâ‚ = map(i->zeros(Î), 1:nÎ¸_paâ‚)
	âˆ‡âˆ‡priorprobability!(âˆ‡âˆ‡paâ‚, âˆ‡paâ‚, P, trial.previousanswer)
	paâ‚ = P.ğ›‘
	pY = zeros(Î,K)
	âˆ‡pY = collect(zeros(Î,K) for n=1:nÎ¸_pY)
	âˆ‡âˆ‡pY = map(i->zeros(Î,K), CartesianIndices((nÎ¸_pY,nÎ¸_pY)))
	âˆ‡âˆ‡conditionallikelihood!(âˆ‡âˆ‡pY, âˆ‡pY, pY, glmÎ¸s, 1, trial.spiketrainmodels, sameacrosstrials)
	pYâ‚â¨€pcâ‚ = pY .* Ï€á¶œáµ€
	for i = 1:nÎ¸_paâ‚
		q = indexÎ¸_paâ‚[i]
		for j = i:nÎ¸_paâ‚
			r = indexÎ¸_paâ‚[j]
			âˆ‡âˆ‡f[q,r] = âˆ‡âˆ‡paâ‚[i,j] .* pYâ‚â¨€pcâ‚
		end
	end
	paâ‚â¨€pcâ‚ = paâ‚ .* Ï€á¶œáµ€
	for i = 1:nÎ¸_pY
		q = indexÎ¸_pY[i]
		for j = i:nÎ¸_pY
			r = indexÎ¸_pY[j]
			âˆ‡âˆ‡f[q,r] = âˆ‡âˆ‡pY[i,j] .* paâ‚â¨€pcâ‚
		end
	end
	for q = 1:nÎ¸_trialset
		for r = q:nÎ¸_trialset
			i = index_pcâ‚_in_Î¸[q]
			j = index_pY_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* paâ‚ .* âˆ‡Ï€á¶œáµ€[i]
			end
			i = index_paâ‚_in_Î¸[q]
			j = index_pY_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* âˆ‡paâ‚[i] .* Ï€á¶œáµ€
			end
			i = index_paâ‚_in_Î¸[q]
			j = index_pcâ‚_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= pY .* âˆ‡paâ‚[i] .* âˆ‡Ï€á¶œáµ€[j]
			end
			i = index_pcâ‚_in_Î¸[q]
			j = index_paâ‚_in_Î¸[r]
			if i > 0 && j > 0
				âˆ‡âˆ‡f[q,r] .+= pY .* âˆ‡paâ‚[j] .* âˆ‡Ï€á¶œáµ€[i]
			end
		end
	end
	for i = 1:nÎ¸_pY
		q = indexÎ¸_pY[i]
		âˆ‡f[q] = âˆ‡pY[i] .* paâ‚â¨€pcâ‚
	end
	for i = 1:nÎ¸_paâ‚
		q = indexÎ¸_paâ‚[i]
		âˆ‡f[q] = âˆ‡paâ‚[i] .* pYâ‚â¨€pcâ‚
	end
	for i = 1:nÎ¸_pcâ‚
		q = indexÎ¸_pcâ‚[i]
		âˆ‡f[q] .= paâ‚ .* pY .* âˆ‡Ï€á¶œáµ€[i]
	end
	f = paâ‚â¨€pcâ‚ # reuse memory
	f .*= pY
	âˆ‡âˆ‡â„“ = zeros(nÎ¸_trialset, nÎ¸_trialset)
	âˆ‡â„“ = zeros(nÎ¸_trialset)
	â„“ = zeros(1)
	forward!(âˆ‡âˆ‡f, âˆ‡f, f, âˆ‡âˆ‡â„“, âˆ‡â„“, â„“)
	if !isempty(clicks.inputtimesteps)
		adaptedclicks = âˆ‡âˆ‡adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
		âˆ‡âˆ‡Aáµƒinput = map(i->zeros(Î,Î), CartesianIndices((nÎ¸_paâ‚œaâ‚œâ‚‹â‚,nÎ¸_paâ‚œaâ‚œâ‚‹â‚)))
		âˆ‡Aáµƒinput = map(i->zeros(Î,Î), 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚)
		Aáµƒinput = zeros(Î,Î)
		Aáµƒinput[1,1] = Aáµƒinput[Î, Î] = 1.0
	end
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			update_for_âˆ‡âˆ‡transition_probabilities!(P, adaptedclicks, clicks, t)
			âˆ‡âˆ‡transitionmatrix!(âˆ‡âˆ‡Aáµƒinput, âˆ‡Aáµƒinput, Aáµƒinput, P)
			âˆ‡âˆ‡Aáµƒ = âˆ‡âˆ‡Aáµƒinput
			âˆ‡Aáµƒ = âˆ‡Aáµƒinput
			Aáµƒ = Aáµƒinput
		else
			âˆ‡âˆ‡Aáµƒ = âˆ‡âˆ‡Aáµƒsilent
			âˆ‡Aáµƒ = âˆ‡Aáµƒsilent
			Aáµƒ = Aáµƒsilent
		end
		âˆ‡âˆ‡conditionallikelihood!(âˆ‡âˆ‡pY, âˆ‡pY, pY, glmÎ¸s, t, trial.spiketrainmodels, sameacrosstrials)
		if t==trial.ntimesteps
			âˆ‚pYğ‘‘_âˆ‚Ïˆ = pYâ‚â¨€pcâ‚ # reuse memory
			differentiate_pYğ‘‘_wrt_Ïˆ!(âˆ‚pYğ‘‘_âˆ‚Ïˆ, pY, trial.choice)
			pğ‘‘ = P.ğ›‘ #reuse memory
			conditionallikelihood!(pğ‘‘, trial.choice, Î¸native.Ïˆ[1])
			pY .*= pğ‘‘
		end
		fâ¨‰Aá¶œáµ€ = f * Aá¶œáµ€
		Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ = Aáµƒ * fâ¨‰Aá¶œáµ€
		for q = 1:nÎ¸_trialset
			for r = q:nÎ¸_trialset
				âˆ‡âˆ‡f[q,r] = pY .* (Aáµƒ * âˆ‡âˆ‡f[q,r] * Aá¶œáµ€)
			end
		end
		if t==trial.ntimesteps
			dpğ‘‘_dÏˆ = differentiate_pğ‘‘_wrt_Ïˆ(trial.choice, K, Î)
			for q = 1:nÎ¸_trialset
				for r = q:nÎ¸_trialset
					i = index_Ïˆ_in_Î¸[q]
					if i > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * âˆ‡f[r] * Aá¶œáµ€)
					end
					j = index_Ïˆ_in_Î¸[r]
					if j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
					end
					i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
					# j = index_Ïˆ_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (Aáµƒ * f * âˆ‡Aá¶œáµ€[i])
					end
					i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
					# j = index_Ïˆ_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (âˆ‡Aáµƒ[i] * f * Aá¶œáµ€)
					end
					i = index_Ïˆ_in_Î¸[q]
					j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= âˆ‚pYğ‘‘_âˆ‚Ïˆ .* (âˆ‡Aáµƒ[j] * f * Aá¶œáµ€)
					end
					# i = index_Ïˆ_in_Î¸[q]
					j = index_pY_in_Î¸[r]
					if i > 0 && j > 0
						âˆ‡âˆ‡f[q,r] .+= dpğ‘‘_dÏˆ .* âˆ‡pY[j] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
					end
				end
			end
			for i = 1:nÎ¸_pY
				âˆ‡pY[i] .*= pğ‘‘
				for j = i:nÎ¸_pY
					âˆ‡âˆ‡pY[i,j] .*= pğ‘‘
				end
			end
		end
		for i = 1:nÎ¸_pY
			q = indexÎ¸_pY[i]
			for j = i:nÎ¸_pY
				r = indexÎ¸_pY[j]
				âˆ‡âˆ‡f[q,r] .+= âˆ‡âˆ‡pY[i,j] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
			end
		end
		for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
			q = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]
			for j = i:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
				r = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[j]
				âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡âˆ‡Aáµƒ[i,j] * fâ¨‰Aá¶œáµ€)
			end
		end
		for q = 1:nÎ¸_trialset
			for r = q:nÎ¸_trialset
				i = index_pY_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[i] .* (Aáµƒ * âˆ‡f[r] * Aá¶œáµ€)
				end
				j = index_pY_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
				end
				i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[i] * âˆ‡f[r] * Aá¶œáµ€)
				end
				j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[j] * âˆ‡f[q] * Aá¶œáµ€)
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				if i > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (Aáµƒ * âˆ‡f[r] * âˆ‡Aá¶œáµ€[i])
				end
				j = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[r]
				if j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (Aáµƒ * âˆ‡f[q] * âˆ‡Aá¶œáµ€[j])
				end
				i = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_pY_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (âˆ‡Aáµƒ[i] * fâ¨‰Aá¶œáµ€)
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_pY_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= âˆ‡pY[j] .* (Aáµƒ * f * âˆ‡Aá¶œáµ€[i])
				end
				i = index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[q]
				j = index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[r]
				if i > 0 && j > 0
					âˆ‡âˆ‡f[q,r] .+= pY .* (âˆ‡Aáµƒ[j] * f * âˆ‡Aá¶œáµ€[i])
				end
			end
		end
		for q = 1:nÎ¸_trialset
			âˆ‡f[q] = pY .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
		end
		for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
			q = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]
			âˆ‡f[q] .+= pY .* (âˆ‡Aáµƒ[i] * fâ¨‰Aá¶œáµ€)
		end
		for i = 1:nÎ¸_pY
			q = indexÎ¸_pY[i]
			âˆ‡f[q] .+= âˆ‡pY[i] .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
		end
		Aáµƒâ¨‰f = Aáµƒ * f
		for i = 1:nÎ¸_pcâ‚œcâ‚œâ‚‹â‚
			q = indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚[i]
			âˆ‡f[q] .+= pY .* (Aáµƒâ¨‰f * âˆ‡Aá¶œáµ€[i])
		end
		if t==trial.ntimesteps
			q = indexÎ¸_Ïˆ[1]
			âˆ‡f[q] = âˆ‚pYğ‘‘_âˆ‚Ïˆ .* Aáµƒâ¨‰fâ¨‰Aá¶œáµ€
		end
		f = Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ # reuse memory
		f .*= pY
		forward!(âˆ‡âˆ‡f, âˆ‡f, f, âˆ‡âˆ‡â„“, âˆ‡â„“, â„“)
	end
	return â„“[1], âˆ‡â„“, âˆ‡âˆ‡â„“
end

"""
	âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)

Sort a vector of parameters and compute the log-likelihood and its gradient

ARGUMENT
-`model`: a structure containing the data and hyperparameters of the factorial hidden drift-diffusion model
-`concatenatedÎ¸`: values of the parameters in real space concatenated as a vector
-`indexÎ¸`: a structure for sorting (i.e., un-concatenating) the parameters

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood with respect to fitted parameters in real space

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> concatenatedÎ¸, indexÎ¸ = FHMDDM.concatenateparameters(model)
julia> â„“, âˆ‡â„“ = FHMDDM.âˆ‡loglikelihood!(model, concatenatedÎ¸, indexÎ¸)
```
"""
function âˆ‡loglikelihood!(model::Model, concatenatedÎ¸::Vector{<:Real}, indexÎ¸::IndexÎ¸)
	sortparameters!(model, concatenatedÎ¸, indexÎ¸)
	â„“, âˆ‡â„“ = âˆ‡loglikelihood(model)
	native2real!(âˆ‡â„“, indexÎ¸.latentÎ¸, model)
	âˆ‡â„“ = sortparameters(indexÎ¸.latentÎ¸, âˆ‡â„“)
	return â„“, âˆ‡â„“
end

"""
	âˆ‡loglikelihood(model)

Gradient of the log-likelihood of data under a factorial hidden Markov drift-diffusion model (FHMDDM).

The log-likelihood is also returned

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in native space

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> â„“, âˆ‡â„“ = FHMDDM.âˆ‡loglikelihood(model)
```
"""
function âˆ‡loglikelihood(model::Model)
	sameacrosstrials = FHMDDM.Sameacrosstrials(model)
	@unpack Î¸native, trialsets = model
	@unpack Î”t, K, Î = model.options
	Aáµƒinput = zeros(Î,Î)
	Aáµƒinput[1,1] = 1.0
	Aáµƒinput[Î,Î] = 1.0
	âˆ‡Aáµƒinput = map(i->zeros(Î,Î), 1:sameacrosstrials.nÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	â„“ = zeros(1)
	âˆ‡â„“ = zeros(sameacrosstrials.nÎ¸_alltrialsets)
	âˆ‡f = map(i->zeros(Î,K), 1:sameacrosstrials.nÎ¸_alltrialsets)
 	âˆ‡paâ‚ = map(i->zeros(Î), 1:sameacrosstrials.nÎ¸_paâ‚)
	pY = zeros(Î,K)
	âˆ‡pY = collect(zeros(Î,K) for n=1:sameacrosstrials.nÎ¸_pY[1])
	P = FHMDDM.Probabilityvector(Î”t, Î¸native, Î)
	for s in eachindex(trialsets)
		glmÎ¸s = collect(trialsets[s].mpGLMs[n].Î¸ for n = 1:length(trialsets[s].mpGLMs))
		for m in eachindex(trialsets[s].trials)
			FHMDDM.âˆ‡loglikelihood!(Aáµƒinput, âˆ‡Aáµƒinput, â„“, âˆ‡â„“, âˆ‡f, âˆ‡paâ‚, pY, âˆ‡pY, P, glmÎ¸s, Î¸native, s, sameacrosstrials, trialsets[s].trials[m])
		end
	end
	return â„“[1], âˆ‡â„“
end

"""
	âˆ‡loglikelihood(glmÎ¸s, Î¸native, s, sameacrosstrials, trial)

Gradient of the log-likelihood of the observations from one trial

The log-likelihood is also returned

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`s`: index of the trialset
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
-`âˆ‡â„“`: gradient of the log-likelihood
"""
function âˆ‡loglikelihood!(Aáµƒinput::Matrix{<:Real},
						âˆ‡Aáµƒinput::Vector{<:Matrix{<:Real}},
						â„“::Vector{<:Real},
						âˆ‡â„“::Vector{<:Real},
						âˆ‡f::Vector{<:Matrix{<:Real}},
						âˆ‡paâ‚::Vector{<:Vector{<:Real}},
						pY::Matrix{<:Real},
						âˆ‡pY::Vector{<:Matrix{<:Real}},
						P::Probabilityvector,
						glmÎ¸s::Vector{<:GLMÎ¸},
						Î¸native::LatentÎ¸,
						s::Integer,
						sameacrosstrials::Sameacrosstrials,
						trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒsilent, âˆ‡Aáµƒsilent, Aá¶œáµ€, âˆ‡Aá¶œáµ€, Î”t, indexÎ¸_paâ‚, indexÎ¸_paâ‚œaâ‚œâ‚‹â‚, indexÎ¸_pcâ‚, indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚, indexÎ¸_Ïˆ, K, Ï€á¶œáµ€, âˆ‡Ï€á¶œáµ€, Î, nÎ¸_paâ‚, nÎ¸_paâ‚œaâ‚œâ‚‹â‚, nÎ¸_pcâ‚, nÎ¸_pcâ‚œcâ‚œâ‚‹â‚, nÎ¸_Ïˆ, dğ›_dB = sameacrosstrials
	indexÎ¸_pY = sameacrosstrials.indexÎ¸_pY[s]
	indexÎ¸_trialset = sameacrosstrials.indexÎ¸_trialset[s]
	nÎ¸_pY = sameacrosstrials.nÎ¸_pY[s]
	nÎ¸_trialset = sameacrosstrials.nÎ¸_trialset[s]
	âˆ‡priorprobability!(âˆ‡paâ‚, P, trial.previousanswer)
	paâ‚ = P.ğ›‘
	âˆ‡conditionallikelihood!(âˆ‡pY, pY, glmÎ¸s, 1, trial.spiketrainmodels, sameacrosstrials)
	paâ‚â¨€pcâ‚ = paâ‚ .* Ï€á¶œáµ€
	for i = 1:nÎ¸_pY
		q = indexÎ¸_pY[i]
		for jk in eachindex(paâ‚â¨€pcâ‚)
			âˆ‡f[q][jk] = âˆ‡pY[i][jk] * paâ‚â¨€pcâ‚[jk]
		end
	end
	pYâ‚â¨€pcâ‚ = pY .* Ï€á¶œáµ€
	for i = 1:nÎ¸_paâ‚
		q = indexÎ¸_paâ‚[i]
		for j=1:Î
			for k = 1:K
				âˆ‡f[q][j,k] = âˆ‡paâ‚[i][j] * pYâ‚â¨€pcâ‚[j,k]
			end
		end
	end
	for i = 1:nÎ¸_pcâ‚
		q = indexÎ¸_pcâ‚[1]
		for j=1:Î
			for k = 1:K
				âˆ‡f[q][j,k] = pY[j,k] * paâ‚[j] * âˆ‡Ï€á¶œáµ€[i][k]
			end
		end
	end
	f = paâ‚â¨€pcâ‚ # reuse memory
	f .*= pY
	forward!(âˆ‡f, f, âˆ‡â„“, â„“)
	if !isempty(clicks.inputtimesteps)
		adaptedclicks = âˆ‡adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	end
	indexÎ¸_trialset_but_Ïˆ = indexÎ¸_trialset[vcat(1:(indexÎ¸_Ïˆ[1]-1), indexÎ¸_Ïˆ[1]+1:end)]
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			update_for_âˆ‡transition_probabilities!(P, adaptedclicks, clicks, t)
			âˆ‡transitionmatrix!(âˆ‡Aáµƒinput, Aáµƒinput, P)
			âˆ‡Aáµƒ = âˆ‡Aáµƒinput
			Aáµƒ = Aáµƒinput
		else
			âˆ‡Aáµƒ = âˆ‡Aáµƒsilent
			Aáµƒ = Aáµƒsilent
		end
		âˆ‡conditionallikelihood!(âˆ‡pY, pY, glmÎ¸s, t, trial.spiketrainmodels, sameacrosstrials)
		conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, t, trial.spiketrainmodels)
		if t==trial.ntimesteps
			âˆ‚pYğ‘‘_âˆ‚Ïˆ = pYâ‚â¨€pcâ‚ # reuse memory
			differentiate_pYğ‘‘_wrt_Ïˆ!(âˆ‚pYğ‘‘_âˆ‚Ïˆ, pY, trial.choice)
			pğ‘‘ = P.ğ›‘ #reuse memory
			conditionallikelihood!(pğ‘‘, trial.choice, Î¸native.Ïˆ[1])
			pY .*= pğ‘‘
			for i = 1:nÎ¸_pY
				âˆ‡pY[i] .*= pğ‘‘
			end
		end
		fâ¨‰Aá¶œáµ€ = f * Aá¶œáµ€
		Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ = Aáµƒ * fâ¨‰Aá¶œáµ€
		Aáµƒâ¨‰f = Aáµƒ * f
		if t == 2
			for q in indexÎ¸_trialset
				if qâˆˆindexÎ¸_paâ‚œaâ‚œâ‚‹â‚[2:end]
					âˆ‡f[q] .= 0
				elseif q âˆˆ indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚
					âˆ‡f[q] .= 0
				elseif q âˆˆ indexÎ¸_Ïˆ
					âˆ‡f[q] .= 0
				else
					âˆ‡f[q] = pY .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
				end
			end
		else
			for q in indexÎ¸_trialset_but_Ïˆ
				âˆ‡f[q] = pY .* (Aáµƒ * âˆ‡f[q] * Aá¶œáµ€)
			end
		end
		for i = 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚
			q = indexÎ¸_paâ‚œaâ‚œâ‚‹â‚[i]
			âˆ‡Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ = âˆ‡Aáµƒ[i] * fâ¨‰Aá¶œáµ€
			for jk in eachindex(pY)
				âˆ‡f[q][jk] += pY[jk] * âˆ‡Aáµƒâ¨‰fâ¨‰Aá¶œáµ€[jk]
			end
		end
		for i = 1:nÎ¸_pY
			q = indexÎ¸_pY[i]
			for jk in eachindex(Aáµƒâ¨‰fâ¨‰Aá¶œáµ€)
				âˆ‡f[q][jk] += âˆ‡pY[i][jk] * Aáµƒâ¨‰fâ¨‰Aá¶œáµ€[jk]
			end
		end
		for i = 1:nÎ¸_pcâ‚œcâ‚œâ‚‹â‚
			q = indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚[i]
			Aáµƒâ¨‰fâ¨‰âˆ‡Aá¶œáµ€ = Aáµƒâ¨‰f * âˆ‡Aá¶œáµ€[i]
			for jk in eachindex(pY)
				âˆ‡f[q][jk] += pY[jk] * Aáµƒâ¨‰fâ¨‰âˆ‡Aá¶œáµ€[jk]
			end
		end
		if t==trial.ntimesteps
			for jk in eachindex(âˆ‚pYğ‘‘_âˆ‚Ïˆ)
				âˆ‡f[indexÎ¸_Ïˆ[1]][jk] = âˆ‚pYğ‘‘_âˆ‚Ïˆ[jk] * Aáµƒâ¨‰fâ¨‰Aá¶œáµ€[jk]
			end
		end
		f = Aáµƒâ¨‰fâ¨‰Aá¶œáµ€ # reuse memory
		f .*= pY
		forward!(âˆ‡f, f, âˆ‡â„“, â„“)
	end
	return nothing
end

"""
	loglikelihood(model)

Log-likelihood of data under a factorial hidden Markov drift-diffusion model (FHMDDM).

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`â„“`: log-likelihood

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> â„“ = loglikelihood(model)
```
"""
function loglikelihood(model::Model)
	sameacrosstrials = Sameacrosstrials(model)
	@unpack options, Î¸native, trialsets = model
	@unpack Î”t, K, Î = options
	P = Probabilityvector(Î”t, Î¸native, Î)
	pY = zeros(Î,K)
	Aáµƒinput = zeros(Î,Î)
	Aáµƒinput[1,1] = Aáµƒinput[Î, Î] = 1.0
	â„“ = 0.0
	for s in eachindex(trialsets)
		glmÎ¸s = collect(trialsets[s].mpGLMs[n].Î¸ for n = 1:length(trialsets[s].mpGLMs))
		for m in eachindex(trialsets[s].trials)
			â„“ += loglikelihood!(Aáµƒinput, P, pY, glmÎ¸s, model.Î¸native, sameacrosstrials, trialsets[s].trials[m])
		end
	end
	return â„“
end

"""
	loglikelihood(glmÎ¸s, Î¸native, s, sameacrosstrials, trial)

Log-likelihood of the observations from one trial, not meant for ForwardDiff

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`s`: index of the trialset
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
"""
function loglikelihood!(Aáµƒinput::Matrix{<:Real},
					   P::Probabilityvector,
						pY::Matrix{<:Real},
						glmÎ¸s::Vector{<:GLMÎ¸},
					   	Î¸native::LatentÎ¸,
						sameacrosstrials::Sameacrosstrials,
						trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒsilent, Aá¶œáµ€, Î”t, K, Ï€á¶œáµ€, Î, dğ›_dB = sameacrosstrials
	priorprobability!(P, trial.previousanswer)
	paâ‚ = P.ğ›‘
	conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, 1, trial.spiketrainmodels)
	f = pY .* paâ‚ .* Ï€á¶œáµ€
	â„“ = zeros(1)
	forward!(f, â„“)
	if !isempty(clicks.inputtimesteps)
		adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	end
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			update_for_transition_probabilities!(P, adaptedclicks, clicks, t)
			transitionmatrix!(Aáµƒinput, P)
			Aáµƒ = Aáµƒinput
		else
			Aáµƒ = Aáµƒsilent
		end
		conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, t, trial.spiketrainmodels)
		if t==trial.ntimesteps
			pğ‘‘ = P.ğ›‘ #reuse memory
			conditionallikelihood!(pğ‘‘, trial.choice, Î¸native.Ïˆ[1])
			pY .*= pğ‘‘
		end
		f = pY .* (Aáµƒ * f * Aá¶œáµ€)
		forward!(f, â„“)
	end
	return â„“[1]
end

"""
EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> pğ˜ğ‘‘ = FHMDDM.likelihood(model)
julia> â„“ = FHMDDM.loglikelihood!(pğ˜ğ‘‘, model)
```
"""
function loglikelihood!(pğ˜ğ‘‘::Vector{<:Vector{<:Vector{<:Matrix{<:Real}}}}, model::Model)
	sameacrosstrials = Sameacrosstrials(model)
	@unpack options, Î¸native, trialsets = model
	@unpack Î”t, K, Î = options
	likelihood!(pğ˜ğ‘‘, model.trialsets, model.Î¸native.Ïˆ[1])
	P = Probabilityvector(Î”t, Î¸native, Î)
	Aáµƒinput = zeros(Î,Î)
	Aáµƒinput[1,1] = Aáµƒinput[Î, Î] = 1.0
	â„“ = 0.0
	for s in eachindex(model.trialsets)
		for m in eachindex(model.trialsets[s].trials)
			â„“ += loglikelihood!(Aáµƒinput, P, pğ˜ğ‘‘[s][m], model.Î¸native, sameacrosstrials, model.trialsets[s].trials[m])
		end
	end
	return â„“
end

"""
	loglikelihood(glmÎ¸s, Î¸native, s, sameacrosstrials, trial)

Log-likelihood of the observations from one trial, not meant for ForwardDiff

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`s`: index of the trialset
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
"""
function loglikelihood!(Aáµƒinput::Matrix{<:Real},
					    P::Probabilityvector,
						pğ˜ğ‘‘::Vector{<:Matrix{<:Real}},
					   	Î¸native::LatentÎ¸,
						sameacrosstrials::Sameacrosstrials,
						trial::Trial)
	@unpack clicks = trial
	@unpack Aáµƒsilent, Aá¶œáµ€, Î”t, K, Ï€á¶œáµ€, Î = sameacrosstrials
	priorprobability!(P, trial.previousanswer)
	paâ‚ = P.ğ›‘
	f = pğ˜ğ‘‘[1] .* paâ‚ .* Ï€á¶œáµ€
	â„“ = zeros(1)
	forward!(f, â„“)
	if !isempty(clicks.inputtimesteps)
		adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	end
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			update_for_transition_probabilities!(P, adaptedclicks, clicks, t)
			transitionmatrix!(Aáµƒinput, P)
			Aáµƒ = Aáµƒinput
		else
			Aáµƒ = Aáµƒsilent
		end
		f = pğ˜ğ‘‘[t] .* (Aáµƒ * f * Aá¶œáµ€)
		forward!(f, â„“)
	end
	return â„“[1]
end

"""
	loglikelihood_Î¸native(concatenatedÎ¸native, model)

Log-likelihood of the data given the complete set of parameters in their native space

ARGUMENT
-`x`: vector of concatenated parameters in their native space. This vector needs to include all parameters, regardless whether they are being fitted
-`model`: a structure containing the

RETURN
-log-likelihood of the data

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> x = FHMDDM.concatenate_native_parameters(model)
julia> â„“ = FHMDDM.loglikelihood_Î¸native(x, model)
```
"""
function loglikelihood_Î¸native(x::Vector{<:Real}, model::Model)
	model = sort_native_parameters(x, model)
	@unpack options, trialsets = model
	output =map(trialsets) do trialset
				glmÎ¸s = collect(trialset.mpGLMs[n].Î¸ for n = 1:length(trialset.mpGLMs))
		 		omap(trialset.trials) do trial
					loglikelihood(glmÎ¸s, options, model.Î¸native, trial)
				end
			end
	â„“ = output[1][1]
	for i in eachindex(output)
		for m = 2:length(output[i])
			â„“ += output[i][m]
		end
	end
	return â„“
end

"""
	loglikelihood(glmÎ¸s, Î¸native, sameacrosstrials, trial)

Log-likelihood of the data in one trial

ARGUMENT
-`glmÎ¸s`: a vector whose each element is a structure containing the parameters of of the generalized linear model of a neuron
-`Î¸native`: a structure containing parameters specifying the latent variables in their native space
-`sameacrosstrials`: a structure containing quantities used in each trial
-`trial`: a structure containing information on the sensory stimuli, spike trains, input to each neuron's GLM, and behavioral choice

RETURN
-`â„“`: log-likelihood
"""
function loglikelihood(glmÎ¸s::Vector{<:GLMÎ¸},
   					   options::Options,
					   Î¸native::LatentÎ¸,
					   trial::Trial)
	@unpack clicks = trial
	@unpack Î”t, K, Î = options
	type = eltype(glmÎ¸s[1].ğ®[1])
	adaptedclicks = adapt(clicks, Î¸native.k[1], Î¸native.Ï•[1])
	Aáµƒinput, Aáµƒsilent = zeros(type,Î,Î), zeros(type,Î,Î)
	expÎ»Î”t = exp(Î¸native.Î»[1]*Î”t)
	dÎ¼_dÎ”c = differentiate_Î¼_wrt_Î”c(Î”t, Î¸native.Î»[1])
	dğ›_dB = (2 .*collect(1:Î) .- Î .- 1)./(Î-2)
	ğ› = Î¸native.B[1].*dğ›_dB
	transitionmatrix!(Aáµƒsilent, expÎ»Î”t.*ğ›, âˆš(Î”t*Î¸native.ÏƒÂ²â‚[1]), ğ›)
	Aá¶œâ‚â‚ = Î¸native.Aá¶œâ‚â‚[1]
	Aá¶œâ‚‚â‚‚ = Î¸native.Aá¶œâ‚‚â‚‚[1]
	Ï€á¶œâ‚ = Î¸native.Ï€á¶œâ‚[1]
	if K == 2
		Aá¶œáµ€ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚â‚; 1-Aá¶œâ‚‚â‚‚ Aá¶œâ‚‚â‚‚]
		Ï€á¶œáµ€ = [Ï€á¶œâ‚ 1-Ï€á¶œâ‚]
	else
		Aá¶œáµ€ = ones(1,1)
		Ï€á¶œáµ€ = ones(1,1)
	end
	paâ‚ = probabilityvector(Î¸native.Î¼â‚€[1]+Î¸native.wâ‚•[1]*trial.previousanswer, âˆšÎ¸native.ÏƒÂ²áµ¢[1], ğ›)
	pY = zeros(type, Î, K)
	conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, 1, trial.spiketrainmodels)
	f = pY .* paâ‚ .* Ï€á¶œáµ€
	â„“ = zeros(type, 1)
	forward!(f, â„“)
	for t=2:trial.ntimesteps
		if t âˆˆ clicks.inputtimesteps
			cL = sum(adaptedclicks.C[clicks.left[t]])
			cR = sum(adaptedclicks.C[clicks.right[t]])
			ğ› = expÎ»Î”t.*ğ› .+ (cR-cL)*dÎ¼_dÎ”c
			Ïƒ = âˆš((cR+cL)*Î¸native.ÏƒÂ²â‚›[1] + Î”t*Î¸native.ÏƒÂ²â‚[1])
			transitionmatrix!(Aáµƒinput, ğ›, Ïƒ, ğ›)
			Aáµƒ = Aáµƒinput
		else
			Aáµƒ = Aáµƒsilent
		end
		conditionallikelihood!(pY, Î”t, dğ›_dB, glmÎ¸s, K, t, trial.spiketrainmodels)
		if t==trial.ntimesteps
			pğ‘‘ = paâ‚ #reuse memory
			conditionallikelihood!(pğ‘‘, trial.choice, Î¸native.Ïˆ[1])
			pY .*= pğ‘‘
		end
		f = pY .* (Aáµƒ * f * Aá¶œáµ€)
		forward!(f, â„“)
	end
	return â„“[1]
end

"""
	compare_gradients_hessians_Î¸native(model)

Compare the automatically computed and hand-coded gradients and hessians with respect to the parameters in their native space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a factorial hidden-Markov drift-diffusion model

RETURN
-`absdiffâ„“`: absolute difference in the log-likelihood evaluted using the algorithm bein automatically differentiated and the hand-coded algorithm
-`absdiffâˆ‡`: absolute difference in the gradients
-`absdiffâˆ‡âˆ‡`: absolute difference in the hessians

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_09_test/data.mat"; randomize=true)
julia> absdiffâ„“, absdiffâˆ‡, absdiffâˆ‡âˆ‡ = FHMDDM.compare_gradients_hessians_Î¸native(model)
julia> maximum(absdiffâˆ‡âˆ‡)
```
"""
function compare_gradients_hessians_Î¸native(model::Model)
	x0 = concatenate_native_parameters(model)
	f(x) = loglikelihood_Î¸native(x, model)
	â„“auto = f(x0)
	âˆ‡auto = ForwardDiff.gradient(f, x0)
	âˆ‡âˆ‡auto = ForwardDiff.hessian(f, x0)
	â„“hand, âˆ‡hand, âˆ‡âˆ‡hand = FHMDDM.âˆ‡âˆ‡loglikelihood(model)
	return abs(â„“auto-â„“hand), abs.(âˆ‡auto .- âˆ‡hand), abs.(âˆ‡âˆ‡auto .- âˆ‡âˆ‡hand)
end

"""
    loglikelihood(concatenatedÎ¸, indexÎ¸, model)

Compute the log-likelihood in a way that is compatible with ForwardDiff

UNMODIFIED ARGUMENT
-`concatenatedÎ¸`: a vector of concatenated parameter values
-`indexÎ¸`: struct indexing of each parameter in the vector of concatenated values
-`model`: an instance of FHM-DDM

RETURN
-log-likelihood
"""
# function loglikelihood(concatenatedÎ¸::Vector{<:Real},
# 					   indexÎ¸::IndexÎ¸,
# 					   model::Model)
# 	model = sortparameters(concatenatedÎ¸, indexÎ¸, model)
# 	@unpack options, trialsets = model
# 	output =map(trialsets) do trialset
# 				glmÎ¸s = collect(trialset.mpGLMs[n].Î¸ for n = 1:length(trialset.mpGLMs))
# 		 		map(trialset.trials) do trial #pmap
# 					loglikelihood(glmÎ¸s, options, model.Î¸native, trial)
# 				end
# 			end
# 	â„“ = output[1][1]
# 	for i in eachindex(output)
# 		for m = 2:length(output[i])
# 			â„“ += output[i][m]
# 		end
# 	end
# 	return â„“
# end

"""
	compare_gradients_hessians(model)

Compare the automatically computed and hand-coded gradients and hessians with respect to the parameters being fitted in their real space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a factorial hidden-Markov drift-diffusion model

RETURN
-`absdiffâ„“`: absolute difference in the log-likelihood evaluted using the algorithm bein automatically differentiated and the hand-coded algorithm
-`absdiffâˆ‡`: absolute difference in the gradients
-`absdiffâˆ‡âˆ‡`: absolute difference in the hessians

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> absdiffâ„“, absdiffâˆ‡, absdiffâˆ‡âˆ‡ = FHMDDM.compare_gradients_hessians(model)
```
"""
function compare_gradients_hessians(model::Model)
	concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
	f(x) = loglikelihood(x, indexÎ¸, model)
	â„“auto = f(concatenatedÎ¸)
	âˆ‡auto = ForwardDiff.gradient(f, concatenatedÎ¸)
	âˆ‡âˆ‡auto = ForwardDiff.hessian(f, concatenatedÎ¸)
	â„“hand, âˆ‡hand, âˆ‡âˆ‡hand = FHMDDM.âˆ‡âˆ‡loglikelihood!(model,concatenatedÎ¸,indexÎ¸)
	return abs(â„“auto-â„“hand), abs.(âˆ‡auto .- âˆ‡hand), abs.(âˆ‡âˆ‡auto .- âˆ‡âˆ‡hand)
end

"""
	compare_gradients(model)

Compare the automatically computed and hand-coded gradients with respect to the parameters being fitted in their real space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of a factorial hidden-Markov drift-diffusion model

RETURN
-`absdiffâ„“`: absolute difference in the log-likelihood evaluted using the algorithm bein automatically differentiated and the hand-coded algorithm
-`absdiffâˆ‡`: absolute difference in the gradients

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> absdiffâ„“, absdiffâˆ‡ = FHMDDM.compare_gradients(model)
```
"""
function compare_gradients(model::Model)
	concatenatedÎ¸, indexÎ¸ = concatenateparameters(model)
	f(x) = loglikelihood(x, indexÎ¸, model)
	â„“auto = f(concatenatedÎ¸)
	âˆ‡auto = ForwardDiff.gradient(f, concatenatedÎ¸)
	â„“hand, âˆ‡hand = FHMDDM.âˆ‡loglikelihood!(model,concatenatedÎ¸,indexÎ¸)
	return abs(â„“auto-â„“hand), abs.(âˆ‡auto .- âˆ‡hand)
end

"""
	forward!(âˆ‡âˆ‡f,âˆ‡f,f,âˆ‡âˆ‡â„“,âˆ‡â„“,â„“)

Normalize the forward term and its first- and second-order partial derivatives and update the log-likelihood and its first- and second-order partial derivatives

For computational efficiency, no entry below the main diagonal of the Hessian matrix of the log-likelihood is updated

ARGUMENT
-`âˆ‡âˆ‡f`: Second-order partial derivatives of the un-normalized forward term. Element `âˆ‡âˆ‡f[q,r][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th and r-th parameter.
-`âˆ‡f`: first-order partial derivatives of the un-normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th parameter.
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood for the data before the current time-step
-`âˆ‡â„“`: gradient of the log-likelihood for the data before the current time-step
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`âˆ‡âˆ‡f`: Second-order partial derivatives of the normalized forward term. Element `âˆ‡âˆ‡f[q,r][i,j]` corresponds to `âˆ‚Â²p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)âˆ‚Î¸(r)`
-`âˆ‡f`: first-order partial derivatives of the normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to `âˆ‚p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)`
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood for the data up to the current time-step
-`âˆ‡â„“`: gradient of the log-likelihood for the data up to the current time-step
-`â„“`: log-likelihood for the data before the up to the current time-step

"""
function forward!(âˆ‡âˆ‡f::Matrix{<:Matrix{<:Real}},
				  âˆ‡f::Vector{<:Matrix{<:Real}},
				  f::Matrix{<:Real},
				  âˆ‡âˆ‡â„“::Matrix{<:Real},
 				  âˆ‡â„“::Vector{<:Real},
				  â„“::Vector{<:Real})
	âˆ‡D, D = forward!(âˆ‡f,f,âˆ‡â„“,â„“)
	nparameters = length(âˆ‡f)
	for i = 1:nparameters
		for j = i:nparameters
			âˆ‡âˆ‡Dáµ¢â±¼ = sum(âˆ‡âˆ‡f[i,j])
			âˆ‡âˆ‡â„“[i,j] += (âˆ‡âˆ‡Dáµ¢â±¼ - âˆ‡D[i]*âˆ‡D[j]/D)/D
			âˆ‡âˆ‡f[i,j] = (âˆ‡âˆ‡f[i,j] .- âˆ‡f[i].*âˆ‡D[j] .- âˆ‡f[j].*âˆ‡D[i] .- f.*âˆ‡âˆ‡Dáµ¢â±¼)./D
		end
	end
	return nothing
end

"""
	forward!(âˆ‡f,f,âˆ‡â„“,â„“)

Normalize the forward term and its first-order partial derivatives and update the log-likelihood and its first-partial derivatives

ARGUMENT
-`âˆ‡f`: first-order partial derivatives of the un-normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to the derivative of the un-normalized forward term in the i-th accumulator state and j-th coupling state with respect to the q-th parameter.
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`âˆ‡â„“`: gradient of the log-likelihood for the data before the current time-step
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`âˆ‡f`: first-order partial derivatives of the normalized forward term. Element `âˆ‡f[q][i,j]` corresponds to `âˆ‚p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)} / âˆ‚Î¸(q)`
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`âˆ‡â„“`: gradient of the log-likelihood for the data up to the current time-step
-`â„“`: log-likelihood for the data before the up to the current time-step

RETURN
-`âˆ‡D`: gradient of the past-conditioned emissions likelihood for the current time step
-`D`: past-conditioned emissions likelihood: `p{ğ˜(t) âˆ£ ğ˜(1:t-1))`
"""
function forward!(âˆ‡f::Vector{<:Matrix{<:Real}},
				  f::Matrix{<:Real},
 				  âˆ‡â„“::Vector{<:Real},
				  â„“::Vector{<:Real})
	D = forward!(f,â„“)
	âˆ‡D = map(sum, âˆ‡f)
	âˆ‡â„“ .+= âˆ‡D./D
	for i in eachindex(âˆ‡f)
		âˆ‡f[i] = (âˆ‡f[i] .- f.*âˆ‡D[i])./D
	end
	return âˆ‡D, D
end

"""
	forward!(f,â„“)

Normalize the forward term and update the log-likelihood to include the emissions from the current time step

ARGUMENT
-`f`: un-normalized forward term. Element `f[i,j]` corresponds to the un-normalized forward term in the i-th accumulator state and j-th coupling state
-`â„“`: log-likelihood for the data before the current time-step

POST-MODIFICATION ARGUMENT
-`f`: normalized forward term, which represents the joint conditional probability of the latent variables given the elapsed emissions. Element `f[i,j]` corresponds to `p{a(t)=Î¾(i), c(t)=j âˆ£ ğ˜(1:t)}`
-`â„“`: log-likelihood for the data before the up to the current time-step

RETURN
-`D`: past-conditioned emissions likelihood: `p{ğ˜(t) âˆ£ ğ˜(1:t-1))`
"""
function forward!(f::Matrix{<:Real},
				  â„“::Vector{<:Real})
	D = sum(f)
	â„“[1] += log(D)
	f ./= D
	return D
end

"""
	differentiate_pYğ‘‘_wrt_Ïˆ!(âˆ‚pYğ‘‘_âˆ‚Ïˆ, pY, ğ‘‘, Ïˆ)

Partial derivatives of the conditional likelihood of the emissions at the last time step with respect to the lapse rate

ARGUMENT
-`pY`: conditional likelihood of the population spiking at the last time step `T`. Element `pY[i,j]` represents p{Y(T) âˆ£ a(T)=Î¾(i), c(T)=j}
-`ğ‘‘`: left (false) or right (true) choice of the animal

MODIFIED ARGUMENT
-`âˆ‚pYğ‘‘_âˆ‚Ïˆ`: partial derivative of the emissions at the last time step (population spiking and the choice) with respect to the lapse rate. Element `âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j]` represents:
	âˆ‚p{Y(T), ğ‘‘ âˆ£ a(T)=Î¾(i), c(T)=j}}/âˆ‚Ïˆ
"""
function differentiate_pYğ‘‘_wrt_Ïˆ!(âˆ‚pYğ‘‘_âˆ‚Ïˆ::Matrix{<:Real}, pY::Matrix{<:Real}, ğ‘‘::Bool)
	if ğ‘‘
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = 0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = -0.5
	else
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = -0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = 0.5
	end
	Î,K = size(pY)
	zeroindex = cld(Î,2)
	for j = 1:K
		for i = 1:zeroindex-1
			âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j] = pY[i,j]*âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ
		end
		âˆ‚pYğ‘‘_âˆ‚Ïˆ[zeroindex,j] = 0.0
		for i = zeroindex+1:Î
			âˆ‚pYğ‘‘_âˆ‚Ïˆ[i,j] = pY[i,j]*âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ
		end
	end
end

"""
	differentiate_pğ‘‘_wrt_Ïˆ(ğ‘‘,K,Î)

Derivative of the conditional likelihood of the choice with respect to Ïˆ

ARGUMENT
-`ğ‘‘`: choice: left(false) or right(true)
-`K`: number of coupling states
-`Î`: number of accumulator states

RETURN
-`dpğ‘‘_dÏˆ`: a matrix whose element `dpğ‘‘_dÏˆ[i,j]` represents âˆ‚p(ğ‘‘ âˆ£ a=i, c=j)/âˆ‚Ïˆ
"""
function differentiate_pğ‘‘_wrt_Ïˆ(ğ‘‘::Bool, K::Integer, Î::Integer)
	dpğ‘‘_dÏˆ = zeros(Î,K)
	if ğ‘‘
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = 0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = -0.5
	else
		âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ = -0.5
		âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ = 0.5
	end
	zeroindex = cld(Î,2)
	for j = 1:K
		for i = 1:zeroindex-1
			dpğ‘‘_dÏˆ[i,j] = âˆ‚pğ‘‘_Î¾â»_âˆ‚Ïˆ
		end
		for i = zeroindex+1:Î
			dpğ‘‘_dÏˆ[i,j] = âˆ‚pğ‘‘_Î¾âº_âˆ‚Ïˆ
		end
	end
	return dpğ‘‘_dÏˆ
end

"""
	conditionallikelihood!(pğ‘‘, ğ‘‘, Ïˆ)

conditional likelihood of the choice

ARGUMENT
-`P`: a matrix whose element `P[i,j]` corresponds to the i-th accumulator state and j-th coupling state
-`ğ‘‘`: left (false) or right (true) choice of the animal
-`Ïˆ`: lapse rate

MODIFIED ARGUMENT
-`pğ‘‘`: p{ğ‘‘ âˆ£ a(T)=Î¾(i), c(T)=j}
"""
function conditionallikelihood!(pğ‘‘::Vector{<:Real}, ğ‘‘::Bool, Ïˆ::Real)
	if ğ‘‘
		pğ‘‘_Î¾â» = Ïˆ/2
		pğ‘‘_Î¾âº = 1-Ïˆ/2
	else
		pğ‘‘_Î¾â» = 1-Ïˆ/2
		pğ‘‘_Î¾âº = Ïˆ/2
	end
	Î = length(pğ‘‘)
	zeroindex = cld(Î,2)
	for i = 1:zeroindex-1
		pğ‘‘[i] = pğ‘‘_Î¾â»
	end
	pğ‘‘[zeroindex] = 0.5
	for i = zeroindex+1:Î
		pğ‘‘[i] = pğ‘‘_Î¾âº
	end
	return nothing
end

"""
	native2real!(âˆ‡â„“, âˆ‡âˆ‡â„“, latentÎ¸index, model)

Convert the gradient and hessian from being with respect to the parameters in native space to parameters in real space

ARGUMENT
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in native space
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood with respect to all parameters in native space
-`latentÎ¸index`: index of each latent parameter in the gradient and Hessian
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

MODIFIED ARGUMENT
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in real space
-`âˆ‡âˆ‡â„“`: Hessian matrix of the log-likelihood with respect to all parameters in real space
"""
function native2real!(âˆ‡â„“::Vector{<:Real}, âˆ‡âˆ‡â„“::Matrix{<:Real}, latentÎ¸index::LatentÎ¸, model::Model)
	firstderivatives = differentiate_native_wrt_real(model)
	secondderivatives = differentiate_twice_native_wrt_real(model)
	for parametername in fieldnames(LatentÎ¸)
		d1 = getfield(firstderivatives, parametername)[1]
		d2 = getfield(secondderivatives, parametername)[1]
		if d1 != 1.0
			i = getfield(latentÎ¸index, parametername)[1]
			âˆ‡âˆ‡â„“[i,:] .*= d1
			âˆ‡âˆ‡â„“[:,i] .*= d1
			âˆ‡âˆ‡â„“[i,i] += d2*âˆ‡â„“[i]
			âˆ‡â„“[i] *= d1
		end
	end
	return nothing
end

"""
	native2real!(âˆ‡â„“, latentÎ¸index, model)

Convert the gradient from being with respect to the parameters in native space to parameters in real space

ARGUMENT
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in native space
-`latentÎ¸index`: index of each latent parameter in the gradient and Hessian
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

MODIFIED ARGUMENT
-`âˆ‡â„“`: gradient of the log-likelihood with respect to all parameters in real space
"""
function native2real!(âˆ‡â„“::Vector{<:Real}, latentÎ¸index::LatentÎ¸, model::Model)
	firstderivatives = differentiate_native_wrt_real(model)
	for parametername in fieldnames(LatentÎ¸)
		d1 = getfield(firstderivatives, parametername)[1]
		if d1 != 1.0
			i = getfield(latentÎ¸index, parametername)[1]
			âˆ‡â„“[i] *= d1
		end
	end
	return nothing
end

"""
	differentiate_native_wrt_real(model)

Derivative of each latent-variable-related parameter in its native space with respect to its value in real space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`derivatives`: an instance of `LatentÎ¸` containing the derivative of each parameter in its native space with respect to its value in real space
"""
function differentiate_native_wrt_real(model::Model)
	@unpack options, Î¸real, Î¸native = model
	tmpAá¶œâ‚â‚ = logistic(Î¸real.Aá¶œâ‚â‚[1] + logit(options.q_Aá¶œâ‚â‚))
	tmpAá¶œâ‚‚â‚‚ = logistic(Î¸real.Aá¶œâ‚‚â‚‚[1] + logit(options.q_Aá¶œâ‚‚â‚‚))
	tmpÏ€á¶œâ‚ 	= logistic(Î¸real.Ï€á¶œâ‚[1] + logit(options.q_Ï€á¶œâ‚))
	tmpÏˆ 	= logistic(Î¸real.Ïˆ[1] + logit(options.q_Ïˆ))
	f_bound_z = 1.0-2.0*options.bound_z
	f_bound_Ïˆ = 1.0-2.0*options.bound_Ïˆ
	d = LatentÎ¸()
	d.Aá¶œâ‚â‚[1] = f_bound_z*tmpAá¶œâ‚â‚*(1.0 - tmpAá¶œâ‚â‚)
	d.Aá¶œâ‚‚â‚‚[1] = f_bound_z*tmpAá¶œâ‚‚â‚‚*(1.0 - tmpAá¶œâ‚‚â‚‚)
	d.B[1] = Î¸native.B[1]*logistic(-Î¸real.B[1])
	d.k[1] = Î¸native.k[1]
	d.Î»[1] = 1.0
	d.Î¼â‚€[1] = 1.0
	d.Ï•[1] = Î¸native.Ï•[1]*(1.0 - Î¸native.Ï•[1])
	d.Ï€á¶œâ‚[1] = f_bound_z*tmpÏ€á¶œâ‚*(1.0 - tmpÏ€á¶œâ‚)
	d.Ïˆ[1] = f_bound_Ïˆ*tmpÏˆ*(1.0 - tmpÏˆ)
	d.ÏƒÂ²â‚[1] = options.q_ÏƒÂ²â‚*exp(Î¸real.ÏƒÂ²â‚[1])
	d.ÏƒÂ²áµ¢[1] = options.q_ÏƒÂ²áµ¢*exp(Î¸real.ÏƒÂ²áµ¢[1])
	d.ÏƒÂ²â‚›[1] = options.q_ÏƒÂ²â‚›*exp(Î¸real.ÏƒÂ²â‚›[1])
	d.wâ‚•[1] = 1.0
	return d
end

"""
	differentiate_twice_native_wrt_real(model)

Second derivative of each latent-variable-related parameter in its native space with respect to its value in real space

ARGUMENT
-`model`: a structure containing the data, parameters, and hyperparameters of an FHMDDM

RETURN
-`derivatives`: an instance of `LatentÎ¸` containing the derivative of each parameter in its native space with respect to its value in real space
"""
function differentiate_twice_native_wrt_real(model::Model)
	@unpack options, Î¸real, Î¸native = model
	tmpAá¶œâ‚â‚ = logistic(Î¸real.Aá¶œâ‚â‚[1] + logit(options.q_Aá¶œâ‚â‚))
	tmpAá¶œâ‚‚â‚‚ = logistic(Î¸real.Aá¶œâ‚‚â‚‚[1] + logit(options.q_Aá¶œâ‚‚â‚‚))
	tmpÏ€á¶œâ‚ 	= logistic(Î¸real.Ï€á¶œâ‚[1] + logit(options.q_Ï€á¶œâ‚))
	tmpÏˆ 	= logistic(Î¸real.Ïˆ[1] + logit(options.q_Ïˆ))
	f_bound_z = 1.0-2.0*options.bound_z
	f_bound_Ïˆ = 1.0-2.0*options.bound_Ïˆ
	d = LatentÎ¸()
	d.Aá¶œâ‚â‚[1] = f_bound_z*(tmpAá¶œâ‚â‚*(1-tmpAá¶œâ‚â‚)^2 - tmpAá¶œâ‚â‚^2*(1-tmpAá¶œâ‚â‚))
	d.Aá¶œâ‚‚â‚‚[1] = f_bound_z*(tmpAá¶œâ‚‚â‚‚*(1-tmpAá¶œâ‚‚â‚‚)^2 - tmpAá¶œâ‚‚â‚‚^2*(1-tmpAá¶œâ‚‚â‚‚))
	fB = logistic(Î¸real.B[1])
	d.B[1] = 2options.q_B*(fB*(1-fB)^2 - fB^2*(1-fB))
	d.k[1] = Î¸native.k[1]
	d.Î»[1] = 0.0
	d.Î¼â‚€[1] = 0.0
	d.Ï•[1] = Î¸native.Ï•[1]*(1.0 - Î¸native.Ï•[1])^2 - Î¸native.Ï•[1]^2*(1.0 - Î¸native.Ï•[1])
	d.Ï€á¶œâ‚[1] = f_bound_z*(tmpÏ€á¶œâ‚*(1-tmpÏ€á¶œâ‚)^2 - tmpÏ€á¶œâ‚^2*(1-tmpÏ€á¶œâ‚))
	d.Ïˆ[1] = f_bound_Ïˆ*(tmpÏˆ*(1-tmpÏˆ)^2 - tmpÏˆ^2*(1-tmpÏˆ))
	d.ÏƒÂ²â‚[1] = options.q_ÏƒÂ²â‚*exp(Î¸real.ÏƒÂ²â‚[1])
	d.ÏƒÂ²áµ¢[1] = options.q_ÏƒÂ²áµ¢*exp(Î¸real.ÏƒÂ²áµ¢[1])
	d.ÏƒÂ²â‚›[1] = options.q_ÏƒÂ²â‚›*exp(Î¸real.ÏƒÂ²â‚›[1])
	d.wâ‚•[1] = 0.0
	return d
end

"""
	Sameacrosstrials(model)

Make a structure containing quantities that are used in each trial

ARGUMENT
-`model`: data, parameters, and hyperparameters of the factorial hidden-Markov drift-diffusion model

RETURN
-a structure containing quantities that are used in each trial

EXAMPLE
```julia-repl
julia> using FHMDDM
julia> model = Model("/mnt/cup/labs/brody/tzluo/analysis_data/analysis_2022_04_14_test/data.mat"; randomize=true)
julia> S = FHMDDM.Sameacrosstrials(model)
```
"""
function Sameacrosstrials(model::Model)
	@unpack options, Î¸native, Î¸real, trialsets = model
	@unpack Î”t, K, Î = options
	Aá¶œâ‚â‚ = Î¸native.Aá¶œâ‚â‚[1]
	Aá¶œâ‚‚â‚‚ = Î¸native.Aá¶œâ‚‚â‚‚[1]
	Ï€á¶œâ‚ = Î¸native.Ï€á¶œâ‚[1]
	if K == 2
		Aá¶œ = [Aá¶œâ‚â‚ 1-Aá¶œâ‚‚â‚‚; 1-Aá¶œâ‚â‚ Aá¶œâ‚‚â‚‚]
		âˆ‡Aá¶œ = [[1.0 0.0; -1.0 0.0], [0.0 -1.0; 0.0 1.0]]
		Ï€á¶œ = [Ï€á¶œâ‚, 1-Ï€á¶œâ‚]
		âˆ‡Ï€á¶œ = [[1.0, -1.0]]
	else
		Aá¶œ = ones(1,1)
		âˆ‡Aá¶œ = [zeros(1,1), zeros(1,1)]
		Ï€á¶œ = ones(1)
		âˆ‡Ï€á¶œ = [zeros(1)]
	end
	indexÎ¸_paâ‚ = [3,6,11,13]
	indexÎ¸_paâ‚œaâ‚œâ‚‹â‚ = [3,4,5,7,10,12]
	indexÎ¸_pcâ‚ = [8]
	indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚ = [1,2]
	indexÎ¸_Ïˆ = [9]
	counter = 13
	indexÎ¸_py = map(trialset->map(mpGLM->zeros(Int,length(mpGLM.Î¸.ğ®)+length(mpGLM.Î¸.ğ¯)), trialset.mpGLMs), trialsets)
	for s in eachindex(indexÎ¸_py)
		for n in eachindex(indexÎ¸_py[s])
			for q in eachindex(indexÎ¸_py[s][n])
				counter += 1
				indexÎ¸_py[s][n][q] = counter
			end
		end
	end
	indexÎ¸_pY = map(x->vcat(x...), indexÎ¸_py)
	nÎ¸_trialset = indexÎ¸_pY[end][end]
	index_paâ‚_in_Î¸, index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸, index_pcâ‚_in_Î¸, index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸, index_Ïˆ_in_Î¸ = zeros(Int, nÎ¸_trialset), zeros(Int, nÎ¸_trialset), zeros(Int, nÎ¸_trialset), zeros(Int, nÎ¸_trialset), zeros(Int, nÎ¸_trialset)
	index_paâ‚_in_Î¸[indexÎ¸_paâ‚] .= 1:length(indexÎ¸_paâ‚)
	index_paâ‚œaâ‚œâ‚‹â‚_in_Î¸[indexÎ¸_paâ‚œaâ‚œâ‚‹â‚] .= 1:length(indexÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	index_pcâ‚_in_Î¸[indexÎ¸_pcâ‚] .= 1:length(indexÎ¸_pcâ‚)
	index_pcâ‚œcâ‚œâ‚‹â‚_in_Î¸[indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚] .= 1:length(indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚)
	index_Ïˆ_in_Î¸[indexÎ¸_Ïˆ] .= 1:length(indexÎ¸_Ïˆ)
	index_pY_in_Î¸ = map(x->zeros(Int, nÎ¸_trialset), indexÎ¸_pY)
	for i = 1:length(index_pY_in_Î¸)
		index_pY_in_Î¸[i][indexÎ¸_pY[i]] = 1:length(indexÎ¸_pY[i])
	end
	nÎ¸_paâ‚œaâ‚œâ‚‹â‚ = length(indexÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	P = Probabilityvector(Î”t, Î¸native, Î)
	update_for_âˆ‡âˆ‡transition_probabilities!(P)
	âˆ‡âˆ‡Aáµƒsilent = map(i->zeros(Î,Î), CartesianIndices((nÎ¸_paâ‚œaâ‚œâ‚‹â‚,nÎ¸_paâ‚œaâ‚œâ‚‹â‚)))
	âˆ‡Aáµƒsilent = map(i->zeros(Î,Î), 1:nÎ¸_paâ‚œaâ‚œâ‚‹â‚)
	Aáµƒsilent = zeros(typeof(Î¸native.B[1]), Î, Î)
	Aáµƒsilent[1,1] = Aáµƒsilent[Î, Î] = 1.0
	âˆ‡âˆ‡transitionmatrix!(âˆ‡âˆ‡Aáµƒsilent, âˆ‡Aáµƒsilent, Aáµƒsilent, P)
	Sameacrosstrials(Aáµƒsilent=Aáµƒsilent,
					âˆ‡Aáµƒsilent=âˆ‡Aáµƒsilent,
					âˆ‡âˆ‡Aáµƒsilent=âˆ‡âˆ‡Aáµƒsilent,
					Aá¶œ=Aá¶œ,
					âˆ‡Aá¶œ=âˆ‡Aá¶œ,
					Î”t=options.Î”t,
					indexÎ¸_paâ‚=indexÎ¸_paâ‚,
					indexÎ¸_paâ‚œaâ‚œâ‚‹â‚=indexÎ¸_paâ‚œaâ‚œâ‚‹â‚,
					indexÎ¸_pcâ‚=indexÎ¸_pcâ‚,
					indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚=indexÎ¸_pcâ‚œcâ‚œâ‚‹â‚,
					indexÎ¸_Ïˆ=indexÎ¸_Ïˆ,
					indexÎ¸_py=indexÎ¸_py,
					indexÎ¸_pY=indexÎ¸_pY,
					K=K,
					Ï€á¶œ=Ï€á¶œ,
					âˆ‡Ï€á¶œ=âˆ‡Ï€á¶œ,
					Î=Î)
end
